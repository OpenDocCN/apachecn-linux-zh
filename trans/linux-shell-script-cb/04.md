# 四、打字和开车

在本章中，我们将介绍以下食谱:

*   使用正则表达式
*   使用 grep 搜索和挖掘文件中的文本
*   用 cut 按列剪切文件
*   使用`sed`进行文本替换
*   使用`awk`进行高级文本处理
*   查找给定文件中单词的使用频率
*   压缩或解压缩 JavaScript
*   将多个文件合并为列
*   在文件或行中打印第 n <sup>个</sup>字或列
*   在行号或图案之间打印文本
*   以相反的顺序打印行
*   从文本中解析电子邮件地址和网址
*   删除文件中包含单词的句子
*   用目录中所有文件的文本替换模式
*   文本切片和参数操作

# 介绍

Shell 脚本包括许多解决问题的工具。有一套丰富的文本处理工具。这些工具包括`sed`、`awk`、`grep`、`cut`等实用工具，可以组合起来进行文本处理需求。

这些实用程序按字符、行、字、列或行处理文件，以多种方式处理文本文件。

正则表达式是一种基本的模式匹配技术。大多数文本处理实用程序都支持正则表达式。使用正则表达式字符串，我们可以在文本文件中过滤、剥离、替换和搜索。

这一章包括一个食谱的集合，引导你通过文本处理问题的许多解决方案。

# 使用正则表达式

正则表达式是基于模式的文本处理的核心。为了有效地使用正则表达式，需要理解它们。

每个使用`ls`的人都熟悉 glob 风格的图案。Glob 规则在许多情况下都很有用，但是对于文本处理来说太有限了。正则表达式允许您比全局规则更详细地描述模式。

匹配电子邮件地址的典型正则表达式可能如下所示:

```sh
[a-z0-9_]+@[a-z0-9]+\.[a-z]+. 

```

如果这看起来很奇怪，不要担心；一旦你通过这个食谱理解了这些概念，它就真的很简单了。

# 怎么做...

**正则表达式**由具有特殊含义的文本片段和符号组成。使用这些，我们可以构造一个正则表达式来匹配任何文本。正则表达式是许多工具的基础。本节描述正则表达式，但不介绍使用它们的 Linux/Unix 工具。后面的食谱会描述这些工具。

正则表达式由组合成字符串的一个或多个元素组成。元素可以是位置标记、标识符或计数修饰符。位置标记将正则表达式锚定到目标字符串的开头或结尾。标识符定义一个或多个字符。count 修饰符定义了一个标识符可能出现的次数。

在我们看一些示例正则表达式之前，让我们先看看规则。

# 位置标记

位置标记将正则表达式锚定到字符串中的某个位置。默认情况下，可以使用与正则表达式匹配的任何字符集，而不管字符串中的位置如何。

| **regex** | **描述** | **例** |
| --- | --- | --- |
| `^` | 这指定匹配正则表达式的文本必须从字符串的开头开始 | `^tux`匹配以`tux`开头的行 |
| `$` | 这指定匹配正则表达式的文本必须以目标字符串中的最后一个字符结尾 | `tux$`匹配以`tux`结束的线 |

# 标识符

标识符是正则表达式的基础。这些定义了匹配正则表达式必须存在(或不存在)的字符。

| **regex** | **描述** | **例** |
| --- | --- | --- |
| `A`字符 | 正则表达式必须与此字母匹配。 | `A`将匹配字母 A |
| `.` | 这匹配任何一个字符。 | `"Hack."`匹配`Hack1`、`Hacki`，但不匹配`Hack12`或`Hackil`；只有一个附加字符匹配 |
| `[]` | 这与括号中的任何一个字符匹配。括起来的字符可以是一组或一个范围。 | `coo[kl]`匹配`cook`或`cool`；[0-9]匹配任何单个数字 |
| `[^]` | 这与任何一个字符匹配，但方括号内的字符除外。括起来的字符可以是一组或一个范围。 | `9[^01]`匹配`92``93`，不匹配`91``90`；`A[^0-9]`匹配一个`A`，后面跟除了一个数字之外的任何东西 |

# 计数修饰符

标识符可能出现一次、从未出现或多次。计数修改器定义一个模式可能出现的次数。

| **regex** | **描述** | **例** |
| --- | --- | --- |
| `?` | 这意味着前面的项目必须匹配一次或零次 | `colou?r`匹配`color`或`colour`，但不匹配`colouur` |
| `+` | 这意味着前面的项目必须匹配一次或多次 | `Rollno-9+`匹配`Rollno-99`和`Rollno-9`，但不匹配`Rollno-` |
| `*` | 这意味着前面的项目必须匹配零次或更多次 | `co*l`匹配`cl`、`col`和`coool` |
| `{n}` | 这意味着前面的项目必须匹配 n 次 | `[0-9]{3}`匹配任意三位数；`[0-9]{3}`可扩展为`[0-9][0-9][0-9]` |
| `{n,}` | 这指定了前一项匹配的最小次数 | `[0-9]{2,}`匹配两位数或更长的任何数字 |
| `{n, m}` | 这指定了前一项匹配的最小和最大次数 | `[0-9]{2,5}`匹配任何两位到五位的数字 |

# 其他的

以下是微调正则表达式解析方式的其他字符。

| `()` | 这将随附的术语视为一个整体 | `ma(tri)?x`匹配`max`或`matrix` |
| `&#124;` | 这指定了交替-；`&#124;`两侧的其中一个项目应该匹配 | `Oct (1st &#124; 2nd)`匹配`Oct 1st`或`Oct 2nd` |
| `\` | 这是转义字符，用于转义前面提到的任何特殊字符 | `a\.b`匹配`a.b`，但不匹配`ajb`；它忽略了`.`的特殊含义，因为`\` |

关于可用正则表达式组件的更多细节，可以参考[http://www.linuxforu.com/2011/04/sed-explained-part-1/](http://www.linuxforu.com/2011/04/sed-explained-part-1/)。

# 还有更多...

让我们看几个正则表达式的例子:

这个正则表达式可以匹配任何一个单词:

```sh
( +[a-zA-Z]+ +) 

```

最初的`+`字符表示我们需要 1 个或更多的空格。

`[a-zA-Z]`集合都是大写字母和小写字母。下面的加号表示我们至少需要一个字母，并且可以有更多。

最后的`+`字符表示我们需要用一个或多个空格来结束这个单词。

This would not match the last word in a sentence. To match the last word in a sentence or the word before a comma, we write the expression like this:

```sh
( +[a-zA-Z]+[?,\.]? +) 

```

`[?,\.]?`短语表示我们可能有一个问号、逗号或句号，但最多一个。句点用反斜杠转义，因为空句点是匹配任何内容的通配符。

更容易匹配一个 IP 地址。我们知道我们会有四个三位数的数字，用句点分隔。

`[0-9]`短语定义了一个数字。`{1,3}`短语将计数定义为至少一个数字且不超过三个数字:

```sh
[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3} 

```

我们还可以使用`[[:digit:]]`构造来定义一个 IP 地址，以定义一个数字:

```sh
[[:digit:]]{1,3}\.[[:digit:]]{1,3}\.[[:digit:]]{1,3}\.[[:digit:]]{1,3} 

```

我们知道一个 IP 地址在四个整数的范围内(每个从 0 到 255)，用点分隔(例如，`192.168.0.2`)。

This regex will match an IP address in the text being processed. However, it doesn't check for the validity of the address. For example, an IP address of the form `123.300.1.1` will be matched by the regex despite being an invalid IP.

# 它是如何工作的...

正则表达式由复杂的状态机解析，该状态机试图找到正则表达式与目标文本字符串的最佳匹配。该文本可以是管道、文件甚至是您在命令行上键入的字符串的输出。如果有多种方法来实现正则表达式，引擎通常会选择最大的匹配字符集。

例如，给定字符串`this is a test`和正则表达式`s.*s`，匹配将是`s is a tes`，而不是`s is`。

关于可用正则表达式组件的更多细节，可以参考[http://www.linuxforu.com/2011/04/sed-explained-part-1/](http://www.linuxforu.com/2011/04/sed-explained-part-1/)。

# 还有更多...

前面的表格描述了正则表达式中使用的字符的特殊含义。

# 特殊字符的处理

正则表达式使用一些字符，如`$`、`^`、`.`、`*`、`+`、`{`、`}`作为特殊字符。但是，如果我们想使用这些字符作为正常的文本字符呢？让我们看一个正则表达式的例子，`a.txt`。

这将匹配字符`a`，后跟任何字符(由于`.`字符)，然后后跟`txt`字符串。然而，我们希望`.`匹配文字`.`而不是任何字符。为了实现这一点，我们在字符前加一个反斜杠`\`(这样做叫做转义字符)。这表明正则表达式想要匹配文字字符，而不是它的特殊含义。因此，最终的正则表达式变成`a\.txt`。

# 可视化正则表达式

正则表达式可能很难理解。幸运的是，有实用程序可以帮助可视化正则表达式。位于[http://www.regexper.com](http://www.regexper.com)的页面让你输入一个正则表达式，并创建一个图表来帮助你理解它。下面是描述一个简单正则表达式的截图:

![](assets/B05265_04_image.png)

# 使用 grep 搜索和挖掘文件中的文本

如果你忘了把钥匙放在哪里，你只要去找就行了。如果你忘记了什么文件有一些信息，`grep`命令会帮你找到。这个食谱将教你如何定位包含模式的文件。

# 怎么做...

`grep`命令是搜索文本的神奇的 Unix 工具。它接受正则表达式，可以生成各种格式的报告。

1.  搜索`stdin`匹配模式的线条:

```sh
        $ echo -e "this is a word\nnext line" | grep word 
 this is a word

```

2.  在单个文件中搜索包含给定模式的行:

```sh
        $ grep pattern filename
 this is the line containing pattern

```

或者，这将执行相同的搜索:

```sh
        $ grep "pattern" filename
 this is the line containing pattern

```

3.  在多个文件中搜索符合模式的行:

```sh
        $ grep "match_text" file1 file2 file3 ... 

```

4.  要突出显示匹配的图案，请使用`-color`选项。虽然选择权的地位并不重要，但惯例是将选择权放在首位。

```sh
        $ grep -color=auto word filename
 this is the line containing word

```

5.  `grep`命令默认使用基本正则表达式。这些是前面描述的规则的子集。`-E`选项将导致`grep`使用**扩展正则表达式**语法。`egrep`命令是`grep`的变体，默认情况下使用扩展正则表达式:

```sh
        $ grep -E "[a-z]+" filename

```

或者:

```sh
        $ egrep "[a-z]+" filename

```

6.  `-o`选项将只报告匹配的字符，而不是整行:

```sh
        $ echo this is a line. | egrep -o "[a-z]+\."
 line

```

7.  `-v`选项将打印除包含`match_pattern`的行以外的所有行:

```sh
        $ grep -v match_pattern file

```

添加到`grep`的`-v`选项反转匹配结果。

8.  `-c`选项将计算图案出现的行数:

```sh
        $ grep -c "text" filename
 10

```

需要注意的是`-c`统计的是匹配行数，而不是匹配次数。考虑这个例子:

```sh
        $ echo -e "1 2 3 4\nhello\n5 6" | egrep  -c "[0-9]"
 2

```

即使有六个匹配项，`grep`报告`2`，因为只有两个匹配行。单行中的多个匹配只计算一次。

9.  要计算文件中匹配项目的数量，请使用以下技巧:

```sh
        $ echo -e "1 2 3 4\nhello\n5 6" | egrep -o "[0-9]" | wc -l
 6

```

10.  `-n`选项将打印匹配字符串的行号:

```sh
        $ cat sample1.txt
 gnu is not unix
 linux is fun
 bash is art
 $ cat sample2.txt
 planetlinux
 $ grep linux -n sample1.txt
 2:linux is fun

```

或者

```sh
        $ cat sample1.txt | grep linux -n

```

如果使用多个文件，`-c`选项将打印文件名，结果如下:

```sh
        $ grep linux -n sample1.txt sample2.txt
 sample1.txt:2:linux is fun
 sample2.txt:2:planetlinux

```

11.  `-b`选项将打印发生匹配的行的偏移量。添加`-o`选项将打印模式匹配的精确字符或字节偏移量:

```sh
        $ echo gnu is not unix | grep -b -o "not"
 7:not

```

字符位置从`0`开始编号，而不是从`1`开始编号。

12.  `-l`选项列出了哪些文件包含该模式:

```sh
        $ grep -l linux sample1.txt sample2.txt
 sample1.txt
 sample2.txt

```

`-l`参数的反义词是`-L`。`-L`参数返回不匹配文件的列表。

# 还有更多...

`grep`命令是最通用的 Linux/Unix 命令之一。它还包括在文件夹中搜索的选项，选择要搜索的文件，以及识别模式的更多选项。

# 递归搜索许多文件

要递归搜索文件层次结构中包含的文件中的文本，请使用以下命令:

```sh
    $ grep "text" . -R -n

```

在该命令中，`.`指定当前目录。

The options `-R` and `-r` mean the same thing when used with `grep`.

考虑这个例子:

```sh
    $ cd src_dir
 $ grep "test_function()" . -R -n
 ./miscutils/test.c:16:test_function();

```

`test_function()`存在于`miscutils/test.c`的第 16 行。如果您在网站或源代码树中搜索短语，则`-R`选项特别有用。它相当于这个命令:

```sh
    $ find . -type f | xargs grep "test_function()"

```

# 忽略模式中的大小写

`-i`参数匹配模式，不考虑大写或小写:

```sh
    $ echo hello world | grep -i "HELLO"
 hello

```

# 通过匹配多个模式进行 grep

`-e`参数指定了多个匹配模式:

```sh
    $ grep -e "pattern1" -e "pattern2"

```

这将打印包含任一模式的行，并为每个匹配输出一行。考虑这个例子:

```sh
    $ echo this is a line of text | grep -o -e "this" -e "line"
 this
 line

```

一个文件中可以定义多个模式。`-f`选项将读取文件并使用行分隔模式:

```sh
    $ grep -f pattern_filesource_filename

```

考虑以下示例:

```sh
    $ cat pat_file
 hello
 cool

 $ echo hello this is cool | grep -f pat_file
 hello this is cool

```

# 在 grep 搜索中包括和排除文件

`grep`可以包含或排除使用通配符模式进行搜索的文件。

要递归地只搜索`.c`和`.cpp`文件，请使用-include 选项:

```sh
    $ grep "main()" . -r  --include *.{c,cpp}

```

注意`some{string1,string2,string3}`随着`somestring1 somestring2 somestring3`膨胀。

使用`-exclude`标志从搜索中排除所有`README`文件:

```sh
    $ grep "main()" . -r --exclude "README" 

```

`--exclude-dir`选项将从搜索中排除命名目录:

```sh
    $ grep main . -r -exclude-dir CVS

```

要读取要从文件中排除的文件列表，请使用`--exclude-from FILE`。

# 使用带有零字节后缀的 xargs 的 grep

`xargs`命令提供了另一个命令的命令行参数列表。当文件名用作命令行参数时，文件名使用零字节终止符，而不是默认的空格终止符。文件名可以包含空格字符，这将被误解为名称分隔符，导致文件名被分成两个文件名(例如，`New file.txt`可能被解释为两个文件名`New`和`file.txt`)。使用零字节后缀选项解决了这个问题。我们使用`xargs`接受来自`grep`和`find`等命令的`stdin`文本。这些命令可以生成带有零字节后缀的输出。当使用`-0`标志时，`xargs`命令将预期`0`字节终止。

创建一些测试文件:

```sh
    $ echo "test" > file1
 $ echo "cool" > file2
 $ echo "test" > file3

```

`-l`选项告诉`grep`只输出匹配的文件名。`-Z`选项使`grep`对这些文件使用零字节结束符(`\0`)。这两个选项经常一起使用。`-0`到`xargs`的参数使其读取输入并在零字节结束符处分离文件名:

```sh
    $ grep "test" file* -lZ | xargs -0 rm

```

# grep 的静默输出

有时，我们只对是否匹配感兴趣，而不是检查匹配的字符串。安静选项(`-q`)使`grep`静默运行，不产生任何输出。相反，它运行命令并根据成功或失败返回退出状态。返回状态为`0`表示成功，非零表示失败。

`grep`命令可以在安静模式下使用，用于测试文件中是否出现匹配文本:

```sh
#!/bin/bash  
#Filename: silent_grep.sh 
#Desc: Testing whether a file contain a text or not  

if [ $# -ne 2 ]; then 
  echo "Usage: $0 match_text filename" 
  exit 1 
fi 

match_text=$1  
filename=$2 
grep -q "$match_text" $filename 

if [ $? -eq 0 ]; then 
  echo "The text exists in the file" 
else 
  echo "Text does not exist in the file" 
fi 

```

`silent_grep.sh`脚本接受两个命令行参数，一个匹配词(`Student`)和一个文件名(`student_data.txt`):

```sh
    $ ./silent_grep.sh Student student_data.txt 
 The text exists in the file 

```

# 在文本匹配前后打印行

基于上下文的打印是`grep`的优秀特性之一。当 grep 找到与模式匹配的行时，它只打印匹配的行。我们可能需要在匹配线之前或之后看到 *n* 线。`-B`和`-A`选项分别显示比赛前后的线条。

`-A`选项在匹配后打印行:

```sh
    $ seq 10 | grep 5 -A 3
 5
 6
 7
 8

```

`-B`选项打印匹配前的行:

```sh
    $ seq 10 | grep 5 -B 3
 2
 3
 4
 5

```

`-A`和`-B`选项可以一起使用，也可以使用`-C`选项在比赛前后打印相同的行数:

```sh
    $ seq 10 | grep 5 -C 3
 2
 3
 4
 5
 6
 7
 8

```

如果有多个匹配项，则每个部分由一条`--`线定界:

```sh
    $ echo -e "a\nb\nc\na\nb\nc" | grep a -A 1
 a
 b
 --
 a
 b

```

# 用 cut 按列剪切文件

cut 命令按列而不是行拆分文件。这对于处理具有固定宽度字段的文件、**逗号分隔值** ( **CSV** 文件)或空格分隔文件(如标准日志文件)非常有用。

# 怎么做...

`cu` t 命令提取字符位置或列之间的数据。您可以指定分隔每一列的分隔符。在`cut`术语中，每一列被称为一个**字段**。

1.  -f 选项定义了要提取的字段:

```sh
        cut -f FIELD_LIST filename

```

`FIELD_LIST`是要显示的列列表。列表由逗号分隔的列号组成。考虑这个例子:

```sh
        $ cut -f 2,3 filename

```

这里，显示第二列和第三列。

2.  `cut`命令也读取来自`stdin`的输入。

*制表符*是字段的默认分隔符。将打印没有分隔符的行。`-s`选项将禁止打印没有分隔符的行。以下命令演示了如何从制表符分隔的文件中提取列:

```sh
        $ cat student_data.txt 
 No  Name  Mark  Percent
 1  Sarath  45  90
 2  Alex  49  98
 3  Anu  45  90

 $ cut -f1 student_data.txt
 No 
 1 
 2 
 3 

```

3.  要提取多个字段，请使用以下选项提供用逗号分隔的多个字段编号:

```sh
        $ cut -f2,4 student_data.txt
 Name     Percent
 Sarath   90
 Alex     98
 Anu      90

```

4.  `--complement`选项将显示除`-f`定义的字段外的所有字段。该命令显示除`3`以外的所有字段:

```sh
        $ cut -f3 --complement student_data.txt
 No  Name    Percent 
 1   Sarath  90
 2   Alex    98
 3   Anu     90

```

5.  `-d`选项将设置分隔符。以下命令显示了如何使用带有冒号分隔列表的`cut`:

```sh
        $ cat delimited_data.txt
 No;Name;Mark;Percent
 1;Sarath;45;90
 2;Alex;49;98
 3;Anu;45;90

 $ cut -f2 -d";" delimited_data.txt
 Name
 Sarath
 Alex
 Anu

```

# 还有更多

`cut`命令有更多选项来定义显示的列。

# 将字符或字节范围指定为字段

具有固定宽度列的报表在列之间会有不同数量的空格。不能根据字段位置提取值，但可以根据字符位置提取值。`cut`命令可以根据字节或字符以及字段进行选择。

输入每个字符位置进行提取是不合理的，因此 cut 接受这些符号以及逗号分隔列表:

| `N-` | 从第*N*个字节、字符或字段到行尾 |
| `N-M` | 从*N<sup>th</sup>T3】到*M<sup>th</sup>T7】(包括)字节、字符或字段** |
| `-M` | 从第一个到第 M 个(包括)字节、字符或字段 |

我们使用前面的符号将字段指定为一系列字节、字符或具有以下选项的字段:

*   `-b`为字节
*   `-c`为字符
*   `-f`用于定义字段

考虑这个例子:

```sh
    $ cat range_fields.txt
 abcdefghijklmnopqrstuvwxyz
 abcdefghijklmnopqrstuvwxyz
 abcdefghijklmnopqrstuvwxyz
 abcdefghijklmnopqrstuvwxy

```

显示第二到第五个字符:

```sh
    $ cut -c2-5 range_fields.txt
 bcde
 bcde
 bcde
 bcde

```

显示前两个字符:

```sh
    $ cut -c -2  range_fields.txt
 ab
 ab
 ab
 ab

```

将`-c`替换为`-b`进行字节计数。

`-output-delimiter`选项指定输出分隔符。这在显示多组数据时特别有用:

```sh
    $ cut range_fields.txt -c1-3,6-9 --output-delimiter ","
 abc,fghi
 abc,fghi
 abc,fghi
 abc,fghi

```

# 使用 sed 执行文本替换

`sed`代表**流编辑**。它最常用于文本替换。这个食谱涵盖了许多常见的`sed`技术。

# 怎么做...

`sed`命令可以用另一个字符串替换一个模式的出现。模式可以是简单的字符串或正则表达式:

```sh
 $ sed 's/pattern/replace_string/' file 

```

或者，`sed`可以从`stdin`读取:

```sh
 $ cat file | sed 's/pattern/replace_string/'

```

If you use the `vi` editor, you will notice that the command to replace the text is very similar to the one discussed here. By default, `sed` only prints the substituted text, allowing it to be used in a pipe.

```sh
 $ cat /etc/passwd | cut -d : -f1,3 | sed 's/:/ - UID: /'
 root - UID: 0
 bin - UID: 1
 ...

```

1.  `-I`选项将使`sed`用修改后的数据替换原始文件:

```sh
        $ sed -i 's/text/replace/' file

```

2.  前面的示例替换了每行中第一次出现的模式。`-g`参数将使`sed`在每次出现时替换:

```sh
        $ sed 's/pattern/replace_string/g' file

```

`/#g`选项将从 *N <sup>第</sup>T4 事件开始替换:*

```sh
        $ echo thisthisthisthis | sed 's/this/THIS/2g' 
 thisTHISTHISTHIS

 $ echo thisthisthisthis | sed 's/this/THIS/3g' 
 thisthisTHISTHIS

 $ echo thisthisthisthis | sed 's/this/THIS/4g' 
 thisthisthisTHIS

```

`sed`命令将`s`后面的字符视为命令分隔符。这允许我们改变带有`/`字符的字符串:

```sh
        sed 's:text:replace:g'
 sed 's|text|replace|g'

```

当分隔符出现在模式中时，我们必须使用`\`前缀对其进行转义，如下所示:

```sh
        sed 's|te\|xt|replace|g'

```

`\|`是出现在用转义符替换的模式中的分隔符。

# 还有更多...

`sed`命令支持正则表达式作为要替换的模式，并且有更多的选项来控制其行为。

# 删除空行

正则表达式支持使删除空行变得容易。`^$`正则表达式定义了一条在开始和结束之间没有任何内容的线==一条空行。最后的`/d`告诉 sed 删除这些行，而不是执行替换。

```sh
    $ sed '/^$/d' file

```

# 直接在文件中执行替换

当文件名传递给`sed`时，通常会打印到`stdout`。`-I`选项将导致`sed`就地修改文件内容:

```sh
    $ sed 's/PATTERN/replacement/' -i filename

```

例如，用文件中的另一个指定数字替换所有三位数，如下所示:

```sh
    $ cat sed_data.txt
 11 abc 111 this 9 file contains 111 11 88 numbers 0000

 $ sed -i 's/\b[0-9]\{3\}\b/NUMBER/g' sed_data.txt
 $ cat sed_data.txt
 11 abc NUMBER this 9 file contains NUMBER 11 88 numbers 0000

```

前面的一行仅替换三位数。`\b[0-9]\{3\}\b`是用来匹配三位数的正则表达式。`[0-9]`是从`0`到`9`的数字范围。`{3}`字符串定义了位数。反斜杠用于给`{`和`}`赋予特殊含义，`\b`代表空白，即单词边界标记。

It's a useful practice to first try the `sed` command without `-i` to make sure your regex is correct. After you are satisfied with the result, add the `-i` option to make changes to the file. Alternatively, you can use the following form of `sed`:

```sh
    sed -i .bak 's/abc/def/' file

```

In this case, `sed` will perform the replacement on the file and also create a file called `file.bak`, which contains the original contents.

# 匹配字符串表示法()

`&`符号是匹配的字符串。该值可用于替换字符串:

```sh
    $ echo this is an example | sed 's/\w\+/[&]/g'
 [this] [is] [an] [example]

```

这里`\w\+`正则表达式匹配每个单词。然后，我们用`[&]`替换，对应匹配的词。

# 子字符串匹配表示法 （\1）

`&`对应于给定模式的匹配字符串。正则表达式的括号部分可以与`\#`匹配:

```sh
    $ echo this is digit 7 in a number | sed 's/digit \([0-9]\)/\1/'
 this is 7 in a number

```

前面的命令将`digit 7`替换为`7`。匹配的子字符串是`7`。`\(pattern\)`匹配子串。该模式包含在`()`中，用反斜杠转义。第一个子串匹配，对应的符号是`\1`，第二个是`\2`，以此类推。

```sh
    $ echo seven EIGHT | sed 's/\([a-z]\+\) \([A-Z]\+\)/\2 \1/'
 EIGHT seven

```

`([a-z]\+\)`匹配第一个单词，`\([A-Z]\+\)`匹配第二个单词；`\1`和`\2`用于参考。这种类型的引用称为**反向引用**。在替换零件中，它们的顺序被更改为`\2 \1`，因此，它以相反的顺序出现。

# 组合多个表达式

多个`sed`命令可以与管道、用分号分隔的模式或`-e PATTERN`选项组合在一起:

```sh
    sed 'expression' | sed 'expression'

```

前面的命令相当于下面的命令:

```sh
    $ sed 'expression; expression'

```

或者:

```sh
    $ sed -e 'expression' -e expression'

```

考虑这些例子:

```sh
    $ echo abc | sed 's/a/A/' | sed 's/c/C/'
 AbC
 $ echo abc | sed 's/a/A/;s/c/C/'
 AbC
 $ echo abc | sed -e 's/a/A/' -e 's/c/C/'
 AbC

```

# 引用

`sed`表达式一般用单引号引用。可以使用双引号。shell 将在调用 sed 之前展开双引号。当我们想要在`sed`表达式中使用变量字符串时，使用双引号非常有用。

考虑这个例子:

```sh
 $ text=hello
 $ echo hello world | sed "s/$text/HELLO/" 
 HELLO world 

```

`$text`评定为`hello`。

# 使用 awk 进行高级文本处理

`awk`命令处理数据流。它支持关联数组、递归函数、条件语句等等。

# 准备好

一个`awk`脚本的结构是:

```sh
awk ' BEGIN{ print "start" } pattern { commands } END{ print "end"}' file

```

`awk`命令也可以从`stdin`读取。

一个`awk`脚本包括三个部分–:`BEGIN`、`END`，以及一个带有模式匹配选项的公共语句块。这些都是可选的，它们中的任何一个都可以在脚本中缺失。

Awk 将逐行处理文件。在`<code>awk</code>`开始处理文件之前，将对`BEGIN`之后的命令进行评估。Awk 将使用 PATTER 后面的命令处理与 PATTER 匹配的每一行。最后，在处理完整个文件后，`<CODE>awk</CODE>`将处理跟随`END`的命令。

# 怎么做...

让我们写一个简单的`awk`脚本，用单引号或双引号括起来:

```sh
    awk 'BEGIN { statements } { statements } END { end statements }'

```

或者:

```sh
    awk "BEGIN { statements } { statements } END { end statements }"

```

该命令将报告文件中的行数:

```sh
    $ awk 'BEGIN { i=0 } { i++ } END{ print i}' filename

```

或者:

```sh
    $ awk "BEGIN { i=0 } { i++ } END{ print i }" filename

```

# 它是如何工作的...

`awk`命令按以下顺序处理参数:

1.  首先，它执行`BEGIN { commands }`块中的命令。
2.  接下来，`awk`从文件或`stdin`中读取一行，如果匹配可选模式，则执行`commands`块。它重复这个步骤，直到文件结束。
3.  当到达输入流的末尾时，它执行`END { commands }`块。

在`awk`开始从输入流读取行之前执行`BEGIN`块。它是一个可选块。这些命令，例如变量初始化和打印输出表的输出头，是`BEGIN`块中常见的命令。

`END`块类似于`BEGIN`块。当`awk`完成从输入流中读取所有行时，它被执行。这通常是在分析所有行后打印结果。

最重要的块保存模式块的公共命令。该块也是可选的。如果没有提供，则执行`{ print }`打印读取的每一行。该块对`awk`读取的每一行执行。它就像一个`while`循环，语句在循环体内部执行。

当读取一行时，`awk`检查模式是否与该行匹配。模式可以是正则表达式匹配、条件、一系列行等等。如果当前行与模式匹配，`awk`执行包含在`{ }`中的命令。

模式是可选的。如果不使用，所有行都匹配:

```sh
    $ echo -e "line1\nline2" | awk 'BEGIN{ print "Start" } { print } \   
        END{ print "End" } '
 Start
 line1
 line2
 End

```

当`print`在没有参数的情况下使用时，`awk`打印当前行。

print 命令可以接受参数。这些参数用逗号分隔，用空格分隔符打印。双引号用作连接运算符。

考虑这个例子:

```sh
    $ echo | awk '{ var1="v1"; var2="v2"; var3="v3"; \
 print var1,var2,var3 ; }'

```

前面的命令将显示:

```sh
    v1 v2 v3

```

`echo`命令在标准输出中写入一行。因此，`awk`的`{ }`块中的语句被执行一次。如果`awk`的输入包含多行，`awk`中的命令将被执行多次。

用带引号的字符串进行连接:

```sh
    $ echo | awk '{ var1="v1"; var2="v2"; var3="v3"; \
 print var1 "-" var2 "-" var3 ; }'
 v1-v2-v3

```

`{ }`就像一个循环中的块，迭代文件的每一行。

It's a common practice to place initial variable assignments such as `var=0;` in the `BEGIN` block. The `END{}` block contains commands to print the results.

# 还有更多...

`awk`命令与`grep`、`find`和`tr`等命令的不同之处在于，它不仅仅是一个带有改变行为选项的功能。`awk`命令是一个解释和执行程序的程序，像 shell 一样包含特殊变量。

# 特殊变量

可以与`awk`一起使用的一些特殊变量如下:

*   `NR`:代表当前记录号，对应`awk`使用行作为记录时的当前行号。
*   `NF`:代表字段数，对应当前正在处理的记录中的字段数。默认字段分隔符是空格。
*   `$0`:这是一个包含当前记录文本的变量。
*   `$1`:这是一个保存第一个字段文本的变量。
*   `$2`:这是一个保存第二个字段文本的变量。

考虑这个例子:

```sh
    $ echo -e "line1 f2 f3\nline2 f4 f5\nline3 f6 f7" | \

 awk '{
 print "Line no:"NR",No of fields:"NF, "$0="$0,   
        "$1="$1,"$2="$2,"$3="$3 
 }' 
 Line no:1,No of fields:3 $0=line1 f2 f3 $1=line1 $2=f2 $3=f3 
 Line no:2,No of fields:3 $0=line2 f4 f5 $1=line2 $2=f4 $3=f5 
 Line no:3,No of fields:3 $0=line3 f6 f7 $1=line3 $2=f6 $3=f7

```

我们可以将一行的最后一个字段打印为`print $NF`，倒数第二个字段打印为`$(NF-1)`等等。

`awk`还支持一个`printf()`函数，语法与 c 中相同。

以下命令打印每行的第二个和第三个字段:

```sh
    $awk '{ print $3,$2 }'  file

```

我们可以使用 NR 来计算文件中的行数:

```sh
    $ awk 'END{ print NR }' file

```

这里，我们只使用`END`块。Awk 在读取每一行时更新`NR`。当`awk`到达文件末尾时，NR 将包含最后一个行号。您可以将`field 1`每行的所有数字总结如下:

```sh
    $ seq 5 | awk 'BEGIN{ sum=0; print "Summation:" } 
 { print $1"+"; sum+=$1 } END { print "=="; print sum }' 
 Summation: 
 1+ 
 2+ 
 3+ 
 4+ 
 5+ 
 ==
 15

```

# 将外部变量传递给 awk

使用`-v`参数，我们可以将`stdin`以外的外部值传递给`awk`，如下所示:

```sh
    $ VAR=10000
 $ echo | awk -v VARIABLE=$VAR '{ print VARIABLE }'
 10000

```

有一种灵活的替代方法可以从外部传递许多变量值`awk`。考虑以下示例:

```sh
    $ var1="Variable1" ; var2="Variable2"
 $ echo | awk '{ print v1,v2 }' v1=$var1 v2=$var2
 Variable1 Variable2

```

当通过文件而不是标准输入进行输入时，请使用以下命令:

```sh
    $ awk '{ print v1,v2 }' v1=$var1 v2=$var2 filename

```

在前面的方法中，变量被指定为键-值对，用空格分隔，并且在`BEGIN`、`{ }`和`END`块之后不久将`(v1=$var1 v2=$var2 )`指定为`awk`的命令参数。

# 使用 getline 显式读取一行

`awk`程序默认读取整个文件。`getline`功能将读取一行。这可用于从`BEGIN`块中的文件读取标题信息，然后处理主块中的实际数据。

语法是`getline var`。`var`变量将包含该行。如果调用`getline`没有参数，我们可以使用`$0`、`$1`和`$2`访问该行的内容。

考虑这个例子:

```sh
    $ seq 5 | awk 'BEGIN { getline; print "Read ahead first line", $0 }     
    { print $0 }'
 Read ahead first line 1 
 2
 3
 4
 5

```

# 使用过滤器模式过滤 awk 处理的线条

我们可以为要处理的行指定条件:

```sh
 $ awk 'NR < 5' # first four lines
    $ awk 'NR==1,NR==4' #First four lines
    $ # Lines containing the pattern linux (we can specify regex)
    $ awk '/linux/' 
    $ # Lines not containing the pattern linux
    $ awk '!/linux/' 

```

# 设置字段分隔符

默认情况下，字段的分隔符是空格。`-F`选项定义了不同的字段分隔符。

```sh
    $ awk -F: '{ print $NF }' /etc/passwd

```

或者:

```sh
    awk 'BEGIN { FS=":" } { print $NF }' /etc/passwd

```

我们可以通过在`BEGIN`块中设置`OFS="delimiter"`来设置输出字段分隔符。

# 从 awk 读取命令输出

Awk 可以调用命令并读取输出。将命令字符串放在引号内，并使用竖线将输出传送到`getline`:

```sh
    "command" | getline output ;

```

下面的代码从`/etc/passwd`读取一行，显示登录名和主文件夹。它将字段分隔符重置为`BEGIN`块中的`:`并调用主块中的`grep`。

```sh
    $ awk 'BEGIN {FS=":"} { "grep root /etc/passwd" | getline; \
        print $1,$6 }'
 root /root

```

# Awk 中的关联数组

Awk 支持包含数字或字符串的变量，也支持关联数组。关联数组是用字符串而不是数字来索引的数组。您可以通过方括号内的索引来识别关联数组:

```sh
    arrayName[index]

```

可以为数组赋值等号，就像简单的用户定义变量一样:

```sh
    myarray[index]=value

```

# 在 awk 中使用循环

Awk 支持数值`for`循环，语法类似于`C`:

```sh
    for(i=0;i<10;i++) { print $i ; } 

```

Awk 还支持显示数组内容的循环列表样式:

```sh
    for(i in array) { print array[i]; } 

```

下面的示例显示了如何将数据收集到数组中，然后显示它。该脚本从`/etc/password`读取行，在`:`标记处将其拆分为字段，并创建一个名称数组，其中索引是登录标识，值是用户名:

```sh
    $ awk 'BEGIN {FS=":"} {nam[$1]=$5} END {for {i in nam} \
        {print i,nam[i]}}' /etc/passwd
 root root
 ftp FTP User
 userj Joe User

```

# awk 中的字符串操作函数

`awk`的语言包括许多内置的字符串操作功能:

*   `length(string)`:返回字符串长度。
*   `index(string, search_string)`:返回字符串中`search_string`的位置。
*   `split(string, array, delimiter)`:这将使用通过在分隔符上拆分字符串而创建的字符串填充数组。
*   `substr(string, start-position, end-position)`:返回字符串在开始和结束字符偏移量之间的子字符串。
*   `sub(regex, replacement_str, string)`:这将字符串中第一个出现的正则表达式匹配替换为`replacment_str`。
*   `gsub(regex, replacment_str, string)`:这和`sub()`很像，但是它代替了每一个正则表达式匹配。
*   `match(regex, string)`:返回字符串中是否有正则表达式(正则表达式)匹配。如果找到匹配，则返回非零输出，否则返回零。两个特殊变量与`match()`相关联。他们是`RSTART`和`RLENGTH`。`RSTART`变量包含正则表达式匹配开始的位置。`RLENGTH`变量包含正则表达式匹配的字符串长度。

# 查找给定文件中单词的使用频率

计算机擅长计数。我们经常需要计算一些项目，比如发送垃圾邮件的网站数量、不同网页的下载数量，或者单词在一篇文本中的使用频率。这个食谱展示了如何计算一段文字中的单词使用量。这些技术也适用于日志文件、数据库输出等。

# 准备好

我们可以用`awk`的关联数组用不同的方式来解决这个问题。**单词**是字母字符，用空格或句点分隔。首先，我们应该解析给定文件中的所有单词，然后需要找到每个单词的数量。可以使用带有工具的正则表达式来解析单词，如`sed`、`awk`或`grep`。

# 怎么做...

我们只是探索了解决方案的逻辑和思路；现在让我们创建如下 shell 脚本:

```sh
#!/bin/bash 
#Name: word_freq.sh 
#Desc: Find out frequency of words in a file 

if [ $# -ne 1 ]; 
then 
  echo "Usage: $0 filename"; 
  exit -1 
fi 

filename=$1 
egrep -o "\b[[:alpha:]]+\b" $filename | \
  awk '{ count[$0]++ }
    END {printf("%-14s%s\n","Word","Count") ;
      for(ind in count)
        { printf("%-14s%d\n",ind,count[ind]); 
        }
      }

```

该脚本将生成以下输出:

```sh
    $ ./word_freq.sh words.txt 
 Word          Count 
 used           1
 this             2 
 counting   1

```

# 它是如何工作的...

`egrep`命令将文本文件转换成单词流，每行一个单词。`\b[[:alpha:]]+\b`模式匹配每个单词，并删除空白和标点符号。`-o`选项将匹配的字符序列打印为每行一个单词。

`awk`命令对每个单词进行计数。它为每一行执行`{ }`块中的语句，所以我们不需要特定的循环来执行。计数通过`count[$0]++`命令递增，其中`$0`是当前行，`count`是关联数组。处理完所有行后，`END{}`块打印单词及其计数。

这个过程的主体可以使用我们所看到的其他工具进行修改。我们可以使用`tr`命令将大写和非大写的单词合并成一个计数，并使用 sort 命令对输出进行排序，如下所示:

```sh
egrep -o "\b[[:alpha:]]+\b" $filename | tr [A=Z] [a-z] | \ 
  awk '{ count[$0]++ } 
    END{ printf("%-14s%s\n","Word","Count") ; 
      for(ind in count) 
        {  printf("%-14s%d\n",ind,count[ind]); 
        }
      }' | sort 

```

# 请参见

*   本章中的*使用 awk 进行高级文本处理*配方解释了`awk`命令
*   [第 1 章](01.html)*中的*数组和关联数组*配方解释了 Bash 中的数组*

# 压缩或解压缩 JavaScript

JavaScript 在网站中被广泛使用。在开发 JavaScript 代码时，我们使用空格、注释和标签来提高代码的可读性和维护性。这会增加文件大小，从而降低页面加载速度。因此，大多数专业网站使用压缩的 JavaScript 加速页面加载。这种压缩(也称为**缩小的 JS** )是通过删除空白和换行符来完成的。一旦 JavaScript 被压缩，就可以通过替换足够的空白和换行符来解压缩，使其可读。这个配方在 Shell 中产生类似的功能。

# 准备好

我们将编写一个 JavaScript 压缩器工具和一个解压缩工具。考虑以下 JavaScript:

```sh
    $ cat sample.js
 function sign_out()
 { 

 $("#loading").show(); 
 $.get("log_in",{logout:"True"},

 function(){ 
 window.location="";
 }); 
 }

```

我们的脚本需要执行以下步骤来压缩 JavaScript:

1.  删除换行符和制表符。
2.  删除重复的空格。
3.  替换看起来像`/* content */`的评论。

为了解压或使 JavaScript 更易读，我们可以使用以下任务:

*   将`;`替换为`;\n`
*   将`{`替换为`{\n`，将`}`替换为`\n}`

# 怎么做...

使用这些步骤，我们可以使用以下命令链:

```sh
    $ cat sample.js |  \
 tr -d '\n\t' |  tr -s ' ' \
 | sed 's:/\*.*\*/::g' \
 | sed 's/ \?\([{}();,:]\) \?/\1/g' 

```

输出如下:

```sh
    function sign_out(){$("#loading").show();$.get("log_in",  
    {logout:"True"},function(){window.location="";});}

```

以下解压缩脚本使模糊代码可读:

```sh
    $ cat obfuscated.txt | sed 's/;/;\n/g; s/{/{\n\n/g; s/}/\n\n}/g' 

```

或者:

```sh
    $ cat obfuscated.txt | sed 's/;/;\n/g' | sed 's/{/{\n\n/g' | sed   
    's/}/\n\n}/g'

```

There is a limitation in the script: that it even gets rid of extra spaces where their presence is intentional. For example, if you have a line like the following:                 `var a = "hello world"` 
The two spaces will be converted into one space. You can fix problems such as this using the pattern-matching tools we have discussed. Also, when dealing with a mission-critical JavaScript code, it is advised that you use well-established tools to do this.

# 它是如何工作的...

压缩命令执行以下任务:

*   删除`\n`和`\t`字符:

```sh
 tr -d '\n\t'  

```

*   删除额外空间:

```sh
 tr -s ' ' or sed 's/[ ]\+/ /g' 

```

*   删除注释:

```sh
 sed 's:/\*.*\*/::g' 

```

`:`用作`sed`分隔符，以避免需要转义`/`，因为我们需要使用`/*`和`*/`。

在 sed 中，`*`被转义为`\*`。

`.*`匹配`/*`和`*/`之间的所有文本。

*   删除`{`、`}`、`(`、`)`、`;`、`:`和`,`字符前后的所有空格:

```sh
 sed 's/ \?\([{}();,:]\) \?/\1/g' 

```

前面的`sed`语句是这样工作的:

*   `sed`代码中的`/ \?\([{}();,:]\) \?/`为匹配部分，`/\1 /g`为替换部分。
*   `\([{}();,:]\)`用于匹配`[ { }( ) ; , : ]`集合中的任意一个字符(插入空格是为了可读性)。`\(`和`\)`是组运算符，用于记忆替换零件中的匹配和回参考。`(`和`)`都是为了给他们一个特殊的群体操作者的意义而逃出来的。`\?`在组运算符之前和之后，以匹配集合中任何字符之前或之后的空格字符。
*   在替换部分，匹配字符串(即`:`、空格(可选)、集合中的一个字符以及可选空格的组合)被替换为匹配的字符。它使用组运算符`()`对匹配和记忆的字符进行反向引用。反向引用字符是指使用`\1`符号的组匹配。

解压缩命令的工作原理如下:

*   `s/;/;\n/g`将`;`替换为`;\n`
*   `s/{/{\n\n/g`将`{`替换为`{\n\n`
*   `s/}/\n\n}/g`将`}`替换为`\n\n}`

# 请参见

*   本章中的*使用 sed 执行文本替换*方法解释了`sed`命令
*   [第二章](02.html)、*好好指挥*中的*用 tr* 食谱翻译解释了`tr`命令

# 将多个文件合并为列

can 命令可用于逐行合并两个文件，一个文件接一个文件。有时我们需要并排合并两个或多个文件，将文件 1 中的行与文件 2 中的行连接起来。

# 怎么做...

`paste`命令执行列连接:

```sh
    $ paste file1 file2 file3 ...

```

这里有一个例子:

```sh
    $ cat file1.txt
 1
 2
 3
 4
 5
 $ cat file2.txt
 slynux
 gnu
 bash
 hack
 $ paste file1.txt file2.txt
 1 slynux
 2 gnu
 3 bash
 4 hack
 5

```

默认分隔符是制表符。我们可以用`-d`指定分隔符:

```sh
    $ paste file1.txt file2.txt -d ","
 1,slynux
 2,gnu
 3,bash
 4,hack
 5,

```

# 请参见

*   本章中的*用剪切*方法逐列剪切文件解释了如何从文本文件中提取数据

# 打印文件或行中的第 n 个单词或列

我们经常需要从文件中提取几列有用的数据。例如，在按分数排序的学生列表中，我们希望获得第四高的分数。这个食谱说明了如何做这件事。

# 怎么做...

`awk`命令经常用于此任务。

1.  要打印第五列，请使用以下命令:

```sh
        $ awk '{ print $5 }' filename

```

2.  我们可以打印多列，并在列之间插入一个自定义字符串。

以下命令将打印当前目录中每个文件的权限和文件名:

```sh
        $ ls -l | awk '{ print $1 " :  " $8 }'
 -rw-r--r-- :  delimited_data.txt
 -rw-r--r-- :  obfuscated.txt
 -rw-r--r-- :  paste1.txt
 -rw-r--r-- :  paste2.txt

```

# 请参见

*   本章中的*使用 awk 进行高级文本处理*配方解释了`awk`命令
*   本章中的*用剪切*方法逐列剪切文件解释了如何从文本文件中提取数据

# 在行号或图案之间打印文本

我们可能需要打印文件的选定部分，要么是行号范围，要么是开始和结束模式匹配的范围。

# 准备好了

`Awk`、`grep`或`sed`将根据条件选择要打印的行。使用`grep`打印包含图案的线条是最简单的。Awk 是最通用的工具。

# 怎么做...

要打印行号或图案之间的文本，请执行以下步骤:

1.  打印行号范围内的文本行，`M`至`N`:

```sh
        $ awk 'NR==M, NR==N' filename

```

Awk 可以从`stdin`读取:

```sh
        $ cat filename | awk 'NR==M, NR==N'

```

2.  将`M`和`N`替换为数字:

```sh
        $ seq 100 | awk 'NR==4,NR==6' 
 4 
 5 
 6

```

3.  打印 a `start_pattern`和`end_pattern`之间的文本行:

```sh
        $ awk '/start_pattern/, /end _pattern/' filename

```

考虑这个例子:

```sh
        $ cat section.txt 
 line with pattern1 
 line with pattern2 
 line with pattern3 
 line end with pattern4 
 line with pattern5 

 $ awk '/pa.*3/, /end/' section.txt 
 line with pattern3 
 line end with pattern4

```

`awk`中使用的模式是正则表达式。

# 请参见

*   本章中的*使用 awk 进行高级文本处理*配方解释了`awk`命令

# 以相反的顺序打印行

这个方法看起来可能没什么用，但是可以用来模拟 Bash 中的堆栈数据结构。

# 准备好

最简单的方法是使用`tac`命令(cat 的反义词)。任务也可以用`awk`完成。

# 怎么做...

我们将首先看看如何使用`tac`来做到这一点。

1.  `tac`的语法如下:

```sh
        tac file1 file2 ...

```

`tac`命令也可以从`stdin`读取:

```sh
        $ seq 5 | tac
 5 
 4 
 3 
 2 
 1

```

`tac`的默认行分隔符是`\n`。-s 选项将重新定义这一点:

```sh
        $ echo "1,2" | tac -s ,
 2
 1

```

2.  该`awk`脚本将以相反的顺序打印行:

```sh
        seq 9 | \
          awk '{ lifo[NR]=$0 } \
            END { for(lno=NR;lno>-1;lno--) { print lifo[lno]; }
                }'

```

`\`在 shell 脚本中是用来将一个单行命令序列拆分成多行的。

# 它是如何工作的...

`awk`脚本使用行号作为索引将每一行存储到关联数组中(`NR`返回行号)。读完所有行后，`awk`执行`END`块。`NR`变量由`awk`维护。它保存当前行号。当`awk`开始结束块时，`NR`是行数。使用`{ }`块中的`lno=NR`从最后一个行号迭代到`0`，以逆序打印行。

# 从文本中解析电子邮件地址和网址

解析电子邮件地址和 URL 等元素是一项常见的任务。正则表达式使找到这些模式变得容易。

# 怎么做...

匹配电子邮件地址的正则表达式模式如下:

```sh
    [A-Za-z0-9._]+@[A-Za-z0-9.]+\.[a-zA-Z]{2,4} 

```

考虑以下示例:

```sh
    $ cat url_email.txt 
 this is a line of text contains,<email> #slynux@slynux.com.    
    </email> and email address, blog "http://www.google.com",    
    test@yahoo.com dfdfdfdddfdf;cool.hacks@gmail.com<br />
 <a href="http://code.google.com"><h1>Heading</h1>

```

因为我们使用的是扩展正则表达式(例如`+`)，所以我们应该使用`egrep`:

```sh
    $ egrep -o '[A-Za-z0-9._]+@[A-Za-z0-9.]+\.[a-zA-Z]{2,4}'    
    url_email.txt
 slynux@slynux.com 
 test@yahoo.com 
 cool.hacks@gmail.com

```

HTTP 网址的`egrep`正则表达式模式如下:

```sh
    http://[a-zA-Z0-9\-\.]+\.[a-zA-Z]{2,4}

```

考虑这个例子:

```sh
    $ egrep -o "http://[a-zA-Z0-9.]+\.[a-zA-Z]{2,3}" url_email.txt 
 http://www.google.com 
 http://code.google.com

```

# 它是如何工作的...

正则表达式很容易逐部分设计。在电子邮件正则表达式中，我们都知道电子邮件地址采用`name@domain.some_2-4_letter_suffix`形式。用 regex 语言编写这个模式将如下所示:

```sh
[A-Za-z0-9.]+@[A-Za-z0-9.]+\.[a-zA-Z]{2,4} 

```

`[A-Za-z0-9.]+`表示我们在`[]`块中需要一个或多个字符(`+`表示至少一个，也许更多)。该字符串后面是一个`@`字符。接下来，我们将看到域名，一串字母或数字，一个句点，然后是 2-4 个字母。`[A-Za-z0-9]+`模式定义了一个字母数字字符串。`\.`模式意味着必须出现一个文字周期。`[a-zA-Z]{2,4}`模式定义 2、3 或 4 个字母。

HTTP URL 类似于电子邮件，但我们不需要电子邮件正则表达式的`name@`匹配部分:

```sh
http://[a-zA-Z0-9.]+\.[a-zA-Z]{2,3} 

```

# 请参见

*   本章中的*使用 sed 执行文本替换*方法解释了`sed`命令
*   本章中的*使用正则表达式*食谱解释了如何使用正则表达式

# 删除文件中包含单词的句子

使用正则表达式删除包含特定单词的句子是一项简单的任务。这个食谱展示了解决类似问题的技巧。

# 准备好

`sed`是进行替换的最佳工具。本食谱使用`sed`将匹配的句子替换为空白。

# 怎么做...

让我们创建一个包含一些文本的文件来执行替换。考虑这个例子:

```sh
    $ cat sentence.txt 
 Linux refers to the family of Unix-like computer operating systems   
    that use the Linux kernel. Linux can be installed on a wide variety   
    of computer hardware, ranging from mobile phones, tablet computers   
    and video game consoles, to mainframes and supercomputers. Linux is 
    predominantly known for its use in servers.

```

要删除包含单词`mobile phones`的句子，请使用以下`sed`表达式:

```sh
    $ sed 's/ [^.]*mobile phones[^.]*\.//g' sentence.txt
 Linux refers to the family of Unix-like computer operating systems   
    that use the Linux kernel. Linux is predominantly known for its use   
    in servers.

```

This recipe assumes that no sentence spans more than one line, for example, a sentence should always begin and end on the same line in the text.

# 它是如何工作的...

`sed`正则表达式`'s/ [^.]*mobile phones[^.]*\.//g'`具有`'s/substitution_pattern/replacement_string/g`格式。它用替换字符串替换每次出现的`substitution_pattern`。

替代模式是句子的正则表达式。每句话以空格开头，以`.`结尾。正则表达式必须与`"space" some text MATCH_STRING some text "dot"`格式的文本匹配。除了作为分隔符的“点”之外，句子可以包含任何字符。`[^.]`模式匹配除句点`.`之外的任何字符。`*`模式定义了任意数量的字符。`mobile phones`文本匹配字符串位于非句点字符的模式之间。每一个匹配的句子都被`//`代替(无)。

# 请参见

*   本章中的*使用 sed 执行文本替换*方法解释了`sed`命令
*   本章中的*使用正则表达式*食谱解释了如何使用正则表达式

# 用目录中所有文件的文本替换模式

我们经常需要在目录中的每个文件中用新的文本替换特定的文本。一个例子是在网站的源目录中到处改变一个共同的 URI。

# 怎么做...

我们可以使用`find`定位要修改文本的文件。我们可以用`sed`来做实际的替换。

要将所有`.cpp`文件中的`Copyright`文本替换为`Copyleft`单词，请使用以下命令:

```sh
 find . -name *.cpp -print0 | \
        xargs -I{} -0 sed -i 's/Copyright/Copyleft/g' {}

```

# 它是如何工作的...

我们在当前目录(`.`)上使用`find`来查找带有`.cpp`后缀的文件。find 命令使用- `print0`打印空的文件列表(当文件名中有空格时使用`-print0`)。我们将列表传送到`xargs`，T5 将文件名传送到`sed`，T6 进行修改。

# 还有更多...

如果您还记得，`find`有一个`-exec`选项，可用于对符合搜索条件的每个文件运行命令。我们可以使用此选项来达到相同的效果，或者用新的文本替换文本:

```sh
    $ find . -name *.cpp -exec sed -i 's/Copyright/Copyleft/g' \{\} \;

```

或者:

```sh
    $ find . -name *.cpp -exec sed -i 's/Copyright/Copyleft/g' \{\} \+

```

这些命令执行相同的功能，但是第一个表单将为每个文件调用`sed`一次，而第二个表单将组合多个文件名并将它们一起传递给`sed`。

# 文本切片和参数操作

这个食谱介绍了一些简单的文本替换技术和 Bash 中可用的参数扩展快捷键。一些简单的技术可以帮助避免编写多行代码。

# 怎么做...

让我们进入任务。

替换变量中的一些文本:

```sh
    $ var="This is a line of text"
 $ echo ${var/line/REPLACED}
 This is a REPLACED of text"

```

`line`字替换为`REPLACED`。

我们可以使用以下语法，通过指定开始位置和字符串长度来生成子字符串:

```sh
    ${variable_name:start_position:length}

```

从第五个字符开始打印:

```sh
    $ string=abcdefghijklmnopqrstuvwxyz
 $ echo ${string:4}
 efghijklmnopqrstuvwxyz

```

从第五个字符开始打印八个字符:

```sh
    $ echo ${string:4:8}
 efghijkl

```

字符串中的第一个字符位于位置`0`。我们可以从最后一个字母算起`-1`。当`-1`在括号内时，`(-1)`是最后一个字母的索引:

```sh
    echo ${string:(-1)}
 z
 $ echo ${string:(-2):2}
 yz

```

# 请参见

*   本章中的*使用 sed 执行文本替换*方法解释了其他字符操作技巧