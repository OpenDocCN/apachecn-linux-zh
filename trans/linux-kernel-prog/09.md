# 九、面向模块作者的内核内存分配——第二部分

前一章讲述了基础知识(还有更多！)通过内核中的页面(BSA)和平板分配器使用可用的 API 进行内存分配。在这一章中，我们将深入探讨这个大而有趣的话题。我们介绍了自定义平板缓存的创建，`vmalloc`接口，非常重要的是，考虑到丰富的选择，在何种情况下使用哪些 API。关于可怕的**内存不足** ( **OOM** )杀手的内部内核细节，并要求分页帮助完成这些重要的主题。

当使用内核模块，尤其是设备驱动程序时，这些领域往往是需要理解的关键方面之一。一个 Linux 系统项目突然崩溃，控制台上只有一条`Killed`消息，需要一些解释，是的！？OOM 杀手是幕后黑手...

简而言之，本章涵盖了以下主要方面:

*   创建自定义板缓存
*   在板层调试
*   理解和使用内核 vmalloc()
*   内核中的内存分配–什么时候使用哪些 API
*   活着 OOM 杀手

# 技术要求

我假设您已经完成了[第 1 章](01.html)、*内核工作区设置*，并且已经适当地准备了一个运行 Ubuntu 18.04 LTS(或更高版本的稳定版本)的来宾 VM，并且安装了所有需要的软件包。如果没有，我强烈建议你先做这个。

还有，这一章的最后一节有没有故意运行一个*非常*内存密集型的 app 如此密集，内核会采取一些激烈的行动！显然，我强烈建议您在一个安全、隔离的系统上尝试这样的东西，最好是一个 Linux 测试虚拟机(上面没有重要数据)。

为了充分利用这本书，我强烈建议您首先设置工作区
环境，包括克隆这本书的 GitHub 代码存储库，并以动手的方式进行处理。GitHub 资源库可以在[https://github.com/PacktPublishing/Linux-Kernel-Programming](https://github.com/PacktPublishing/Linux-Kernel-Programming)找到。

# 创建自定义板缓存

正如上一章详细解释的，平板缓存背后的一个关键设计概念是对象缓存的强大思想。通过缓存经常使用的对象(实际上是数据结构)，性能得到了提升。所以，想想看:如果我们正在编写一个驱动程序，并且在那个驱动程序中，某个数据结构(一个对象)被频繁地分配和释放，会怎么样？通常，我们会使用通常的`kzalloc()`(或`kmalloc()`)后跟`kfree()`API 来分配和释放这个对象。不过好消息是:Linux 内核充分地向我们展示了作为模块作者的 slab 层 API，允许我们创建自己的定制 slab 缓存。在本节中，您将了解如何利用这一强大的功能。

## 在内核模块中创建和使用定制的平板缓存

在本节中，我们将创建、使用并随后销毁一个自定义的 slab 缓存。大体上，我们将执行以下步骤:

1.  使用`kmem_cache_create()`应用编程接口创建给定大小的自定义切片缓存。这通常作为内核模块初始化代码路径的一部分来完成(或者在驱动程序中的探测方法中)。
2.  使用平板缓存。在这里，我们将执行以下操作:
    1.  发出`kmem_cache_alloc()`应用编程接口，在您的板缓存中分配自定义对象的单个实例。
    2.  使用对象。
    3.  用`kmem_cache_free()` API 将其释放回缓存。

3.  使用`kmem_cache_destroy()`完成后，销毁自定义平板缓存。这通常作为内核模块清理代码路径的一部分来完成(或者在驱动程序中的移除/分离/断开方法中)。

让我们详细探讨一下这些 API。我们从创建一个自定义(平板)缓存开始。

### 创建自定义板缓存

首先，当然，让我们学习如何创建自定义平板缓存。`kmem_cache_create()`内核 API 的签名如下:

```sh
#include <linux/slab.h>
struct kmem_cache *kmem_cache_create(const char *name, unsigned int size,  
           unsigned int align, slab_flags_t flags, void (*ctor)(void *));
```

第一个参数是缓存的名称，这将由`proc`(以及`proc`上的其他包装实用程序，如`vmstat(8)`、`slabtop(1)`等)显示。它通常与被缓存的数据结构或对象的名称相匹配(但不是必须的)。

第二个参数`size`实际上是关键参数——它是新缓存中每个对象的字节大小。基于这个对象大小(使用最佳匹配算法)，内核的平板层构建了一个对象缓存。由于以下三个原因，缓存中每个对象的实际大小将(稍微)大于请求的大小:

*   第一，我们总能提供比所要求的内存更多的内存，但绝不会少。
*   第二，需要一些空间来存放元数据(内务信息)。
*   第三，内核在提供所需大小的缓存方面受到限制。它使用最接近匹配大小的内存(回想一下第 8 章、*模块作者的内核内存分配–第 1 部分*，在*使用 slab 分配器时的注意事项*部分，我们清楚地看到更多(有时很多！)实际上可以使用内存)。

Recall from [Chapter 8](08.html), *Kernel Memory Allocation for Module Authors – Part 1*, that the `ksize()` API can be used to query the actual size of the allocated object. There is another API with which we can query the size of the individual objects within the new slab cache:
`unsigned int kmem_cache_size(struct kmem_cache *s);`. You shall see this being used shortly.

第三个参数`align`是缓存内对象所需的*对齐*。如果不重要，就传为`0`。然而，通常有非常特殊的对齐要求，例如，确保对象与机器上的一个字的大小对齐(32 或 64 位)。为此，将该值作为`sizeof(long)`传递(该参数的单位是字节，而不是位)。

第四个参数`flags`可以是`0`(意味着没有特殊行为)，也可以是以下标志值的按位或运算符。为清晰起见，我们直接从源文件`mm/slab_common.c`中的注释中复制以下标志的信息:

```sh
// mm/slab_common.c
[...]
 * The flags are
 *
 * %SLAB_POISON - Poison the slab with a known test pattern (a5a5a5a5)
 * to catch references to uninitialized memory.
 *
 * %SLAB_RED_ZONE - Insert `Red` zones around the allocated memory to check
 * for buffer overruns.
 *
 * %SLAB_HWCACHE_ALIGN - Align the objects in this cache to a hardware
 * cacheline. This can be beneficial if you're counting cycles as closely
 * as davem.
[...]
```

让我们快速查看旗帜:

*   第一个标志`SLAB_POISON`提供了片中毒，即将高速缓冲存储器初始化为一个先前已知的值(`0xa5a5a5a5`)。这样做可以在调试情况下有所帮助。
*   第二个标志`SLAB_RED_ZONE`很有趣，它在分配的缓冲区周围插入红色区域(类似于保护页)。这是检查缓冲区溢出错误的常用方法。它几乎总是在调试环境中使用(通常是在开发过程中)。

*   第三个可能的标志`SLAB_HWCACHE_ALIGN`非常常用，实际上是为了性能而推荐的。它保证所有高速缓存对象都与硬件(中央处理器)高速缓存行大小一致。这正是通过流行的`k[m|z]alloc()`应用编程接口分配的内存与硬件(中央处理器)缓存行对齐的方式。

最后，`kmem_cache_create()`的第五个参数也很有意思:一个函数指针，`void (*ctor)(void *);`。它被建模为构造函数(如面向对象和面向对象语言)。它方便地允许您在分配时从自定义板缓存中初始化板对象！作为内核中这个功能的一个例子，请参见名为`integrity` 的 **Linux 安全模块** ( **LSM** )的代码:

```sh
 security/integrity/iint.c:integrity_iintcache_init()
```

它调用以下内容:

```sh
iint_cache = kmem_cache_create("iint_cache", sizeof(struct integrity_iint_cache),
 0, SLAB_PANIC, init_once);
```

`init_once()`函数初始化缓存的对象实例(刚刚分配的)。请记住，每当此缓存分配新页面时，都会调用构造函数。

Though it may seem counter-intuitive, the fact is that the modern Linux kernel is quite object-oriented in design terms. The code, of course, is mostly plain old C, a traditional procedural language. Nevertheless, a vast number of architecture implementations within the kernel (the driver model being a big one) are quite object-oriented in design: method dispatch via virtual function pointer tables - the strategy design pattern, and so on. See a two-part article on LWN depicting this in some detail here: *Object-oriented design patterns in the kernel, part 1, June 2011* ([https://lwn.net/Articles/444910/](https://lwn.net/Articles/444910/)).

`kmem_cache_create()`应用编程接口的返回值是一个指针，成功时指向新创建的自定义平板缓存，失败时指向`NULL`。这个指针通常是全局的，因为您需要访问它才能从它实际分配对象(我们的下一步)。

重要的是要理解`kmem_cache_create()` API 只能从流程上下文中调用。相当多的内核代码(包括许多驱动程序)创建并使用自己的定制平板缓存。例如，在 5.4.0 Linux 内核中，调用了超过 350 个这样的应用编程接口实例。

好了，现在您有了一个可用的自定义(slab)缓存，您到底如何使用它来分配内存对象？继续读下去；下一节将详细介绍这一点。

### 使用新的片缓存的内存

好的，我们创建了一个定制的平板缓存。要使用它，必须发布`kmem_cache_alloc()` API。它的工作是:给定指向一个平板缓存的指针(您刚刚创建的)，它在该平板缓存上分配一个对象的单个实例(事实上，这就是`k[m|z]alloc()`API 在幕后的工作方式)。它的签名如下(当然，记住始终包括所有基于平板的 API 的`<linux/slab.h>`头):

```sh
void *kmem_cache_alloc(struct kmem_cache *s, gfp_t gfpflags);
```

让我们看看它的参数:

*   `kmem_cache_alloc()`的第一个参数是指向我们在上一步中创建的(自定义)缓存的指针(指针是来自`kmem_cache_create()`应用编程接口的返回值)。
*   第二个参数是通常要传递的 GFP 标志(记住基本规则:使用`GFP_KERNEL`进行正常的进程上下文分配，否则`GFP_ATOMIC`如果在任何种类的原子或中断上下文中)。

和现在熟悉的`k[m|z]alloc()`API 一样，返回值是指向新分配的内存块的指针——一个内核逻辑地址(当然是 KVA)。

使用新分配的内存对象，完成后，不要忘记使用以下命令释放它:

```sh
void kmem_cache_free(struct kmem_cache *, void *);
```

在此，请注意关于`kmem_cache_free()`应用编程接口的以下内容:

*   `kmem_cache_free()`的第一个参数还是指向您在上一步中创建的(自定义)板缓存的指针(来自`kmem_cache_create()`的返回值)。

*   第二个参数是指向你想要释放的内存对象的指针——你刚刚被分配了`kmem_cache_alloc()`的对象实例——从而让它返回到第一个参数指定的缓存！

类似于`k[z]free()`API，没有返回值。

### 销毁自定义缓存

完成后(通常在内核模块的清理或退出代码路径中，或您的驱动程序的`remove`方法中)，您必须销毁您之前使用以下行创建的自定义 slab 缓存:

```sh
void kmem_cache_destroy(struct kmem_cache *);
```

当然，该参数是指向您在上一步中创建的(自定义)缓存的指针(来自`kmem_cache_create()`应用编程接口的返回值)。

现在您已经理解了这个过程及其相关的 API，让我们开始使用一个内核模块，它创建自己的自定义 slab 缓存，使用它，然后销毁它。

## 定制平板——一个演示内核模块

是时候用一些代码弄脏我们的手了！让我们看一个使用前面的 API 来创建我们自己的自定义 slab 缓存的简单演示。像往常一样，我们在这里只显示相关代码。我强烈建议你克隆这本书的 GitHub 资源库，自己尝试一下！你可以在`ch9/slab_custom/slab_custom.c`找到这个文件的代码。

在我们的 init 代码路径中，我们首先调用以下函数来创建我们的自定义 slab 缓存:

```sh
// ch9/slab_custom/slab_custom.c
#define OURCACHENAME   "our_ctx"
/* Our 'demo' structure, that (we imagine) is often allocated and freed;
 * hence, we create a custom slab cache to hold pre-allocated 'instances'
 * of it... Its size: 328 bytes.
 */
struct myctx {
    u32 iarr[10];
    u64 uarr[10];
    char uname[128], passwd[16], config[64];
};
static struct kmem_cache *gctx_cachep; 
```

在前面的代码中，我们声明了一个(全局)指针(`gctx_cachep`)指向要创建的自定义 slab 缓存，它将保存对象；也就是我们虚构的经常被分配的数据结构，`myctx`。

在下面，请参见创建自定义板缓存的代码:

```sh
static int create_our_cache(void)
{
    int ret = 0;
    void *ctor_fn = NULL;

    if (use_ctor == 1)
        ctor_fn = our_ctor;
    pr_info("sizeof our ctx structure is %zu bytes\n"
            " using custom constructor routine? %s\n",
            sizeof(struct myctx), use_ctor==1?"yes":"no");

  /* Create a new slab cache:
   * kmem_cache_create(const char *name, unsigned int size, unsigned int 
      align, slab_flags_t flags, void (*ctor)(void *));  */
    gctx_cachep = kmem_cache_create(OURCACHENAME, // name of our cache
          sizeof(struct myctx), // (min) size of each object
          sizeof(long),         // alignment
          SLAB_POISON |         /* use slab poison values (explained soon) */
          SLAB_RED_ZONE |       /* good for catching buffer under|over-flow bugs */
          SLAB_HWCACHE_ALIGN,   /* good for performance */
          ctor_fn);             // ctor: here, on by default

  if (!gctx_cachep) {
        [...]
        if (IS_ERR(gctx_cachep))
            ret = PTR_ERR(gctx_cachep);
  }
  return ret;
}
```

嘿，这很有趣:注意我们的缓存创建 API 提供了一个构造函数来帮助初始化任何新分配的对象；这是:

```sh
/* The parameter is the pointer to the just allocated memory 'object' from
 * our custom slab cache; here, this is our 'constructor' routine; so, we
 * initialize our just allocated memory object.
 */
static void our_ctor(void *new)
{
    struct myctx *ctx = new;
    struct task_struct *p = current;

    /* TIP: to see how exactly we got here, insert this call:
     *  dump_stack();
     * (read it bottom-up ignoring call frames that begin with '?') */
    pr_info("in ctor: just alloced mem object is @ 0x%llx\n", ctx);

    memset(ctx, 0, sizeof(struct myctx));
    /* As a demo, we init the 'config' field of our structure to some
     * (arbitrary) 'accounting' values from our task_struct
     */
    snprintf(ctx->config, 6*sizeof(u64)+5, "%d.%d,%ld.%ld,%ld,%ld",
            p->tgid, p->pid,
            p->nvcsw, p->nivcsw, p->min_flt, p->maj_flt);
}
```

前面代码中的注释是不言自明的；一定要看看。构造器例程，如果设置(取决于我们的`use_ctor`模块参数的值；默认情况下是`1`，每当一个新的内存对象被分配到我们的缓存中时，就会被内核自动调用。

在初始化代码路径中，我们调用`use_our_cache()`函数。它通过`kmem_cache_alloc()`应用编程接口分配我们的`myctx`对象的一个实例，如果我们的自定义构造函数例程被启用，它就会运行，初始化该对象。然后，我们转储它的内存，以显示它确实被初始化为编码，完成后释放它(为简洁起见，我们将省略显示错误代码路径):

```sh
    obj = kmem_cache_alloc(gctx_cachep, GFP_KERNEL);
    pr_info("Our cache object size is %u bytes; ksize=%lu\n",
            kmem_cache_size(gctx_cachep), ksize(obj));
    print_hex_dump_bytes("obj: ", DUMP_PREFIX_OFFSET, obj, sizeof(struct myctx));
 kmem_cache_free(gctx_cachep, obj);
```

最后，在退出代码路径中，我们销毁我们的自定义 slab 缓存:

```sh
kmem_cache_destroy(gctx_cachep);
```

示例运行的以下输出帮助我们理解它是如何工作的。以下只是部分截图，显示了运行 Linux 5.4 内核的 x86_64 Ubuntu 18.04 LTS 客户机上的输出:

![](Images/ccea160f-99ee-4292-ad57-721968be31f8.png)

Figure 9.1 – Output of our slab_custom kernel module on an x86_64 VM

太好了。不过，请稍等，这里有几个要点需要注意:

*   由于默认情况下我们的构造函数例程是启用的(我们的`use_ctor`模块参数的值是`1`，所以每当内核层将新的对象实例分配给我们的新缓存时，它都会运行。这里，我们只执行了一个`kmem_cache_alloc()`，然而我们的构造函数例程已经运行了 21 次，这意味着内核的 slab 代码(pre)为我们全新的缓存分配了 21 个对象！当然，这个数字各不相同。
*   二、一些非常重要的注意事项！如前一张截图所示，每个对象的*大小*看似是 328 字节(这三个 API 都显示:`sizeof()`、`kmem_cache_size()`和`ksize()`)。然而，这又不是真的！内核分配的对象的实际大小更大；我们可以通过`vmstat(8)`看到这一点:

```sh
$ sudo vmstat -m | head -n1
Cache                       Num  Total  Size  Pages
$ sudo vmstat -m | grep our_ctx
our_ctx                       0     21   768     21
$ 
```

如前一段代码中突出显示的，每个分配对象的实际大小不是 328 字节，而是 768 字节(确切的数字各不相同；在一种情况下，我将其视为 448 字节)。正如我们之前看到的，这一点对你来说很重要，要意识到，并且确实要检查。我们在接下来的*调试板层*部分展示了另一种很容易检查的方法。

FYI, you can always check out the man page of `vmstat(8)` for the precise meaning of each column seen earlier.

我们将结束关于使用平板收缩器界面创建和使用自定义平板缓存的讨论。

## 了解平板收缩器

缓存对性能有好处。可视化从磁盘读取大文件的内容，而不是从内存读取其内容。毫无疑问，基于内存的输入输出要快得多！可以想象，Linux 内核利用了这些思想，因此维护了几个缓存——页面缓存、数据缓存、索引节点缓存、片缓存等等。这些缓存确实对性能有很大帮助，但是仔细想想，实际上并不是强制性要求。当内存压力达到很高的水平时(意味着使用的内存太多，空闲的内存太少)，Linux 内核拥有智能释放缓存的机制(也就是内存回收——这是一个持续的过程；内核线程(通常命名为`kswapd*`)回收内存，作为其内务处理的一部分；在*回收内存-内核内务处理任务和* *OOM* 一节中有更多相关内容。

就片层缓存而言，事实是一些内核子系统和驱动程序创建了它们自己的定制片层缓存，正如我们在本章前面所述。为了很好地集成并与内核协作，最佳实践要求您的自定义 slab 缓存代码应该注册一个 shrinker 接口。完成后，当内存压力变得足够大时，内核很可能会调用几个 slab shrinker 回调，这有望通过释放(收缩)slab 对象来缓解内存压力。

向内核注册收缩器函数的应用编程接口是`register_shrinker()`应用编程接口。它的单个参数(从 Linux 5.4 开始)是一个指向`shrinker`结构的指针。该结构包含(除其他内务处理成员外)两个回调例程:

*   第一个例程`count_objects()`，仅仅计算并返回将被释放的对象的数量(当它被实际调用时)。如果它返回`0`，这意味着现在无法确定可释放内存对象的数量，或者我们现在甚至不应该尝试释放任何对象。
*   只有当第一个回调例程返回非零值时，才会调用第二个例程`scan_objects()`；它是一个当被 slab 缓存层调用时，实际上释放或收缩有问题的 slab 缓存。它返回在此回收周期中释放的对象的实际数量，如果回收尝试无法进行(由于可能的死锁)，则返回`SHRINK_STOP`。

现在，我们将快速总结一下使用这个层进行内存(de)分配的利弊，从而结束对 slab 层的讨论，这对作为内核/驱动程序作者的您来说非常重要，您应该非常清楚这一点！

## 平板分配器-优点和缺点-总结

在这一节中，我们非常简要地总结了您现在已经学到的东西。这是为了让你快速查找和回忆这些关键点！

使用 slab 分配器(或 slab 缓存)API 来分配和释放内核内存的优点如下:

*   (非常)快(因为它使用预先缓存的内存对象)。
*   保证物理上连续的内存块。
*   创建缓存时使用`SLAB_HWCACHE_ALIGN`标志时，硬件(中央处理器)缓存行对齐内存得到保证。`kmalloc()`、`kzalloc()`等等都是如此。
*   您可以为特定(经常允许/释放)对象创建自己的自定义板缓存。

使用片分配器(或片缓存)API 的缺点如下:

*   一次只能分配有限的内存；通常，在大多数当前平台上，直接通过 slab 接口只有 8 KB，或者通过页面分配器间接达到 4 MB(当然，精确的上限取决于 arch)。
*   错误地使用`k[m|z]alloc()`API:请求太多内存，或者请求刚好超过阈值的内存大小(在[第 8 章](08.html)、*模块作者的内核内存分配–第 1 部分*中，在 kmalloc API 部分的*大小限制下详细讨论)，肯定会导致内部碎片(浪费)。它的设计只是为了真正针对常见情况进行优化——针对小于一页的分配。*

现在，让我们转到内核/驱动程序开发人员的另一个真正关键的方面——当内存分配/释放出现问题时进行有效的调试，尤其是在 slab 层。

# 在板层调试

不幸的是，内存损坏是 bug 的一个非常常见的根本原因。能够调试它们是一项关键技能。我们现在来看看解决这个问题的几种方法。在深入细节之前，请记住下面的讨论是关于平板层的 *SLUB* (未引用的分配器)实现的。这是大多数 Linux 安装的默认设置(我们在[第 8 章](08.html)、*模块作者的内核内存分配–第 1 部分*，在*内核*部分的“板层实现”下提到，当前的 Linux 内核有三个互斥的板层实现)。

此外，我们在这里的意图不是讨论关于内存调试的深入内核调试工具——这本身就是一个很大的主题，不幸的是超出了本书的范围。尽管如此，我还是要说，您最好熟悉已经提到的强大框架/工具，尤其是以下这些:

*   **KASAN** (即**内核地址杀毒软件**；可用于 x86_64 和 AArch64，4.x 内核及更高版本)
*   SLUB 调试技术(此处涉及)
*   `kmemleak`(虽然 KASAN 是高手)
*   `kmemcheck`(注意`kmemcheck`在 Linux 4.15 中被删除)

不要忘记在*进一步阅读*部分寻找这些链接。好了，让我们开始讨论一些有用的方法来帮助开发人员在 slab 层调试代码。

## 通过板坯中毒进行调试

一个非常有用的特征是所谓的石板中毒。术语*中毒*在这个上下文中意味着用某些签名字节或容易识别的模式戳内存。然而，使用这个的前提是`CONFIG_SLUB_DEBUG`内核配置选项打开。怎么能查？简单:

```sh
$ grep -w CONFIG_SLUB_DEBUG /boot/config-5.4.0-llkd01
CONFIG_SLUB_DEBUG=y
```

前面代码中看到的`=y`表示确实开启。现在(假设它已打开)如果您创建一个带有`SLAB_POISON`标志的平板缓存(我们在*创建自定义平板缓存*部分中介绍了平板缓存的创建)，那么，当内存被分配时，它总是被初始化为特殊值或内存模式`0x5a5a5a5a`–它被毒化了(这是有意的:十六进制值`0x5a`是 ASCII 字符`Z`代表零)！所以，想想看，如果你在内核诊断消息或转储中发现了这个值，也称为*哎呀，*很有可能这是一个(不幸的是非常典型的)未初始化内存错误或 **UMR** (简称**未初始化内存读取**)。

Why use the word *perhaps* in the preceding sentence? Well, simply because debugging deeply hidden bugs is a really difficult thing to do! The symptoms that might present themselves are not necessarily *the root cause* of the issue at hand. Thus, hapless developers are fairly often led down the proverbial garden path by various red herrings! The reality is that debugging is both an art and a science; deep knowledge of the ecosystem (here, the Linux kernel) goes a really long way in helping you effectively debug difficult situations.

如果`SLAB_POISON`标志未置位，未初始化的平板内存将被设置为`0x6b6b6b6b`内存模式(十六进制`0x6b`是 ASCII 字符`k`(见图 9.2))。类似地，当释放了 slab 缓存内存并且`CONFIG_SLUB_DEBUG`打开时，内核向其中写入相同的内存模式(`0x6b6b6b6b ; 'k'`)。这也非常有用，允许我们发现(内核认为的)未初始化或空闲的内存。

中毒值在`include/linux/poison.h`中定义如下:

```sh
/* ...and for poisoning */
#define POISON_INUSE    0x5a    /* for use-uninitialized poisoning */
#define POISON_FREE     0x6b    /* for use-after-free poisoning */
#define POISON_END      0xa5    /* end-byte of poisoning */
```

关于 SLUB 分配器的内核 SLUB 实现，我们来看看**如何以及何时**(具体情况由下面的`if`部分决定)*SLUB 中毒发生的概要视图，*及其类型如下伪代码所示:

```sh
if CONFIG_SLUB_DEBUG is enabled
   AND the SLAB_POISON flag is set
   AND there's no custom constructor function
   AND it's type-safe-by-RCU
```

然后板坯中毒发生如下:

*   初始化时，平板存储器设置为`POISON_INUSE (0x5a = ASCII 'Z')`；这里的代码是:`mm/slub.c:setup_page_debug()`。
*   在`mm/slub.c:init_object()`中初始化时，板对象被设置为`POISON_FREE (0x6b = ASCII 'k')`。
*   在`mm/slub.c:init_object()`中初始化时，板对象的最后一个字节被设置为`POISON_END (0xa5)`。

(因此，由于板层执行这些板内存初始化的方式，我们以值`0x6b` (ASCII `k`)作为刚刚分配的板内存的初始值结束)。请注意，要做到这一点，您不应该安装自定义构造函数。还有，你可以暂时忽略`it's-type-safe-by-RCU`指令；通常情况是这样的(也就是说，“被 RCU 保护的类型”是正确的；仅供参考，RCU(阅读副本更新)是一种先进的同步技术，超出了本书的范围)。从 SLUB 调试模式下运行时如何初始化 SLUB 可以看出，内存内容被有效初始化为`POISON_FREE (0x6b = ASCII 'k')`值。因此，如果这个值在释放内存后发生变化，内核可以检测到这一点并触发一个报告(通过 printk)。这当然是大家熟知的【免费后使用】 ( **UAF** )内存 bug 的一个案例！类似地，在红区区域之前或之后写入(这些区域实际上是保护区域，通常被初始化为`0xbb`)将触发写缓冲区不足/溢出错误，内核会报告该错误。有用！

### 尝试一下——引发 UAF 病毒

为了帮助您更好地理解这一点，我们将在本节中通过截图展示一个示例。执行以下步骤:

1.  首先，确保启用`CONFIG_SLUB_DEBUG`内核配置(应该设置为`y`；这通常是发行版内核的情况)
2.  接下来，引导系统，同时包含内核命令行`slub_debug=`指令(这开启了完全 SLUB 调试；或者您可以传递一个更细粒度的变量，如`slub_debug=FZPU`(参见这里的内核文档了解每个字段的解释:[https://www.kernel.org/doc/Documentation/vm/slub.txt](https://www.kernel.org/doc/Documentation/vm/slub.txt))；作为演示，在我的 Fedora 31 来宾 VM 上，我传递了如下内核命令行-这里重要的是，`slub_debug=FZPU`以粗体突出显示:

```sh
$ cat /proc/cmdline
BOOT_IMAGE=(hd0,msdos1)/vmlinuz-5.4.0-llkd01 root=/dev/mapper/fedora_localhost--live-root ro resume=/dev/mapper/fedora_localhost--live-swap rd.lvm.lv=fedora_localhost-live/root rd.lvm.lv=fedora_localhost-live/swap rhgb slub_debug=FZPU 3
```

(关于`slub_debug`参数的更多细节在下一节*引导和运行时的 SLUB 调试选项*中)。

3.  编写一个内核模块，创建一个新的自定义 slab 缓存(当然有内存错误！).确保没有指定构造函数(示例代码在这里:`ch9/poison_test`；我将把它作为一个练习留给你浏览代码并测试它)。

4.  我们在这里尝试一下:通过`kmem_cache_alloc()`(或等效物)分配一些平板内存。下面是一个截图(图 9.2)，显示了分配的内存，以及快速`memset()`将前 16 个字节设置为`z` ( `0x7a`)后的相同区域:

![](Images/24c04df3-283c-44c7-8e05-8cc9cee15bb7.png)

Figure 9.2 – Slab memory after allocation and memset() of the first 16 bytes

5.  现在，为了虫子！在清理方法中，我们释放分配的板，然后通过尝试对其执行另一个`memset()`*来重用它，从而触发 UAF 错误*。同样，我们通过另一个截图显示了内核日志(图 9.3):

![](Images/8dc2f695-050a-49b6-9d8b-f2e32194ca00.png)

Figure 9.3 – The kernel reporting the UAF bug!

请注意内核如何将此(上图中红色的第一个文本)报告为`Poison overwritten`错误。事实确实如此:我们用`0x21` 覆盖了`0x6b`毒值(相当有意地是 ASCII 字符`!`)。在释放一个来自 slab 缓存的缓冲区后，如果内核在有效负载中检测到除中毒值(`POISON_FREE = 0x6b = ASCII 'k'`)以外的任何值，它就会触发错误。(还要注意，红区保护区被初始化为值`0xbb`)。

下一节提供了 SLUB 层调试选项的更多细节。

## 引导和运行时 SLUB 调试选项

当使用 SLUB 实现(默认)时，调试内核级的 slab 问题非常强大，因为内核有完整的调试信息可用。只是默认关闭了。我们可以通过各种方式(视口)打开和查看平板调试级信息；丰富的细节是可用的！这样做的一些方法包括:

*   在内核命令行上传递`slub_debug=`字符串(当然是通过引导加载程序)。这将开启完全 SLUB 内核级调试。
*   可以通过传递给`slub_debug=`字符串的选项来微调要查看的具体调试信息(在`=`后不传递任何内容意味着所有 SLUB 调试选项都已启用)；例如，通过`slub_debug=FZ`打开以下选项:

    *   `F`:健全性检查开启(启用`SLAB_DEBUG_CONSISTENCY_CHECKS`)；请注意，打开此选项会降低系统速度。
    *   `Z`:红色分区。
*   即使 SLUB 调试功能没有通过内核命令行打开，我们仍然可以通过将`1`(作为根)写入`/sys/kernel/slab/<slab-name>`下合适的伪文件来启用/禁用它:
    *   回想一下我们之前的演示内核模块(`ch9/slab_custom`)；加载到内核后，看到每个分配对象的理论和实际大小，如下所示:

```sh
$ sudo cat /sys/kernel/slab/our_ctx/object_size  /sys/kernel/slab/our_ctx/slab_size 
328 768
```

```sh
$ sudo cat /sys/kernel/slab/our_ctx/ctor
our_ctor+0x0/0xe1 [slab_custom]
```

你可以在这里找到相当多的相关细节(非常有用！)此处文档:*SLUB*([https://www.kernel.org/doc/Documentation/vm/slub.txt](https://www.kernel.org/doc/Documentation/vm/slub.txt))短用户指南。

此外，在内核源代码树的`tools/vm`文件夹下快速浏览一下，会发现一些有趣的程序(`slabinfo.c`是这里的相关程序)和一个生成图形的脚本(通过`gnuplot(1)`)。上一段提到的文档也提供了关于图生成的使用细节。

As an important aside, the kernel has an enormous (and useful!) number of *kernel parameters* that can be optionally passed to it at boot (via the bootloader). See the complete list here in the documentation: *The kernel’s command-line parameters* ([https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html](https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html)).

好了，这(最后)结束了我们对 slab 分配器的介绍(从上一章继续到这一章)。您已经了解到它分层在页面分配器之上，并解决了两个关键问题:一是它允许内核创建和维护对象缓存，以便可以非常高效地执行一些重要内核数据结构的分配和释放；第二，这包括通用内存缓存，允许您以非常少的开销分配少量的内存(页面的片段)(不像二进制伙伴系统分配器)。事实很简单:slab APIs 是驱动程序真正常用的；不仅如此，现代驱动程序作者利用资源管理的`devm_k{m,z}alloc()`API；我们鼓励你这样做。不过要小心:我们详细检查了实际分配的内存比您想象的多多少(使用`ksize()`来计算到底有多少)。您还学习了如何创建自定义的平板缓存，更重要的是，如何在平板层进行调试。

现在让我们了解一下`vmalloc()` API 是什么，如何以及何时使用它进行内核内存分配。

# 理解和使用内核 vmalloc()

正如我们在上一章中了解到的，内核中最终只有一个内存分配引擎——页面(或伙伴系统)分配器。顶层是平板分配器(或平板缓存)机器。此外，在内核的地址空间中还有另一个完全虚拟的地址空间，从这里可以随意分配虚拟页面——这被称为内核`vmalloc`区域。

当然，最终，一旦一个虚拟页面被实际使用(通过进程或线程被内核或用户空间中的某个东西使用)——它所映射到的物理页面框架实际上是通过页面分配器分配的(这最终也适用于所有用户空间内存框架，尽管是以间接的方式；稍后在*需求分页和 OOM* 部分会有更多相关内容。

在内核段或 VAS 中(我们在[第 7 章](07.html)、*内存管理内部组件-要点、*中的*检查内核段*部分中详细介绍了这一切)，是从`VMALLOC_START`延伸到`VMALLOC_END-1`的 *vmalloc* 地址空间。首先，它是一个完全虚拟的区域，也就是说，它的虚拟页面最初没有映射到任何物理页面框架。

For a quick refresher, revisit the diagram of the user and kernel segments – in effect, the complete VAS – by re-examining *Figure 7.12*. You will find this in [Chapter 7](07.html), *Memory Management Internals - Essentials,* under the *Trying it out – viewing kernel segment details* section.

在本书中，我们的目的不是要深入研究内核`vmalloc`区域的血淋淋的内部细节。相反，我们为您(模块或驱动程序作者)提供了足够的信息，以便在运行时使用这个区域来分配虚拟内存。

## 学习使用 vmalloc 系列应用编程接口

您可以使用`vmalloc()`应用编程接口从内核的`vmalloc`区域分配虚拟内存(当然是在内核空间):

```sh
#include <linux/vmalloc.h>
void *vmalloc(unsigned long size);
```

vmalloc 上需要注意的一些要点:

*   `vmalloc()` API 为调用者分配连续的虚拟内存。不能保证分配的区域在物理上是连续的；它可能是也可能不是(事实上，分配越大，它在物理上连续的可能性就越小)。
*   理论上，分配的虚拟页面的内容是随机的；实际上，它似乎是依赖于 arch 的(至少 x86_64 似乎将内存区域清零)；当然，(冒着轻微性能下降的风险)建议您使用`vzalloc()`包装器 API 来确保内存清零

*   `vmalloc()`(和朋友)应用编程接口只能从进程上下文中调用(因为它可能会导致调用者休眠)。
*   `vmalloc()`的返回值是成功时的 KVA(在内核 vmalloc 区域内)或失败时的`NULL`。
*   刚刚分配的 vmalloc 内存的起点保证在页面边界上(换句话说，它总是页面对齐的)。
*   实际分配的内存(来自页面分配器)可能比请求的内存大(同样，它在内部分配足够的页面来覆盖请求的大小)

你会觉得这个 API 看起来和熟悉的用户空间`malloc(3)`非常相似。乍看之下确实如此，当然，除了这是一个内核空间分配(同样，请记住这两者之间没有直接的关联)。

既然如此，`vmalloc()`对我们模块或者驱动作者有什么帮助？当您需要一个比 slab APIs(即`k{m|z}alloc()`和 friends)所能提供的大小更大的虚拟连续缓冲区时(回想一下，ARM 和 x86[_64]上的单次分配通常为 4 MB)，那么您应该使用`vmalloc`！

仅供参考，内核使用`vmalloc()`有各种原因，其中一些原因如下:

*   当内核模块加载到内核中时(在`kernel/module.c:load_module()`中)，为内核模块的(静态)内存分配空间。
*   如果定义了`CONFIG_VMAP_STACK`，则`vmalloc()`用于分配每个线程的内核模式堆栈(在`kernel/fork.c:alloc_thread_stack_node()`中)。
*   在内部，当服务于一个名为`ioremap()`的操作时。
*   Linux 套接字过滤器(bpf)内的代码路径，等等。

为了方便起见，内核提供了`vzalloc()`包装器 API(类似于`kzalloc()`)来分配和清空内存区域——这无疑是一个很好的编码实践，但可能会稍微损害时间关键的代码路径:

```sh
void *vzalloc(unsigned long size);
```

使用完分配的虚拟缓冲区后，您当然必须释放它:

```sh
void vfree(const void *addr);
```

不出所料，`vfree()`的参数是来自`v[m|z]alloc()`的返回地址(甚至是这些调用的底层`__vmalloc()`应用编程接口)。通过`NULL`使其无害返回。

在下面的代码片段中，我们展示了一些来自`ch9/vmalloc_demo`内核模块的示例代码。像往常一样，我敦促您克隆这本书的 GitHub 存储库，并自己尝试一下(为简洁起见，我们不会在下面的代码片段中显示全部源代码；我们展示了由模块的 init 代码调用的主`vmalloc_try()`函数)。

这是代码的第一部分。如果`vmalloc()`应用编程接口偶然失败，我们通过内核的`pr_warn()`助手生成一个警告。请注意以下`pr_warn()`助手并不是真正需要的；由于这里迂腐，我们保留它...其余情况同上，如下所示:

```sh
// ch9/vmalloc_demo/vmalloc_demo.c
#define pr_fmt(fmt) "%s:%s(): " fmt, KBUILD_MODNAME, __func__
[...]
#define KVN_MIN_BYTES     16
#define DISP_BYTES        16
static void *vptr_rndm, *vptr_init, *kv, *kvarr, *vrx;

static int vmalloc_try(void)
{
    if (!(vptr_rndm = vmalloc(10000))) {
        pr_warn("vmalloc failed\n");
        goto err_out1;
    }
    pr_info("1\. vmalloc(): vptr_rndm = 0x%pK (actual=0x%px)\n", 
            vptr_rndm, vptr_rndm);
    print_hex_dump_bytes(" content: ", DUMP_PREFIX_NONE, vptr_rndm,     
                DISP_BYTES);
```

前面代码块中的`vmalloc()` API 分配了一个(至少)10，000 字节的连续内核虚拟内存区域；实际上，内存是页面对齐的！我们使用内核的`print_hex_dump_bytes()`助手例程来转储这个区域的前 16 个字节。

继续看下面的代码，使用`vzalloc()` API 再次分配另一个(至少)10，000 字节的连续内核虚拟内存区域(尽管它是页面对齐的内存)；这一次，内存内容设置为零:

```sh
    /* 2\. vzalloc(); memory contents are set to zeroes */
    if (!(vptr_init = vzalloc(10000))) {
        pr_warn("%s: vzalloc failed\n", OURMODNAME);
        goto err_out2;
    }
    pr_info("2\. vzalloc(): vptr_init = 0x%pK (actual=0x%px)\n",
            vptr_init, (TYPECST)vptr_init);
    print_hex_dump_bytes(" content: ", DUMP_PREFIX_NONE, vptr_init, 
                DISP_BYTES);
```

关于以下代码有几点:第一，注意使用`goto`的错误处理(在多个`goto`实例的目标标签处，我们使用`vfree()`根据需要释放先前分配的内存缓冲区)，典型的内核代码。二、目前请忽略`kvmalloc()`、`kcalloc()`和`__vmalloc()`朋友套路；我们将在*vmalloc 之友()*部分介绍它们:

```sh
  /* 3\. kvmalloc(): allocate 'kvn' bytes with the kvmalloc(); if kvn is
   * large (enough), this will become a vmalloc() under the hood, else
   * it falls back to a kmalloc() */
    if (!(kv = kvmalloc(kvn, GFP_KERNEL))) {
        pr_warn("kvmalloc failed\n");
        goto err_out3;
    }
    [...]

    /* 4\. kcalloc(): allocate an array of 1000 64-bit quantities and zero
     * out the memory */
    if (!(kvarr = kcalloc(1000, sizeof(u64), GFP_KERNEL))) {
        pr_warn("kvmalloc_array failed\n");
        goto err_out4;
    }
    [...]
    /* 5\. __vmalloc(): <seen later> */
    [...]
    return 0;
err_out5:
  vfree(kvarr);
err_out4:
    vfree(kv);
err_out3:
    vfree(vptr_init);
err_out2:
    vfree(vptr_rndm);
err_out1:
    return -ENOMEM;
}
```

在内核模块的清理代码路径中，我们当然会释放分配的内存区域:

```sh
static void __exit vmalloc_demo_exit(void)
{
    vfree(vrx);
    kvfree(kvarr);
    kvfree(kv);
    vfree(vptr_init);
    vfree(vptr_rndm);
    pr_info("removed\n");
}
```

我们将让您来尝试和验证这个演示内核模块。

现在，让我们简单探究另一个真正关键的方面——一个用户空间`malloc()`，或者一个内核空间`vmalloc()`，内存分配到底是如何变成物理内存的？一定要继续读下去，找到答案！

## 关于内存分配和按需分页的简要说明

在不深入研究`vmalloc()`(或用户空间`malloc()`)内部工作的细节的情况下，我们将讨论一些关键点，像您这样有能力的内核/驱动程序开发人员必须了解这些点。

首先，虚拟内存必须在某个时候(使用时)变成物理内存。这种物理内存是通过唯一的方式在内核中分配的——通过页面(或伙伴系统)分配器。这是如何发生的有点间接，简单解释如下。

使用`vmalloc()`时，需要理解一个关键点:`vmalloc()`只导致虚拟内存页面被分配(它们只是被操作系统标记为保留)。此时实际上没有分配物理内存。与虚拟页面相对应的实际物理页面框架只有在以任何方式(例如读取、写入或执行)触摸这些虚拟页面时才会被分配，也是逐页分配。这种在程序或进程实际尝试使用物理内存之前不实际分配物理内存的关键原则被各种名称引用–*需求分页、惰性分配、按需分配*等等。事实上，文档陈述了这个事实:

"vmalloc space is lazily synchronized into the different PML4/PML5 pages of the processes using the page fault handler ..."

清楚地了解内存分配如何真正为`vmalloc()`和朋友工作是很有启发性的，事实上，对于用户空间 glibc `malloc()`系列例程来说——这都是通过按需分页实现的！也就是说，这些 API 的成功返回在*物理*内存分配方面真的没有任何意义。当`vmalloc()`或者实际上是用户空间`malloc()`返回成功时，到目前为止真正发生的只是保留了一个虚拟内存区域；实际上还没有分配物理内存！*物理页面框架的实际分配仅在访问虚拟页面时以每页为基础发生(对于任何事情:读取、写入或执行)*。

但是这是如何在内部发生的呢？简单来说，答案就是:每当内核或者进程访问一个虚拟地址时，这个虚拟地址都是由**内存管理单元** ( **MMU** )来解释的，这个内存管理单元是 CPU 内核上硅片的一部分。MMU 的**翻译后备缓冲区** ( **TLB** ) *(* 我们没有闲心在这里深究这一切，抱歉！ *)* 现在将被检查是否有*命中*。如果是，内存转换(虚拟到物理地址)已经可用；如果没有，我们有一个 TLB 小姐。如果是，MMU 现在将*遍历*进程的分页表，有效地转换虚拟地址，从而获得*物理地址。*它把这个放到地址总线上，CPU 继续它的快乐之路。

但是，考虑一下，如果 MMU 找不到匹配的物理地址怎么办？出现这种情况的原因有很多，其中之一就是我们这里的情况——我们(还)没有*的*物理页面框架，只有一个虚拟页面。在这一点上，MMU 基本上放弃了，因为它不能处理它。相反，它*在`current`的上下文中调用操作系统的页面错误处理程序代码*——在进程上下文中运行的异常或错误处理程序。这个页面错误处理程序实际上解决了这种情况；在我们的案例中，有了`vmalloc()`(或者确实连用户空间都有了`malloc()`！)，它向页面分配器请求单个物理页面帧(在顺序`0`)并将其映射到虚拟页面。

同样重要的是要认识到，这种按需分页(或惰性分配)是*而不是内核内存分配*的情况，后者是通过页面(伙伴系统)和 slab 分配器执行的。在那里，当分配内存时，理解实际的物理页面帧被立即分配*。(实际上在 Linux 上，这一切都非常快，因为回想一下，好友系统自由列表已经将所有系统物理内存映射到内核*lowm*区域，因此可以随意使用。)*

 *回想一下我们在早期程序`ch8/lowlevel_mem`中所做的事情；在那里，我们使用我们的`show_phy_pages()`库例程来显示给定内存范围的虚拟地址、物理地址和**页面帧号** ( **PFN** )，从而验证低级页面分配器例程确实分配了物理上连续的内存块。现在，你可能会想，为什么不在这个`vmalloc_demo`内核模块中调用这个相同的函数呢？如果分配的(虚拟)页面的 pfn 不是连续的，我们再次证明，事实上，它只是虚拟连续的。听起来很想试试，但没用！为什么？原因很简单，如前所述(在[第 8 章](08.html)、*模块作者的内核内存分配–第 1 部分*):除了直接映射(标识映射/ lowmem 区域)地址–页面或平板分配器提供的地址，不要尝试从虚拟地址转换为物理地址。只是和`vmalloc`不配合。

`vmalloc`上还有几个点和一些相关信息；一定要读下去。

## vmalloc 之友()

在许多情况下，用于执行内存分配的精确应用编程接口(或内存层)对调用者来说并不重要。因此，在许多内核代码路径中出现的一种使用模式类似于下面的伪代码:

```sh
kptr = kmalloc(n);
if (!kptr) {
    kptr = vmalloc(n);
    if (unlikely(!kptr))
        <... failed, cleanup ...>
}
<ok, continue with kptr>
```

这种代码的更干净的替代方案是`kvmalloc()` API。在内部，它试图像这样分配请求的`n`字节内存:首先，通过更高效的`kmalloc()`；如果它成功了，很好，我们很快就获得了物理上连续的内存并完成了；如果没有，则返回到通过较慢但更可靠的`vmalloc()`分配内存(从而获得虚拟连续内存)。其签名如下:

```sh
#include <linux/mm.h>
void *kvmalloc(size_t size, gfp_t flags);
```

(记得包含头文件。)注意，要通过(内部)`vmalloc()`(如果是这样的话)，必须只提供`GFP_KERNEL`标志。像往常一样，返回值是一个指向分配内存的指针(一个内核虚拟地址)，或者失败时的`NULL`。释放`kvfree`获得的内存:

```sh
void kvfree(const void *addr);
```

这里的参数当然是从`kvmalloc()`开始的返回地址。

类似地，类似于`{k|v}zalloc()`API，我们也有`kvzalloc()` API，当然 *z* 访问内存内容。我建议你优先使用`kvmalloc()`应用编程接口(有一个常见的警告:它更安全，但速度稍慢)。

此外，您可以使用`kvmalloc_array()`应用编程接口为项目数组分配虚拟连续内存。它分配每个`size`字节的`n`元素。其实现如下所示:

```sh
// include/linux/mm.h
static inline void *kvmalloc_array(size_t n, size_t size, gfp_t flags)
{
        size_t bytes;
        if (unlikely(check_mul_overflow(n, size, &bytes)))
                return NULL;
        return kvmalloc(bytes, flags);
}
```

这里有一个重点:注意如何对危险的**整数溢出** ( **IoF** ) bug 进行有效性检查；这很重要，也很有趣；在需要时，通过在代码中执行类似的有效性检查来编写健壮的代码。

接下来，`kvcalloc()` API 在功能上等同于`calloc(3)`用户空间 API，只是`kvmalloc_array()` API 的简单包装:

```sh
void *kvcalloc(size_t n, size_t size, gfp_t flags);
```

我们还提到，对于需要 *NUMA 感知*的代码(我们在[第 7 章](07.html)、*内存管理内部组件–要点*中的*物理内存组织*部分讨论了 NUMA 和相关主题)，以下 API 可用，通过这些 API，我们可以指定要从中分配内存的特定 NUMA 节点作为参数(这是指向 NUMA 系统的指针；请务必查看下面的信息框):

```sh
void *kvmalloc_node(size_t size, gfp_t flags, int node);
```

同样，我们也有`kzalloc_node()` API，它将内存内容设置为零。

In fact, generically, most of the kernel-space memory APIs we have seen ultimately boil down to one *that takes a NUMA node as a parameter*. For example, take the call chain for one of the primary page allocator APIs, the `__get_free_page()` API:
`__get_free_page() -> __get_free_pages() -> alloc_pages() -> alloc_pages_current()
-> __alloc_pages_nodemask()` . The **`__alloc_pages_nodemask()`** API is considered to be the *heart* of the zoned buddy allocator; notice its fourth parameter, the (NUMA) nodemask:
`mm/page_alloc.c:struct page *`
`__alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order,
int preferred_nid, nodemask_t *nodemask);`

当然，你必须释放你带走的记忆；对于前面的`kv*()`应用编程接口(和`kcalloc()`应用编程接口)，释放通过`kvfree()`获得的内存。

Another internal detail worth knowing about, and a reason the `k[v|z]malloc[_array]()`APIs are useful: with a regular `kmalloc()`, the kernel will indefinitely retry allocating the memory requested if it's small enough (this number currently being defined as `CONFIG_PAGE_ALLOC_COSTLY_ORDER`, which is `3`, implying 8 pages or less); this can actually hurt performance! With the `kvmalloc()` API, this indefinite retrying is not done (this behavior is specified via the GFP flags `__GFP_NORETRY|__GFP_NOWARN`), thus speeding things up. An LWN article goes into detail regarding the rather weird indefinite-retry semantics of the slab allocator: *The "too small to fail" memory-allocation rule, Jon Corbet, December 2014* ([https://lwn.net/Articles/627419/](https://lwn.net/Articles/627419/)).

关于我们在本节中看到的`vmalloc_demo`内核模块，再快速看一下代码(`ch9/vmalloc_demo/vmalloc_demo.c`)。我们在评论中使用`kvmalloc()`和`kcalloc()` ( *第 3 步*和*第 4 步*)。让我们在 x86_64 Fedora 31 来宾系统上运行它，并查看输出:

![](Images/4f1c6465-29b3-436d-b777-1d3702dbeb77.png)

Figure 9.4 – Output on loading our vmalloc_demo.ko kernel module

我们可以从前面输出中的 API 中看到实际的返回(内核虚拟)地址——注意，它们都属于内核的 vmalloc 区域。注意`kvmalloc()`的返回地址(图 9.4 中的步骤 3)；让我们在`proc`下搜索一下:

```sh
$ sudo grep "^0x00000000fb2af97f" /proc/vmallocinfo
0x00000000fb2af97f-0x00000000ddc1eb2c 5246976 0xffffffffc04a113d pages=1280 vmalloc vpages N0=1280
```

就在那里！我们可以清楚地看到对大量内存(5 MB)使用`kvmalloc()`应用编程接口如何导致`vmalloc()`应用编程接口被内部调用(T2】应用编程接口会失败，不会发出警告，也不会重试)，因此，如您所见，`/proc/vmallocinfo`下的命中。

要解释`/proc/vmallocinfo`前面的字段，请参考这里的内核文档:[https://www . kernel . org/doc/Documentation/file systems/proc . txt](https://www.kernel.org/doc/Documentation/filesystems/proc.txt)。

Something for you to try out here: in our `ch9/vmalloc_demo` kernel module, change the amount of memory to be allocated via `kvmalloc()` by passing `kvnum=<# bytes to alloc>` as a module parameter.

仅供参考，内核提供了一个内部助手应用编程接口`vmalloc_exec()` -它(再次)是`vmalloc()`应用编程接口的包装器，用于分配一个实际上连续的内存区域，该内存区域设置了执行权限。一个有趣的用户是内核模块分配代码路径(`kernel/module.c:module_alloc()`)；内核模块(可执行部分)内存的空间是通过这个例程分配的。不过，这个例程不会导出。

我们提到的另一个助手例程是`vmalloc_user()`；它(又一次)是`vmalloc()` API 的包装器，用于分配一个清零的虚拟连续内存区域，适合映射到用户 VAS 中。该例程被导出；例如，它被几个设备驱动程序以及内核的性能事件环形缓冲区使用。

## 指定内存保护

如果您打算为您分配的内存页面指定特定的内存保护(读、写和执行保护的组合)会怎么样？在这种情况下，使用底层`__vmalloc()` API(它是导出的)。考虑内核源代码(`mm/vmalloc.c`)中的以下注释:

```sh
* For tight control over page level allocator and protection flags
* use __vmalloc() instead.
```

`__vmalloc()` API 的签名显示了我们如何实现这一点:

```sh
void *__vmalloc(unsigned long size, gfp_t gfp_mask, pgprot_t prot);
```

FYI, from the 5.8 kernel, the `__vmalloc()` function's third parameter - `pgprot_t prot` - has been removed (as there weren't any users for page permissions besides the usual ones; [https://github.com/torvalds/linux/commit/88dca4ca5a93d2c09e5bbc6a62fbfc3af83c4fca](https://github.com/torvalds/linux/commit/88dca4ca5a93d2c09e5bbc6a62fbfc3af83c4fca)). Tells us another thing regarding the kernel community - if a feature isn't being used by anyone, it's simply removed.

前两个参数是常见的疑点——所需的内存大小(以字节为单位)和分配的 GFP 标志。第三个参数是这里感兴趣的参数:`prot` 代表我们可以为内存页面指定的内存保护位掩码。例如，要分配 42 个设置为只读的页面(`r--`)，我们可以执行以下操作:

```sh
vrx = __vmalloc(42 * PAGE_SIZE, GFP_KERNEL, PAGE_KERNEL_RO);
```

当然，随后调用`vfree()`将内存释放回系统。

### 测试它–快速**概念验证**

我们将在`vmalloc_demo`内核模块中尝试快速概念验证。我们通过`__vmalloc()`内核应用编程接口分配一个内存区域，指定页面保护为只读(或 *RO* )。然后，我们通过读取*并将*写入只读存储器区域来测试它。它的代码片段如下所示。

请注意，我们在下面的代码中默认保留了(傻傻的)`WR2ROMEM_BUG`宏未定义，这样你这个无辜的读者就不会让我们邪恶的`vmalloc_demo`内核模块简单地崩溃在你身上。因此，为了尝试这个概念验证，请取消对 define 语句的注释(如下所示)，从而允许错误代码执行:

```sh
static int vmalloc_try(void)
{
    [...]
    /* 5\. __vmalloc(): allocate some 42 pages and set protections to RO */
/* #undef WR2ROMEM_BUG */
#define WR2ROMEM_BUG /* 'Normal' usage: keep this commented out, else we 
                      *  will crash! Read  the book, Ch 9, for details :-) */
    if (!(vrx = __vmalloc(42*PAGE_SIZE, GFP_KERNEL, PAGE_KERNEL_RO))) {
        pr_warn("%s: __vmalloc failed\n", OURMODNAME);
        goto err_out5;
    }
    pr_info("5\. __vmalloc(): vrx = 0x%pK (actual=0x%px)\n", vrx, vrx);
    /* Try reading the memory, should be fine */
    print_hex_dump_bytes(" vrx: ", DUMP_PREFIX_NONE, vrx, DISP_BYTES);
#ifdef WR2ROMEM_BUG
    /* Try writing to the RO memory! We find that the kernel crashes
     * (emits an Oops!) */
   *(u64 *)(vrx+4) = 0xba;
#endif
    return 0;
    [...]
```

运行时，当我们试图写入只读存储器时，它崩溃了！见以下部分截图(图 9.5；从在我们的 x86_64 Fedora 客户机上运行它):

![](Images/b0c393b0-0883-4adb-80f2-0d43469ad3f4.png)

Figure 9.5 – The kernel Oops that occurs when we try and write to a read-only memory region!

这证明，事实上，我们执行的`__vmalloc()`应用编程接口已经成功地将内存区域设置为只读。同样，前面(部分可见)内核诊断或*哎呀*消息解释的细节超出了本书的范围。尽管如此，还是很容易看到上图中突出显示的问题的根本原因:下面几行精确地指出了这个错误的原因:

```sh
BUG: unable to handle page fault for address: ffffa858c1a39004
#PF: supervisor write access in kernel mode
#PF: error_code(0x0003) - permissions violation
```

In user space applications, performing a similar memory protection setting upon an arbitrary memory region can be done via the `mprotect(2)` system call; do look up its man page for usage details (it even kindly provides example code!).

### 为什么将内存设为只读？

比如说，在分配时将内存保护指定为只读可能看起来是一件非常无用的事情:那么如何将内存初始化为一些有意义的内容呢？好吧，考虑一下–**守护页面**是这个场景的完美用例(类似于 SLUB 层在调试模式下保持的 redzone 页面)；它确实有用。

如果我们想要只读页面，而不是保护页面，会怎么样？好吧，与其使用`__vmalloc()`，我们或许可以利用一些替代的手段:或许内存通过`mmap()`方法将一些内核内存映射到用户空间，并使用来自用户空间应用的`mprotect(2)`系统调用来设置适当的保护(或者甚至通过众所周知且经过测试的 LSM 框架来设置保护，例如 SELinux、AppArmor、Integrity 等等)。

我们以典型的内核内存分配器 API`kmalloc()`和`vmalloc()`之间的快速比较来结束本节。

## kmalloc()和 vmalloc()API–快速比较

下表快速比较了`kmalloc()`(或`kzalloc()`)和`vmalloc()`(或`vzalloc()`)原料药:

| **特性** | **`kmalloc()`或`kzalloc()`** | **`vmalloc()`或`vzalloc()`** |
| **分配的内存为** | 物理上连续的 | 虚拟(逻辑)连续 |
| **记忆对齐** | 与硬件(中央处理器)缓存行对齐 | 页面对齐 |
| **最小粒度** | 依赖足弓；x86[_64]上低至 8 字节 | 1 页 |
| **性能** | 对于小内存分配(典型情况)，速度要快得多(物理内存已分配)；非常适合< 1 页的分配 | 较慢，按需分页(仅分配虚拟内存；涉及页面错误处理程序的 RAM 的惰性分配)；可以为大型(虚拟)分配提供服务 |
| **尺寸限制** | 受限(通常为 4 MB) | 非常大(内核 vmalloc 区域在 64 位系统上甚至可以是几万亿字节，尽管在 32 位系统上要小得多) |
| **适宜性** | 适用于几乎所有性能重要、所需内存小的用例，包括 DMA(仍然使用 DMA API)；可以在原子/中断环境中工作 | 适合大型软件(虚拟)连续缓冲区；较慢，不能在原子/中断上下文中分配 |

这并不意味着一个优于另一个。它们的用法取决于具体情况。这将引导我们进入下一个——事实上非常重要的——主题:如何决定何时使用哪个内存分配 API？做出正确的决定实际上对于获得最佳的系统性能和稳定性至关重要–请继续阅读，了解如何做出选择！

# 内核中的内存分配–什么时候使用哪些 API

到目前为止，我们学到了一个非常快速的总结:内核用于内存分配(和释放)的底层引擎叫做页面(或伙伴系统)分配器。最终，每一次内存分配(以及随后的空闲)都要经过这一层。但是它也有一些问题，主要是内部碎片或浪费(因为它的最小粒度是一个页面)。因此，我们在它上面有一个层板分配器(或层板缓存)，提供对象缓存和缓存页面片段的能力(帮助缓解页面分配器的浪费问题)。此外，不要忘记，您可以创建自己的自定义平板缓存，正如我们刚刚看到的，内核有一个`vmalloc`区域和 API，用于从其中分配*虚拟*页面。

记住这些信息，让我们继续前进。为了理解什么时候使用哪个应用编程接口，让我们首先看看内核内存分配应用编程接口集。

## 可视化内核内存分配应用编程接口集

下面的概念图向我们展示了 Linux 内核的内存分配层以及其中突出的 APIs 请注意以下几点:

*   这里我们只显示内核向模块/驱动程序作者公开的(通常使用的)API(最终执行分配的除外——底部的`__alloc_pages_nodemask()` API！).
*   为了简洁起见，我们没有展示相应的释放内存的 API。

下面的图表显示了几个(向模块/驱动程序作者公开的)内核内存分配 API:

![](Images/ff0961b1-d6a9-4f80-9453-e4e8fd18923b.png)

Figure 9.6 – Conceptual diagram showing the kernel's memory allocation API set (for module / driver authors)

现在，您已经看到了大量可用的(公开的)内存分配 API，接下来的部分将深入研究如何帮助您做出在什么情况下使用哪个 API 的正确决定。

## 为内核内存分配选择合适的应用编程接口

有了这么多选择，我们该如何选择？虽然我们已经在本章和上一章中讨论了这个案例，但我们将再次总结它，因为它非常重要。一般来说，有两种方法来看待它——要使用的应用编程接口取决于以下几点:

*   所需的内存量
*   所需的内存类型

我们将在本节中说明这两种情况。

首先，要根据要分配的内存的类型、数量和连续性来决定使用哪个应用编程接口，请浏览以下流程图(从这里的“开始”标签的右上角开始):

![](Images/f1d99007-51ca-4de7-a44e-62232273a81e.png)

Figure 9.7 – Decision flowchart for which kernel memory allocation API(s) to use for a module/driver

当然，这不是小事；不仅如此，我还想提醒大家回忆一下我们在本章前面介绍的详细讨论，包括要使用的 GFP 标志(以及*不要在原子上下文中休眠*规则)；实际上，以下内容:

*   当在任何原子上下文中时，包括中断上下文，确保您只使用`GFP_ATOMIC`标志。
*   否则(流程上下文)，你决定使用`GFP_ATOMIC`还是`GFP_KERNEL`标志；在睡觉安全的时候使用`GFP_KERNEL`
*   然后，如使用 slab 分配器时的*注意事项部分所述:使用`k[m|z]alloc()` API 和朋友时，确保使用`ksize()`检查实际分配的内存。*

接下来，要根据要分配的内存类型决定使用哪个 API，请浏览下表:

| **所需内存类型** | **分配方式** | API |
| 内核模块，典型情况:少量(少于一页)的常规使用，物理上连续 | 平板分配器 | `k[m&#124;z]alloc()`、`kcalloc()`和 `krealloc()` |
| 设备驱动程序:定期少量使用(< 1 页)，物理上连续；适用于驱动程序`probe()`或初始化方法；推荐司机使用 | 资源管理的应用程序接口 | `devm_kzalloc()`和`devm_kmalloc()` |
| 物理上连续的通用用途 | 页面分配器 | `__get_free_page[s]()`
`get_zeroed_page()`，以及
`alloc_page[s][_exact]()` |
| 物理上连续，用于**直接内存访问** ( **DMA** ) | 专门构建的 DMA API 层，带有 CMA(或平板/页面分配器) | (这里不涉及:`dma_alloc_coherent(),
dma_map_[single&#124;sg]()`、Linux DMA 引擎 API 等等) |
| 几乎连续(对于大型纯软件缓冲区) | 间接通过页面分配器 | `v[m&#124;z]alloc()` |
| 当不确定运行时大小时，虚拟地或物理地连续 | 平板或 vmalloc 区域 | `kvmalloc[_array]()` |
| 自定义数据结构(对象) | 创建和使用自定义板缓存 | `kmem_cache_[create&#124;destroy]()`和 `kmem_cache_[alloc&#124;free]()` |

(当然与本表及*图 9.7* 流程图有一定重叠)。作为一般的经验法则，您的第一选择应该是 slab 分配器 API，即通过`kzalloc()`或`kmalloc()`；对于典型的小于一页大小的分配，这些是最有效的。此外，回想一下，当不确定所需的运行时大小时，可以使用`kvmalloc()`应用编程接口。同样，如果所需的尺寸恰好是 2 的完美舍入幂次页数(2 <sup>0</sup> 、2 <sup>1</sup> ，...，2 <sup>MAX_ORDER-1</sup> *页面*，那么使用页面分配器 API 将是最优的。

## DMA 和 CMA 一词

关于直接存储器存取的话题，虽然它的研究和使用超出了本书的范围，但我还是想提一下，Linux 有一套专门为直接存储器存取构建的应用编程接口，命名为*直接存储器存取引擎。*执行 DMA 操作的驱动程序作者非常希望使用这些 API，*而不是*直接使用平板或页面分配器 API(确实出现了微妙的硬件问题)。

此外，几年前，三星工程师成功地将一个名为***连续内存分配器** ( **CMA** )的补丁合并到主线内核中。本质上，它允许分配*大的物理连续内存*块(大小超过典型的 4 MB 限制！).这是某些内存密集型设备上的 DMA 所必需的(您想在大屏幕平板电脑或电视上播放超高清质量的电影吗？).酷的是，CMA 代码被透明地构建到了 DMA 引擎和 DMA 应用编程接口中。因此，像往常一样，执行直接存储器存取操作的驱动程序作者应该坚持使用 Linux 直接存储器存取引擎层。*

*If you are interested in learning more about DMA and CMA, see the links provided in the Further reading section for this chapter.

此外，要意识到我们的讨论主要是关于典型的内核模块或设备驱动程序作者。在操作系统内部，对单个页面的需求往往相当高(由于操作系统通过页面故障处理程序进行服务需求分页，即所谓的*小故障*故障)。因此，在幕后，内存管理子系统倾向于频繁发布`__get_free_page[s]()`API。此外，为了满足*页面缓存*(和其他内部缓存)的内存需求，页面分配器扮演着重要的角色。

好了，干得好，这下你有(差一点！)完成了我们关于各种内核内存分配层和 API 的两章内容(针对模块/驱动作者)！让我们用一个剩下的重要领域来结束这个大话题 Linux 内核的(相当有争议的)OOM 杀手；一定要读下去！

# 活着 OOM 杀手

让我们首先介绍一些关于内核内存管理的背景细节，特别是回收空闲内存。这将使您能够理解内核 *OOM 杀手*组件是什么，如何使用它，甚至如何故意调用它。

## 回收内存——内核内务处理任务和 OOM

如您所知，为了获得最佳性能，内核试图将内存页面的工作集保持在内存金字塔(或层次结构)中尽可能高的位置。

The so-called memory pyramid (or memory hierarchy) on a system consists of (in order, from smallest size but fastest speed to largest size but slowest): CPU registers, CPU caches (LI, L2, L3, ...), RAM, and swap (raw disk/flash/SSD partition). In our following discussion, we ignore CPU registers as their size is minuscule.

因此，处理器使用其硬件缓存(L1、L2 等)来保存页面的工作集。但当然，CPU 缓存内存非常有限，因此很快就会耗尽，导致内存溢出到下一个层次——RAM。在现代系统上，即使是许多嵌入式系统，也有相当多的内存；尽管如此，如果操作系统内存不足，它会将无法再放入内存的内存页面溢出到原始磁盘分区–*交换*。因此，该系统继续运行良好，尽管一旦交换被(经常)使用，将会付出巨大的性能代价。

为了确保内存中始终有给定的最小数量的空闲内存页面可用，Linux 内核会不断执行后台页面回收工作——实际上，您可以将此视为常规内务处理。谁实际执行这项工作？`kswapd` 内核线程持续监控系统内存使用情况，并在感知到内存不足时调用页面回收机制。

此页面回收工作是在每个*节点:区域*的基础上完成的。内核使用所谓的*水印级别*–每*节点的最小值、低值和高值:区域*以智能方式确定何时回收内存页面。您可以随时查阅`/proc/zoneinfo`查看当前的水印级别。(请注意，水印级别的单位是页面。)此外，正如我们前面提到的，缓存通常是第一个受害者，并且随着内存压力的增加而缩小。

但是，让我们扮演魔鬼的拥护者:如果所有这些内存回收工作都无济于事，并且内存压力不断增加到整个内存金字塔耗尽的地步，甚至几页的内核分配都失败了(或者无限重试，坦率地说，这也是无用的，也许更糟)，怎么办？如果所有的中央处理器缓存、内存和交换都(几乎)满了怎么办！？嗯，大多数系统只是在这一点上死亡(实际上，它们没有死亡，它们只是变得如此缓慢，以至于看起来好像它们被永久挂起了)。然而，作为 Linux，Linux 内核在这些情况下往往是激进的；它调用了一个名为 OOM 杀手*的组件。*OOM 杀手的工作——你猜对了！–识别并立即终止内存占用程序(通过向其发送致命的`SIGKILL`信号；它甚至可能最终杀死一大堆进程)。

正如你可能想象的那样，它也有它的争议。早期版本的 OOM 杀手受到了(相当正确的)批评。最近的版本使用了非常有效的高级试探法。

You can find more information on the improved OOM killer work (the kick-in strategy and the OOM reaper thread) in this LWN article (December 2015): *Toward more predictable and reliable out-of-memory handling:* [https://lwn.net/Articles/668126/](https://lwn.net/Articles/668126/).

## 故意援引 OOM 杀手

为了测试内核 OOM 杀手，我们必须给系统施加巨大的内存压力。因此，内核将释放它的武器 OOM 杀手，一旦被调用，它将识别并杀死一些进程。因此，很明显，我强烈建议您在一个安全的隔离系统上尝试这样的东西，最好是一个测试 Linux 虚拟机(上面没有重要数据)。

### 通过魔法系统调用 OOM 杀手

内核提供了一个有趣的特性，叫做*魔法系统* : 本质上，某些键盘组合键(或加速器)会导致对某些内核代码的回调。例如，假设它已启用，在 x86[_64]系统上按下`Alt-SysRq-b`组合键会导致冷重启！注意，不要随便打什么，一定要看这里的相关文档:[https://www . kernel . org/doc/Documentation/admin-guide/sysrq . rst](https://www.kernel.org/doc/Documentation/admin-guide/sysrq.rst)。

让我们尝试一些有趣的事情；我们在 Fedora Linux 虚拟机上运行了以下内容:

```sh
$ cat /proc/sys/kernel/sysrq
16
```

这表明 Magic SysRq 功能已部分启用(本节开头提到的内核文档给出了详细信息)。为了完全启用它，我们运行以下命令:

```sh
$ sudo sh -c "echo 1 > /proc/sys/kernel/sysrq"
```

好吧，那么说重点:你可以使用魔法系统调用 OOM 杀手！

Careful! Invoking the OOM killer, via Magic SysRq or otherwise, *will* cause some process – typically the *heavy* one(s) – to unconditionally die!

怎么做？作为根用户，只需键入以下内容:

```sh
# echo f > /proc/sysrq-trigger
```

查看内核日志，看看是否有什么有趣的事情发生！

### 用一个疯狂的分配器程序调用 OOM 杀手

我们还将在下一节演示一种更实际、更有趣的方法，通过这种方法，您可以(很可能)邀请 OOM 杀手加入。编写一个简单的用户空间 C 程序，它的行为就像一个疯狂的分配器，执行(通常)成千上万的内存分配，在每页上写一些东西，当然，永远不会释放内存，从而给内存资源带来巨大的压力。

像往常一样，我们只在下面的代码片段中显示源代码中最相关的部分；完整代码请参考并克隆本书的 GitHub repo 请记住，这是一个用户模式的应用程序，而不是内核模块:

```sh
// ch9/oom_killer_try/oom_killer_try.c
#define BLK     (getpagesize()*2)
static int force_page_fault = 0;
int main(int argc, char **argv)
{
  char *p;
  int i = 0, j = 1, stepval = 5000, verbose = 0;
  [...]

  do {
      p = (char *)malloc(BLK);
      if (!p) {
          fprintf(stderr, "%s: loop #%d: malloc failure.\n",
                  argv[0], i);
          break;
      }

      if (force_page_fault) {
          p[1103] &= 0x0b; // write something into a byte of the 1st page
          p[5227] |= 0xaa; // write something into a byte of the 2nd page
      }
      if (!(i % stepval)) { // every 'stepval' iterations..
          if (!verbose) {
              if (!(j%5)) printf(". ");
         [...]
      }
      i++;
 } while (p && (i < atoi(argv[1])));
```

在下面的代码块中，我们展示了在运行定制的 5.4.0 Linux 内核的 x86_64 Fedora 31 VM 上运行我们的*疯狂分配器*程序时获得的一些输出:

```sh
$ cat /proc/sys/vm/overcommit_memory  /proc/sys/vm/overcommit_ratio0
50                       
$                           << explained below >>

$ ./oom-killer-try
Usage: ./oom-killer-try alloc-loop-count force-page-fault[0|1] [verbose_flag[0|1]]
$ ./oom-killer-try 2000000 0
./oom-killer-try: PID 28896
..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ...Killed
$
```

`Killed`消息就是赠品！用户模式进程已被内核终止。一旦我们浏览内核日志，原因就变得显而易见了——这当然是 OOM 杀手(我们在*需求分页和 OOM* 部分展示了内核日志)。

## 理解 OOM 杀手背后的原理

浏览一下我们的`oom_killer_try`应用程序之前的输出:(在这个特定的运行中)33 个周期(`.`)出现在可怕的`Killed`消息之前。在我们的代码中，我们每分配 5000 次(2 页或 8 KB)，就会发出一个`.`(通过`printf`)。因此，在这里，我们有 33 乘 5 周期，意思是 33 * 5 = 165 次= > 165 * 5000 * 8K ~= 6，445 MB。因此，我们可以得出结论，在我们的进程(虚拟地)分配了大约 6，445 MB (~ 6.29 GB)的内存之后，OOM 杀手终止了我们的进程！你现在需要明白为什么会在这个特定的数字上发生这种情况。

在这个特殊的 Fedora Linux 虚拟机上，内存是 2 GB *而* *交换空间*是 2gb；因此，*内存* *金字塔*中的总可用内存= (CPU 缓存+) RAM +交换。

这是 4 GB(为了简单起见，让我们忽略 CPU 缓存中相当微不足道的内存量)。但是，它回避了一个问题，为什么内核没有在 4 GB 点(或更低)调用 OOM 杀手？为什么只有 6 GB 左右？这是一个有趣的点:Linux 内核遵循**虚拟机过度承诺**策略，故意过度承诺内存(在一定程度上)。要了解这一点，请参见当前的`vm.overcommit`设置:

```sh
$ cat /proc/sys/vm/overcommit_memory
0
```

这确实是默认的(`0`)。允许值(只能由 root 设置)如下:

*   `0`:使用启发式算法允许内存过量使用(详见下一节)；*默认。*

*   `1`:始终超量承诺；换句话说，永远不要拒绝任何`malloc(3)`；对某些使用稀疏内存的科学应用程序很有用。

*   `2`:以下注释直接引用内核文档([https://www . kernel . org/doc/html/v 4.18/VM/超量承诺-记账. html #超量承诺-记账](https://www.kernel.org/doc/html/v4.18/vm/overcommit-accounting.html#overcommit-accounting)):

*“不要过度承诺。系统的总地址空间提交不允许超过交换加上可配置的物理内存量(默认值为 50%)。根据您使用的数量，在大多数情况下，这意味着进程在访问页面时不会被终止，但会在适当的时候收到内存分配错误。对于希望保证其内存分配在未来可用而不必初始化每个页面的应用程序很有用”*

超量承诺范围由超量承诺比率决定:

```sh
$ cat /proc/sys/vm/overcommit_ratio
50
```

我们将在下面的章节中研究两种情况。

### 情况 1–VM .超量承诺设置为 2，超量承诺关闭

首先，记住，这是*而不是*的默认。将`overcommit_memory`可调设置为`2`，用于计算总可用内存(可能过量)的公式如下:

*总可用内存= (RAM +交换)*(超量承诺 _ 比率/100)；*

该公式仅在`vm.overcommit == 2`时适用。

在我们的 Fedora 31 虚拟机上，每个内存和交换内存分别为`vm.overcommit == 2`和 2 GB，这会产生以下结果(以千兆字节为单位):

*总可用内存= (2 + 2) * (50/100) = 4 * 0.5 = 2 GB*

This value – the (over)commit limit – is also seen in `/proc/meminfo` as the `CommitLimit` field.

### 情况 2–VM .超量承诺设置为 0，超量承诺开启，默认值

这个*是*默认的。`vm.overcommit`设置为`0`(不是`2`):这样，内核有效地计算总的(超过的)提交内存大小，如下所示:

*总可用内存= (RAM +交换)*(超量承诺 _ 比率+100%)；*

该公式仅在`vm.overcommit == 0`时适用。

在我们的 Fedora 31 虚拟机上，每个内存和交换内存分别为`vm.overcommit == 0`和 2 GB，该公式得出以下结果(以千兆字节为单位):

*总可用内存= (2 + 2) * (50+100)% = 4 * 150% = 6 GB*

因此，系统实际上假装总共有 6 GB 的可用内存。所以现在我们明白了:当我们的`oom_killer_try`进程分配了巨大的内存并且超过了这个限制(6 GB)时，OOM 杀手就跳了进来！

We now understand that the kernel provides several VM overcommit tunables under `/proc/sys/vm`, allowing the system administrator (or root) to fine-tune it (including switching it off by setting `vm.overcommit` to the value `2`). At first glance, it may appear tempting to do so, to simply turn it off. Do pause though and think it through; leaving the VM overcommit at the kernel defaults is best on most workloads.

(For example, setting the `vm.overcommit` value to `2` on my Fedora 31 guest VM caused the effective available memory to change to just 2 GB. The typical memory usage, especially with the GUI running, far exceeded this, causing the system to be unable to even log in the user in GUI mode!) The following links help throw more light on the subject: Linux kernel documentation: [https://www.kernel.org/doc/Documenta](https://www.kernel.org/doc/Documentation/vm/overcommit-accounting)[tion/vm/overcommit-accounting](https://www.kernel.org/doc/Documentation/vm/overcommit-accounting) and *What are the disadvantages of disabling memory overcommit in Linux?* : [https://www.quora.com/What-are-the-disadvantages-of-disabling-memory-overcommit-in-Linux](https://www.quora.com/What-are-the-disadvantages-of-disabling-memory-overcommit-in-Linux) . (Do see the *Further reading* section for more.)

## 按需分页和 OOM

回想一下我们在本章前面学习的真正重要的事实，在*内存分配和按需分页*一节中:由于操作系统使用的按需分页(或延迟分配)策略，当一个内存页面被`malloc(3)`(和朋友)分配时，它实际上只会导致在进程 VAS 的一个区域中保留虚拟内存空间；此时没有分配物理内存。只有当您对虚拟页面的任何字节执行一些操作(读、写或执行)时，MMU 才会引发页面错误(小错误)，从而运行操作系统的页面错误处理程序。如果它认为这个内存访问是合法的，它就分配一个物理帧(通过页面分配器)。

在我们简单的`oom_killer_try`应用程序中，我们通过它的第三个参数`force_page_fault`来处理这个想法:当设置为`1`时，我们通过在每个循环迭代分配的两个页面的每一个的一个字节中写入一些东西来精确地模拟这种情况，任何东西都可以(如果需要，请再次查看代码)。

所以，既然你知道了这一点，让我们用第三个参数`force_page_fault`重新运行我们的应用，设置为`1`，以确实强制页面错误！以下是我在我的 Fedora 31 虚拟机(在我们定制的 5.4.0 内核上)上运行时得到的输出:

```sh
$ cat /proc/sys/vm/overcommit_memory /proc/sys/vm/overcommit_ratio0
50
$ free -h
              total    used    free     shared   buff/cache    available
Mem:          1.9Gi   1.0Gi    76Mi       12Mi        866Mi        773Mi
Swap:         2.1Gi   3.0Mi   2.1Gi
$ ./oom-killer-try
Usage: ./oom-killer-try alloc-loop-count force-page-fault[0|1] [verbose_flag[0|1]]
$ ./oom-killer-try 900000 1
./oom_killer_try: PID 2032 (verbose mode: off)
..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... .Killed
$ 
$ free -h
              total    used    free    shared   buff/cache     available
Mem:          1.9Gi   238Mi   1.5Gi     2.0Mi        192Mi         1.6Gi
Swap:         2.1Gi   428Mi   1.6Gi
$
```

这一次，你可以真切地感受到系统在为记忆而战。这一次，由于实际的物理内存被分配给了 T2，它很快就用完了内存。(从前面的输出中，我们看到在这种特殊情况下是 15×5+1 个点(`.` 或周期)；也就是 15 次 5 点+ 1 点= > = 76 次= > 76 * 5000 次循环迭代*每次迭代~ = 2969 MB 虚拟*和物理*分配！)

显然，在这一点上，发生了两件事之一:

*   系统内存和交换空间都用完了，因此无法分配页面，从而邀请 OOM 杀手进入。
*   超出了计算的(人工)内核虚拟机提交限制。

我们可以很容易地查找这个内核虚拟机提交值(同样在我运行它的 Fedora 31 虚拟机上):

```sh
$ grep CommitLimit /proc/meminfo
CommitLimit: 3182372 kB
```

这算下来约为 3，108 兆字节(远远超过我们计算的 2，969 兆字节)。因此，在这里，很可能所有的内存和交换空间都被用来运行图形用户界面和现有的应用程序，第一种情况开始发挥作用。

还要注意，在运行我们的程序之前，较大的系统缓存(页面缓存和缓冲区缓存)使用的内存量是非常大的。`free(1)`实用程序输出中名为`buff/cache`的列显示了这一点。在运行我们疯狂的分配器应用程序之前，2 GB 内存中有 866 MB 被用于页面缓存。然而，一旦我们的程序运行，它会对操作系统施加很大的内存压力，以至于执行了大量的交换——将内存页面分页到称为“交换”的原始磁盘分区，实际上所有的缓存都被释放了。不可避免地(当我们拒绝释放任何内存时)，OOM 杀手会跳进去杀死我们，导致大量内存被回收。OOM 杀手清理后的可用内存和缓存使用量分别为 1.5 GB 和 192 MB。(目前缓存使用率较低；它会随着系统的运行而增加。)

查内核日志发现，OOM 杀手确实来过我们这里！请注意，以下部分屏幕截图仅显示了运行 5.4.0 内核的 x86_64 Fedora 31 虚拟机上的堆栈转储:

![](Images/06c7e3e9-3f3f-454e-95e0-2d32918c24a8.png)

Figure 9.8 – The kernel log after the OOM killer, showing the kernel call stack

以自下而上的方式读取*图 9.8* 中的内核模式堆栈(忽略以`?`开头的帧):很明显，出现了页面错误；你可以看到呼叫帧:`page_fault()`|`do_page_fault()`|`[ ... ]`|`__hande_mm_fault()`|`__do_fault()`|`[ ... ]`|`__alloc_pages_nodemask()`。

想想看，这是完全正常的:故障是由内存管理单元在试图为没有物理对应物的虚拟页面提供服务时引发的。操作系统的故障处理代码运行(在进程上下文中，意味着`current`运行它的代码！);它最终会导致 OS 调用页面分配器例程的`__alloc_pages_nodemask()`函数，正如我们之前了解到的，它实际上是分区好友系统(或页面)分配器的核心——内存分配的引擎！

不正常的是，这一次它(`__alloc_pages_nodemask()`功能)失败了！这被认为是一个关键问题，并导致操作系统调用 OOM 杀手(您可以在上图中看到`out_of_memory`调用帧)。

在诊断转储的后半部分，内核努力证明其终止给定进程的理由。它显示了所有线程、它们的内存使用情况(以及各种其他统计数据)的表格。实际上，显示这些统计数据是由于`sysctl : /proc/sys/vm/oom_dump_tasks` 默认开启(`1`)所致。下面是一个示例(在下面的输出中，我们删除了`dmesg`最左边的时间戳列，以使数据更具可读性):

```sh
[...]
Tasks state (memory values in pages):
[ pid ]  uid  tgid total_vm    rss pgtables_bytes swapents oom_score_adj name
[  607]    0   607    11774      8   106496       361   -250 systemd-journal
[  622]    0   622    11097      0    90112      1021  -1000 systemd-udevd
[  732]    0   732     7804      0    69632       153  -1000 auditd

              [...]

[ 1950] 1000  1950    56717      1   77824        571  0    bash
[ 2032] 1000  2032   755460 434468 6086656     317451  0    oom_killer_try
oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=/,mems_allowed=0,global_oom,task_memcg=/user.slice/user-1000.slice/session-3.scope,task=oom_killer_try,pid=2032,uid=1000
Out of memory: Killed process 2032 (oom_killer_try) total-vm:3021840kB, anon-rss:1737872kB, file-rss:0kB, shmem-rss:0kB, UID:1000 pgtables:6086656kB oom_score_adj:0
oom_reaper: reaped process 2032 (oom_killer_try), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB
$ 
```

在前面的输出中，我们用粗体突出显示了`rss` ( *常驻集大小*)列，因为它很好地指示了所讨论的进程的物理内存使用情况(单位是 KB)。显然，我们的`oom_killer_try`进程正在使用大量的物理内存。另外，请注意它的交换条目数(`swapents`)非常高。现代内核(从 4.6 开始)使用专门的`oom_reaper`内核线程来执行收割(杀死)受害者进程的工作(前面输出的最后一行显示这个内核线程收割了我们精彩的`oom_killer_try`进程！).有趣的是，Linux 内核的 OOM 可以被认为是针对叉形炸弹和类似的**(分布式)拒绝服务** ( **(D)DoS** )攻击的(最后)防御。

## 理解 OOM 分数

为了加速发现占用内存的进程在关键时刻是什么(当 OOM 杀手被调用时)，内核在每个进程的基础上分配并维护一个 *OOM 分数*(你总是可以在`/proc/<pid>/oom_score`伪文件中查找该值)。

OOM 评分范围为`0`至`1000`:

*   `0`的 OOM 分数意味着进程没有使用任何可用的内存
*   `1000`的 OOM 分数意味着该进程正在使用 100%的可用内存

显然，OOM 得分最高的流程获胜。它的奖励——它会被 OOM 杀手立刻杀死(谈论枯燥的幽默)。不过没那么快:内核有启发式算法来保护重要的任务。例如，烘焙试探法暗示 OOM 杀手不会选择任何根拥有的进程、内核线程或硬件设备打开的任务作为其受害者。

如果我们想确保某个过程*永远不会被 OOM 杀手杀死*会怎么样？这样做是完全可能的，尽管它确实需要根访问。内核提供一个可调的`/proc/<pid>/oom_score_adj`，一个 OOM 调整值(默认为`0`)。*净* OOM 分数是`oom_score`值和调整值之和:

```sh
  net_oom_score = oom_score + oom_score_adj;
```

因此，将进程的`oom_score_adj`值设置为`1000`几乎可以保证它会被杀死，而将其设置为`-1000`则有完全相反的效果——它永远不会被选为受害者。

查询(甚至设置)流程的 OOM 分数(以及 OOM 调整值)的快速方法是通过`choom(1)`实用程序。比如查询 systemd 流程的 OOM 评分和 OOM 调整值，只需做`choom -p 1`。我们做了一件显而易见的事情——写了一个简单的脚本(内部使用`choom(1)`)来查询系统上当前所有活动进程的 OOM 分数(这里是:`ch9/query_process_oom.sh`；一定要在你的盒子上试试。快速提示:系统中 OOM 评分最高的(十)个流程可以快速看到(第三列为净 OOM 评分):

```sh
./query_process_oom.sh | sort -k3n | tail
```

至此，我们结束了这一节，也结束了这一章。

# 摘要

在这一章中，我们继续上一章的内容。我们详细介绍了如何创建和使用您自己的自定义 slab 缓存(当您的驱动程序或模块非常频繁地分配和释放某个数据结构时很有用)，以及如何使用一些内核基础设施来帮助您调试 slab (SLUB)内存问题。然后，我们了解并使用了内核`vmalloc`API(和朋友)，包括如何在内存页面上设置给定的内存保护。有了丰富的内存 API 和策略，您如何选择在给定情况下使用哪一个？我们用一个有用的*决策图*和表格来解决这个重要的问题。最后，我们深入了解了内核的 *OOM 杀手*组件是什么，以及如何使用它。

正如我之前提到的，对 Linux 内存管理内部和导出的应用编程接口集足够深入的了解将对作为内核模块和/或设备驱动程序作者的您大有帮助。众所周知，现实是开发人员花费了大量的时间来排除故障和调试代码；在这里获得的复杂知识和技能将帮助你更好地穿越这些迷宫。

这就完成了本书对 Linux 内核内存管理的明确介绍。虽然我们已经涵盖了许多领域，但我们也遗漏了或仅仅浏览了其中的一些。

事实上，Linux 内存管理是一个巨大而复杂的话题，非常值得理解，以便学习、编写更高效的代码和调试复杂的情况。

学习强大的`crash(1)`实用程序的(基本)用法(用于通过实时会话或内核转储文件深入查看内核)，然后用这些知识重新查看本章和上一章的内容确实是一种强大的学习方式！

很好的讲解了 Linux 内存管理！接下来的两章将让你了解另一个核心操作系统主题——如何在 Linux 操作系统上执行 *CPU 调度*。休息一下，做下面的作业和问题，浏览*进一步阅读*材料，抓住你的兴趣。然后，重振旗鼓，和我一起跳到下一个激动人心的领域！

# 问题

作为我们的总结，这里有一个问题列表，供您测试您对本章材料的知识:[https://github . com/packt publishing/Linux-Kernel-Programming/tree/master/questions](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions)。你会在这本书的 GitHub repo 中找到一些问题的答案:[https://GitHub . com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions _ to _ assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn)。

# 进一步阅读

为了帮助您用有用的材料更深入地研究这个主题，我们在本书的 GitHub 存储库中的进一步阅读文档中提供了一个相当详细的在线参考资料和链接列表(有时甚至是书籍)。*进一步阅读*文档可在此处获得:[https://github . com/packt publishing/Linux-Kernel-Programming/blob/master/进一步阅读. md](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md) 。**