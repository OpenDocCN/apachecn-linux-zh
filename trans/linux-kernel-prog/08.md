# 八、面向模块作者的内核内存分配——第一部分

在前两章中，一章是关于内核内部方面和体系结构，另一章是关于内存管理内部的本质，我们讨论了作为本章和下一章所需背景信息的关键方面。在这一章和下一章中，我们将通过各种方式来讨论内核内存的实际分配和释放。我们将通过您可以测试和调整的内核模块来演示这一点，详细说明它的原因和方式，并提供许多真实世界的提示和技巧，使像您这样的内核或驱动程序开发人员能够在内核模块中使用内存时获得最大的效率。

在本章中，我们将介绍内核的两个主要内存分配器——页面分配器 ( **PA** )(又名**伙伴系统分配器** ( **BSA** )和平板分配器。我们将深入研究在内核模块中使用它们的 API 的本质。实际上，我们将远远不止简单地看到如何使用 API，清楚地展示为什么所有情况下都不是最佳的，以及如何克服这些情况。[第 9 章](09.html)、*面向模块作者的内核内存分配–第 2 部分*，将继续我们对内核内存分配器的介绍，深入一些更高级的领域。

在本章中，我们将涵盖以下主题:

*   介绍内核内存分配器
*   理解和使用内核页面分配器
*   理解和使用内核板分配器
*   kmalloc 应用编程接口的大小限制
*   平板分配器-一些额外的细节
*   使用平板分配器时的注意事项

# 技术要求

我假设您已经完成了[第 1 章](01.html)、*内核工作区设置*，并适当准备了一个运行 Ubuntu 18.04 LTS(或更高版本的稳定版本)的来宾**虚拟机** ( **VM** )并安装了所有需要的软件包。如果没有，我强烈建议你先做这个。

为了充分利用这本书，我强烈建议您首先设置工作区
环境，包括克隆这本书的 GitHub 存储库([https://github.com/PacktPublishing/Linux-Kernel-Programming](https://github.com/PacktPublishing/Linux-Kernel-Programming))以获取代码，并以动手的方式对其进行操作。

参考*Linux 动手系统编程*，万凯 N 比利莫利亚，Packt([https://www . packtpub . com/networking-and-servers/hand-System-Programming-Linux](https://www.packtpub.com/networking-and-servers/hands-system-programming-linux))作为本章的先决条件(必读，真的):

*   *第 1 章**Linux 系统架构*
*   *第二章**虚拟记忆*

# 介绍内核内存分配器

与任何其他操作系统一样，Linux 内核需要一个强大的算法和实现来执行一项真正关键的任务——内存或页面帧(RAM)的分配和后续释放。Linux 操作系统中的主要(去)分配器引擎被称为 PA，或 BSA。在内部，它使用所谓的伙伴系统算法来有效地组织和分配系统内存的空闲块。我们将在*理解和使用内核页面分配器(或 BSA)* 部分找到更多关于算法的信息。

In this chapter and in this book, when we use the notation *(de)allocate*, please read it as both words: *allocate* and *deallocate*.

当然，由于不完美，页面分配器并不是获得并随后释放系统内存的唯一或总是最好的方法。Linux 内核中还有其他技术可以做到这一点。其中排名靠前的是内核的 **slab 分配器**或 **slab 缓存**系统(我们在这里使用单词 *slab* 作为这种分配器的通用名，因为它起源于这个名字；然而在实践中，Linux 内核使用的现代 slab 分配器的内部实现被称为 SLUB(未引用的 slab 分配器)；稍后将对此进行更多介绍)。

这样想:slab 分配器解决了一些问题，并通过页面分配器优化了性能。具体是什么问题？我们很快就会看到。不过，目前来看，理解真正(去)分配物理内存的唯一方法是通过页面分配器，这一点非常重要。页面分配器是 Linux 操作系统上内存分配的主要引擎！

To avoid confusion and repetition, we will from now on refer to this primary allocation engine as the page allocator. *Y*ou will understand that it's also known as the BSA (derived from the name of the algorithm that drives it).

因此，平板分配器被分层在页面分配器之上。各种核心内核子系统，以及内核中的非核心代码，如设备驱动程序，可以直接通过页面分配器或间接通过平板分配器分配(和解除分配)内存；下图说明了这一点:

![](Images/eeb768cb-262b-456e-a24b-340cb9b83d32.png)

Figure 8.1 – Linux's page allocator engine with the slab allocator layered above it

从一开始就要明确几件事:

*   整个 Linux 内核及其所有核心组件和子系统(不包括内存管理子系统本身)最终使用页面分配器(或 BSA)进行内存(de)分配。这包括非核心的东西，比如内核模块和设备驱动程序。
*   前面的系统完全驻留在内核(虚拟)地址空间中，不能从用户空间直接访问。

*   页面分配器获取内存的页面框架(内存)位于内核低内存区域，或者内核段的直接映射内存区域(我们在上一章中详细介绍了内核段)
*   slab 分配器最终是页面分配器的用户，因此它自己从那里获得内存(这也意味着从内核 lowmem 区域)
*   用户空间动态内存分配熟悉的`malloc`系列 API 不会直接映射到前面的层(也就是说，在用户空间中调用`malloc(3)`*不会直接调用*页面或平板分配器)。这是间接的。具体怎么做？你会学会如何；耐心点！(这个重点覆盖在下一章的两个小节，其实涉及到需求分页；当你读那一章的时候，小心它！)
*   另外，要明确的是，Linux 内核内存是不可交换的。它永远无法换出到磁盘；这是在早期 Linux 时代为了保持高性能而决定的。默认情况下，用户空间内存页面总是可交换的；这可以由系统程序员通过`mlock()` / `mlockall()`系统调用来改变。

现在，系好安全带！有了对页面分配器和 slab 分配器的基本理解，让我们开始学习 Linux 内核的内存分配器是如何工作的(基础知识)，更重要的是，如何很好地使用它们。

# 理解和使用内核页面分配器

在本节中，您将了解 Linux 内核的主(去)分配器引擎的两个方面:

*   首先，我们将介绍这个软件(称为伙伴系统)背后的算法基础。
*   然后，我们将介绍它向内核或驱动程序开发人员公开的 API 的实际使用情况。

理解页面分配器背后算法的基础很重要。然后，您将能够理解它的优点和缺点，以及在何种情况下何时使用哪些 API。让我们从它的内部运作开始。同样，请记住，本书关于内部内存管理细节的范围是有限的。我们将把它覆盖到一个被认为足够的深度，仅此而已。

## 页面分配器的基本工作原理

我们将把这次讨论分成几个相关的部分。让我们从内核的页面分配器如何通过其 freelist 数据结构跟踪空闲物理页面帧开始。

### 自由列表组织

页面分配器(伙伴系统)算法的关键是它的主要内部元数据结构。它被称为好友系统自由列表，由指向(哦，太普通了！)双链接循环列表。这个指针数组的索引叫做列表的顺序——它是 2 的幂。数组长度从`0`到`MAX_ORDER-1`。`MAX_ORDER`的价值取决于拱。在 x86 和 ARM 上，它是 11，而在安腾等大型系统上，它是 17。因此，在 x86 和 ARM 上，订单范围从 2 <sup>0</sup> 到 2<sup>10</sup>；也就是从 1 到 1024。这是什么意思？一定要读下去...

每个双向链接的循环列表指向大小为 *2 <sup>顺序</sup>T3】的空闲物理连续页面帧。因此(假设页面大小为 4 KB)，我们得到了以下列表:*

*   2 <sup>0</sup> = 1 页= 4 KB 区块
*   2 <sup>1</sup> = 2 页= 8 KB 区块
*   2 <sup>2</sup> = 4 页= 16 KB 区块
*   2 <sup>3</sup> = 8 页= 32 KB 区块
*   2 <sup>10</sup> = 1024 页= 1024*4 KB = 4 MB 区块

下图是页面分配器 freelist(单个实例)的简化概念性说明:

![](Images/67223695-1ea4-47ee-b5cb-72ebf9e51799.png)

Figure 8.2 – Buddy system/page allocator freelist on a system with 4 KB page size and MAX_ORDER of 11

在上图中，每个内存“块”由一个方形框表示(为了简单起见，我们在图中使用相同的大小)。当然，在内部，这些不是真正的内存页面；相反，这些框表示指向物理内存框架的元数据结构(struct page)。在图的右侧，我们显示了可以在左侧列表中排队的每个物理上连续的空闲内存块的大小。

内核通过`proc`文件系统(在我们拥有 1 GB 内存的 Ubuntu 客户虚拟机上)为我们提供了一个页面分配器当前状态的便捷(汇总)视图:

![](Images/cfb090a9-cc6f-4b15-ae30-02e1c5f796fd.png)

Figure 8.3 – Annotated screenshot of sample /proc/buddyinfo output

我们的来宾虚拟机是一个伪 NUMA 盒，有一个节点(`Node 0`)和两个区域(`DMA`和`DMA32`)。`zone XXX`后面的数字是空闲(物理上连续！)页面框架按顺序 0，顺序 1，顺序 2，一直到`MAX_ORDER-1`(此处，*11–1 = 10*)。因此，让我们从前面的输出中举几个例子:

*   节点`0`的顺序`0`列表中有 35 个单页空闲内存块，区域 DMA。
*   在节点`0`，区域 DMA32，顺序`3`，这里*图 8.3* 所示的数字是 678；现在，取 *2 <sup>顺序</sup>= 2<sup>3</sup>**= 8**页面帧数= 32 KB* (假设页面大小 4kb)；这意味着该列表中有 678 个 32 KB 物理上连续的空闲内存块。

需要注意的是**每个数据块都保证是物理上连续的内存，并且本身就是**。另外，请注意，给定顺序的内存块的大小总是前一个顺序的两倍(下一个顺序的一半)。当然，这是因为它们都是 2 的幂。

Note that `MAX_ORDER` can (and does) vary with the architecture. On regular x86 and ARM systems, it's `11`, yielding a largest chunk size of 4 MB of physically contiguous RAM on order 10 of the freelists. On high-end enterprise server class systems running the Itanium (IA-64) processor, `MAX_ORDER` can be as high as `17` (implying a largest chunk size on order (17-1), thus of *2<sup>16</sup> = 65,536 pages = 512 MB chunks* of physically contiguous RAM on order 16 of the freelists, for a 4 KB page size). The IA-64 MMU supports up to eight page sizes ranging from a mere 4 KB right up to 256 MB. As another example, with a page size of 16 MB, the order 16 list could potentially have physically contiguous RAM chunks of size *65,536 * 16 MB = 1 TB* each!

另一个关键点:内核保留**多个 BSA 自由列表——每个节点一个:系统上存在的区域！**这为在 NUMA 系统上分配内存提供了一种自然的方式。

下图显示了内核如何实例化多个自由列表–*每个节点一个:系统上存在的区域*(图学分:*专业 Linux 内核架构*，莫勒，Wrox Press，2008 年 10 月):

![](Images/c0fe0659-be5d-4ce4-afd3-48ed835b4a2c.png)

Figure 8.4 – Page allocator (BSA) "freelists," one per node:zone on the system; diagram credit: Professional Linux Kernel Architecture, Mauerer, Wrox Press, Oct 2008

此外，如图 8.5 所示，当内核通过页面分配器被调用来分配内存时，它会选择最佳空闲列表来分配内存——这个列表与请求请求的线程运行的节点相关联(回想一下上一章的 NUMA 架构)。如果这个节点内存不足，或者由于某种原因无法分配内存，那么内核会使用一个后备列表来确定尝试从哪个空闲列表中分配内存。(现实中，真实的画面更加复杂；我们在*页面分配器内部提供了更多细节–更多细节*部分。)

现在让我们理解(在概念上)所有这些实际上是如何工作的。

### 页面分配器的工作原理

实际的(去)分配策略可以用一个简单的例子来解释。假设一个设备驱动程序请求 128 KB 的内存。为了满足这个请求，(简化的和概念性的)页面分配器算法将这样做:

1.  该算法以页为单位表示要分配的数量(此处为 128 KB)。因此，这里是(假设页面大小 4 KB) *128/4 = 32 页*。
2.  接下来，它确定必须将 2 的幂提高到多少才能得到 32。那是*log**<sub>2</sub>**32*，也就是 5(因为 2 <sup>5</sup> 是 32)。
3.  现在，它检查适当的*节点顺序 5 上的列表:区域*页面分配器自由列表。如果内存块可用(其大小为*2**T5**页面= 128 KB* ，将其从列表中出列，更新列表，并将其分配给请求者。任务完成！回复来电者。

Why do we say *of the appropriate node:zone* *page allocator freelist*? Does that mean there's more than one of them? Yes, indeed! We repeat: the reality is that there will be several freelist data structures, one each per *node:zone* on the system. (Also see more details in the section *Page allocator internals – a few more details*.)

4.  如果在顺序 5 列表中没有可用的内存块(也就是说，如果它为空)，那么它在下一个顺序中检查列表；也就是顺序 6 链表(如果不是空的，它会有 *2 <sup>6</sup>* *页面= 256 KB* 内存块在上面排队，每个块都是我们想要的大小的两倍)。
5.  如果 order 6 列表为非空，那么它将从其中取出(出列)一大块内存(大小为 256 KB，是所需大小的两倍)，并执行以下操作:
    *   更新列表以反映一个块现在被移除的事实。
    *   把组块切成两半，这样就得到两个 128 KB 的一半或者**哥们**！(请参见以下信息框。)
    *   将一半(大小为 128 KB)迁移(入队)到订单 5 列表。
    *   将另一半(大小为 128 KB)分配给请求者。
    *   任务完成！回复来电者。
6.  如果顺序 6 列表也是空的，那么它用顺序 7 列表重复前面的过程，以此类推，直到成功。
7.  如果所有剩余的高阶列表都为空(null)，则请求将失败。

We can cut or slice a memory chunk in half because every chunk on the list is guaranteed to be physically contiguous memory. Once cut, we have two halves; each is called a **buddy block**, hence the name of this algorithm. Pedantically, it's called the binary buddy system as we use power-of-2-sized memory chunks. A buddy block is defined as a block that is of the same size and physically adjacent to another.

你会明白前面的描述是概念性的。实际的代码实现当然更加复杂和优化。顺便说一句，代码——正如评论中提到的那样，分区好友分配器*的*核心在这里:`mm/page_alloc.c:__alloc_pages_nodemask()`。超出了本书的范围，我们不会试图深入分配器的代码级细节。**

 *### 通过几个场景

既然我们已经有了算法的基础，让我们考虑几个场景:首先，一个简单直接的例子，然后，几个更复杂的例子。

#### **最简单的情况**

假设内核空间设备驱动程序(或一些核心代码)请求 128 KB，并从自由列表数据结构之一的 5 阶列表中接收内存块。在稍后的某个时间点，它将通过使用一个页面分配器释放 API 来释放内存块。现在，这个应用编程接口的算法通过其顺序计算出刚刚释放的块属于顺序 5 列表；因此，它在那里排队。

#### **更复杂的情况**

现在，假设与前面的简单情况不同，当设备驱动程序请求 128 KB 时，订单 5 列表为空；因此，根据页面分配器算法，我们转到下一个顺序的列表 6，并检查它。假设它是非空的；该算法现在将一个 256 KB 的数据块出列，并将其拆分(或切割)成两半。现在，一半(大小为 128 KB)给了请求者，剩下的一半(同样大小为 128 KB)被排队到订单 5 列表中。

伙伴系统真正有趣的特性是当请求者(设备驱动程序)在稍后的某个时间点释放内存块时会发生什么。正如预期的那样，算法计算(通过其顺序)刚刚释放的块属于顺序 5 列表。但是在那里盲目入队之前，**它寻找它的伙伴块**，在这种情况下，它(可能)找到了！现在，它将两个伙伴块合并成一个更大的块(大小为 256 KB)，并将合并后的块放入*订单 6* 列表中。这太棒了——它实际上帮助整理了内存！

#### **败落案**

现在让我们不要使用方便的 2 次方大小作为要求，让它变得有趣起来。这一次，假设设备驱动程序请求大小为 132 KB 的内存块。好友系统分配器会怎么做？当然，由于它分配的内存不能少于请求的数量，所以它分配了更多的内存——你猜对了(参见*图 8.2* ，下一个可用的内存块是 7 阶的，大小为 256 KB。但是消费者(驱动程序)只会看到并使用分配给它的 256 KB 区块中的第一个 132 KB。剩下的(124 KB)浪费了(想想看，那接近 50%的浪费！).这叫**内部碎片化(或损耗)**是二元哥们系统的致命败笔！

You will learn, though, that there is indeed a mitigation to this: a patch was contributed to deal with similar scenarios (via the `alloc_pages_exact() / free_pages_exact()` APIs). We will cover the APIs to use the page allocator shortly.

### 页面分配器内部——更多细节

在本书中，我们不打算深入研究页面分配器内部的代码级细节。话虽如此，事情是这样的:就数据结构而言，`zone`结构包含一组`free_area`结构。这是有道理的；如您所知，系统上可以(通常是)有多个页面分配器空闲列表，每个节点一个:

```sh
// include/linux/mmzone.h
struct zone { 
    [ ... ] 
    /* free areas of different sizes */
    struct free_area free_area[MAX_ORDER];
    [ ... ]
};
```

`free_area`结构是双向链接循环列表(该节点区域内的空闲内存页面帧)以及当前空闲页面帧数量的实现；

```sh
struct free_area {
    struct list_head free_list[MIGRATE_TYPES];
    unsigned long nr_free;
};
```

为什么它是一个链表数组而不仅仅是一个列表？在不深究细节的情况下，我们会提到，实际上，好友系统 freelist 的内核布局比我们到目前为止所了解到的还要复杂:从 2.6.24 内核开始，我们看到的每个 freelist 实际上都被进一步细分为多个 freelist，以迎合不同的*页面迁移类型*。当试图保持内存碎片整理时，这是处理复杂情况所必需的。除此之外，如前所述，这些自由列表存在于系统上的每个*节点:区域*。例如，在一个有 4 个节点和每个节点 3 个区域的实际 NUMA 系统上，将有 12 个(4 x 3)自由列表。不仅如此，每个自由列表实际上被进一步细分为 6 个自由列表，每个迁移类型一个。因此，在这样一个系统中，总共有 *6 x 12 = 72* 个自由列表数据结构存在于整个系统中！

If you are interested, dig into the details and check out the output of `/proc/buddyinfo` – a nice summary view of the state of the buddy system freelists (as Figure 8.3 shows). Next, for a more detailed and realistic view (of the type mentioned previously, showing *all* the freelists), look up `/proc/pagetypeinfo` (requires root access) – it shows all the freelists (broken up into page migration types as well).

页面分配器(伙伴系统)算法的设计是最适合的类之一。它的主要好处是在系统运行时帮助整理物理内存。简单来说，它的利弊如下。

页面分配器(伙伴系统)算法的优点如下:

*   帮助整理内存碎片(防止外部碎片)
*   保证物理上连续的内存块的分配
*   保证中央处理器高速缓存行对齐的内存块
*   快(嗯，够快；算法时间复杂度为 *O(log n)* )

另一方面，到目前为止最大的缺点是内部分裂或浪费可能太高。

好极了。我们已经介绍了大量关于页面或伙伴系统分配器内部工作的背景材料。动手的时间到了:现在让我们深入了解并使用页面分配器 API 来分配和释放内存。

## 学习如何使用页面分配器 API

Linux 内核通过页面分配器提供(向内核和模块公开)一组分配和释放内存的应用编程接口。这些通常被称为低级(去)分配器例程。下表总结了页面分配 APIs 你会注意到所有的 API 或者宏都有两个参数，第一个参数叫做 *GFP 标志或者位掩码*；我们将很快详细解释它，请暂时忽略它。第二个参数是`order`*——自由列表的顺序，也就是分配的内存量是 2 <sup>顺序</sup>页框。所有原型可在`include/linux/gfp.h`中找到:*

 *| **API 或宏名称** | **评论** | **API 签名或宏** |
| `__get_free_page()` | 只分配一个页面框架。分配的内存将具有随机内容；它是`__get_free_pages()` API 的包装器。返回值是指向刚刚分配的内存的内核逻辑地址的指针。 | `#define __get_free_page(gfp_mask) \ __get_free_pages((gfp_mask), 0)` |
| `__get_free_pages()` | 分配 *2 <sup>顺序</sup>T3】物理上连续的页面框架。分配的内存将具有随机内容；返回值是指向刚刚分配的内存内核逻辑地址的指针。* | `unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order);` |
| `get_zeroed_page()` | 只分配一个页面框架；其内容设置为 ASCII 零(`NULL`；也就是说，它归零了)；返回值是指向刚刚分配的内存内核逻辑地址的指针。 | `unsigned long get_zeroed_page(gfp_t gfp_mask);` |
| `alloc_page()` | 只分配一个页面框架。分配的内存将具有随机内容；`alloc_pages()`应用编程接口的包装；返回值是指向刚刚分配的内存的`page`元数据结构的指针；可以通过`page_address()`函数将其转换为内核逻辑地址。 | `#define alloc_page(gfp_mask) \ alloc_pages(gfp_mask, 0)` |
| `alloc_pages()` | 分配 *2 <sup>顺序</sup>T5】物理上连续的页面框架。分配的内存将具有随机内容；返回值是指向刚分配的内存的`page`元数据结构的开始的指针；可以通过`page_address()`函数将其转换为内核逻辑地址。* | `struct page *
alloc_pages(gfp_t gfp_mask, unsigned int order);` |

Table 8.1 – Low-level (BSA/page) allocator – popular exported allocation APIs

所有前面的 API 都被导出(通过`EXPORT_SYMBOL()`宏)，因此内核模块和设备驱动程序开发人员可以使用。别担心，你很快就会看到一个演示使用它们的内核模块。

Linux 内核认为维护一个(小的)元数据结构来跟踪内存的每一页帧是值得的。这叫做`page`结构。这里的要点是，要小心:与返回指向新分配的内存块开始的指针(虚拟地址)的通常语义不同，请注意前面提到的`alloc_page()`和`alloc_pages()`API 是如何返回指向新分配的内存页面结构开始的指针的，而不是内存块本身(就像其他 API 一样)。您必须通过调用返回的页面结构地址上的`page_address()`应用编程接口来获取指向新分配内存开始的实际指针。*中的示例代码使用页面分配器应用接口*部分编写一个内核模块来演示将说明所有上述应用接口的用法。

然而，在我们能够使用这里提到的页面分配器 API 之前，我们必须至少了解关于**获取免费页面** ( **GFP** )标志的基础知识，这是接下来部分的主题。

### 处理绿色和平旗帜

您会注意到所有先前分配器 API(或宏)的第一个参数是`gfp_t gfp_mask`。这是什么意思？本质上，这些是绿色荧光蛋白标志*。*这些是内核内部内存管理代码层使用的标志(有几个)。出于所有实际目的，对于典型的内核模块(或设备驱动程序)开发人员来说，只有两个 GFP 标志是至关重要的(如前所述，其余的用于内部使用)。它们如下:

*   `GFP_KERNEL`
*   `GFP_ATOMIC`

当通过页面分配器 API 执行内存分配时，决定使用哪一个很重要；要永远记住的一个关键规则如下:

*如果在进程上下文中并且可以安全睡眠，使用 GFP_KERNEL 标志。如果睡眠不安全(通常是在任何类型的原子或中断上下文中)，则必须使用 GFP_ATOMIC 标志。*

遵循前面的规则至关重要。如果做错了，可能会导致整个机器冻结、内核崩溃和/或随机的坏事情发生。那么*安全/不安全睡觉*的说法到底是什么意思呢？为了这个和更多，我们遵从*GFP 旗帜-深入挖掘*部分。虽然*很重要，但*真的很重要，所以我绝对推荐你读一下。

**Linux Driver Verification** (**LDV**) project: back in [Chapter 1](01.html), *Kernel Workspace Setup*, in the The LDV - Linux Driver Verification - project section, we mentioned that this project has useful "rules" with respect to various programming aspects of Linux modules (drivers, mostly) as well as the core kernel.

With regard to our current topic, here's one of the rules, a negative one, implying that you *cannot* do this: *"Using a blocking memory allocation when spinlock is held"* ([http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0043](http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0043)). When holding a spinlock, you're not allowed to do anything that might block; this includes kernel-space memory allocations. Thus, very important, you must use the `GFP_ATOMIC` flag when performing a memory allocation in any kind of atomic or non-blocking context, like when holding a spinlock (you will learn that this isn't the case with the mutex lock; you are allowed to perform blocking activities while holding a mutex). Violating this rule leads to instability and even raises the possibility of (an implicit) deadlock. The LDV page mentions a device driver that was violating this very rule and the subsequent fix ([https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=5b0691508aa99d309101a49b4b084dc16b3d7019](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=5b0691508aa99d309101a49b4b084dc16b3d7019)). Take a look: the patch clearly shows (in the context of the `kzalloc()` API, which we shall soon cover) the `GFP_KERNEL` flag being replaced with the `GFP_ATOMIC` flag.

另一个常用的 GFP 标志是`__GFP_ZERO`。它的用法暗示内核你想要清零的内存页面。它通常与`GFP_KERNEL`或`GFP_ATOMIC`标志按位“或”，以便将初始化的内存返回到零。

The kernel developers do take the trouble to document the GFP flags in detail. Take a look in `include/linux/gfp.h`. Within it, there's a long and detailed comment; it's headed `DOC: Useful GFP flag combinations`.

现在，为了让我们快速入门，请理解使用带有`GFP_KERNEL`标志的 Linux 内核内存分配 API 确实是内核内部分配的常见情况。

### 用页面分配器释放页面

当然，分配内存的另一面是释放内存。内核中的内存泄漏绝对不是你想造成的。对于*表 8.1**所示的页面分配器 API，这里有相应的免费 API:*

 *| **API 或宏名称** | comment | **API 签名或宏** |
| `free_page()` | 释放通过`__get_free_page()`、`get_zeroed_page()`或`alloc_page()`API 分配的(单个)页面；这是对`free_pages()`应用编程接口的简单包装 | `#define free_page(addr) __free_pages((addr), 0)` |
| `free_pages()` | 释放通过`__get_free_pages()`或`alloc_pages()`API 分配的多个页面(它实际上是`__free_pages()`的包装器)。) | `void free_pages(unsigned long addr, unsigned int order)` |
| `__free_pages()` | (*同上一行，加上*)这是完成工作的基础例程；另外，注意第一个参数是指向`page`元数据结构的指针。 | `void __free_pages(struct page *page, unsigned int order)` |

Table 8.2 – Common free page(s) APIs to use with the page allocator

可以看到前面函数中实际的底层 API 是`free_pages()`，它本身只是`mm/page_alloc.c:__free_pages()`代码的一个包装器。`free_pages()`应用编程接口的第一个参数是指向被释放的内存块的开始的指针；这当然是分配例程的返回值。然而，底层 API 的第一个参数`__free_pages()`是指向正在被释放的内存块的开始的*页面*元数据结构的指针。

Generally speaking, unless you really know what you are doing, you're definitely advised to invoke the `foo()` wrapper routine and not its internal `__foo()` routine. One reason to do so is simply correctness (perhaps the wrapper uses some necessary synchronization mechanism - like a lock - prior to invoking the underlying routine). Another reason to do so is validity checking (which helps code remain robust and secure). *O*ften, the `__foo()` routines bypass validity checks in favor of speed.

所有有经验的 C/C++应用开发人员都知道，分配和随后释放内存是一个丰富的 bug 来源！这主要是因为就内存而言，C 是一种非托管语言；因此，你可以找到各种各样的内存缺陷。其中包括众所周知的内存泄漏、读/写缓冲区溢出/下溢、双自由以及**空闲后使用** ( **UAF** )错误。

不幸的是，在内核空间中没有什么不同；只是后果(要)糟糕得多！格外小心！请务必确保以下几点:

*   支持将分配的内存初始化为零的例程。
*   在执行分配时，考虑并使用适当的 GFP 标志——在*GFP 标志——深入研究*一节中对此有更多说明，但简单地说，请注意以下几点:
    *   当处于可以安全睡眠的过程环境中时，使用`GFP_KERNEL`。
    *   在原子上下文中，如处理中断时，使用`GFP_ATOMIC`。
*   当使用页面分配器时(就像我们现在所做的那样)，尽可能保持分配大小为 2 的整数次方(同样，这背后的原理和减轻这种情况的方法——当你不需要那么多内存时，典型的情况——将在本章后面的章节中详细介绍)。
*   您只尝试释放之前分配的内存；不用说，不要错过释放它，也不要双重释放它。
*   保持原始内存块的指针安全，不被重用、操纵(`ptr ++`或类似的东西)和损坏，以便在完成后可以正确释放它。
*   检查(并重新检查！)传递给 API 的参数。是需要指向先前分配的块的指针，还是指向其底层`page`结构的指针？

Finding it difficult and/or worried about issues in production? Don't forget, you have help! Do learn how to use powerful static analysis tools found within the kernel itself (Coccinelle, `sparse` and others, such as `cppcheck` or `smatch`). For dynamic analysis, learn how to install and use **KASAN** (the **Kernel Address Sanitizer**).

Recall the Makefile template I provided in [Chapter 5](05.html), *Writing Your First Kernel Module – LKMs Part 2*, in the *A better Makefile template* section. It contains targets that use several of these tools; please do use it!

好了，现在我们已经讨论了页面分配器的(通用)分配和免费 API，是时候将这些知识付诸实践了。让我们写一些代码！

### 使用页面分配器 API 编写内核模块进行演示

现在让我们开始接触到目前为止我们已经了解到的低级页面分配器和免费 API。在这一节中，我们将展示相关的代码片段，然后是来自我们的演示内核模块(`ch8/lowlevel_mem/lowlevel_mem.c`)的解释。

在我们的小 LKM 的初级工作例程`bsa_alloc()`中，我们突出显示了(粗体)代码注释，这些注释显示了我们正在努力实现的目标。需要注意的几点:

1.  首先，我们做了一件非常有趣的事情:我们使用我们的小内核“库”函数`klib_llkd.c:show_phy_pages()`来字面上向您展示物理 RAM 页面帧是如何在内核 lowmem 区域中被标识映射到内核虚拟页面的！(很快将讨论`show_phy_pages()`例程的确切工作方式):

```sh
// ch8/lowlevel_mem/lowlevel_mem.c
[...]
static int bsa_alloc(void)
{
    int stat = -ENOMEM;
    u64 numpg2alloc = 0;
    const struct page *pg_ptr1;

    /* 0\. Show the identity mapping: physical RAM page frames to kernel virtual
     * addresses, from PAGE_OFFSET for 5 pages */
    pr_info("%s: 0\. Show identity mapping: RAM page frames : kernel virtual pages :: 1:1\n", OURMODNAME);
    show_phy_pages((void *)PAGE_OFFSET, 5 * PAGE_SIZE, 1);
```

2.  接下来，我们通过底层的`__get_free_page()`页面分配器 API(我们之前在*表 8.1* 中看到的)分配一页内存:

```sh
  /* 1\. Allocate one page with the __get_free_page() API */
  gptr1 = (void *) __get_free_page(GFP_KERNEL);
  if (!gptr1) {
        pr_warn("%s: __get_free_page() failed!\n", OURMODNAME);
        /* As per convention, we emit a printk above saying that the
         * allocation failed. In practice it isn't required; the kernel
         * will definitely emit many warning printk's if a memory alloc
         * request ever fails! Thus, we do this only once (here; could also
         * use the WARN_ONCE()); from now on we don't pedantically print any
         * error message on a memory allocation request failing. */
        goto out1;
  }
  pr_info("%s: 1\. __get_free_page() alloc'ed 1 page from the BSA @ %pK (%px)\n",
      OURMODNAME, gptr1, gptr1);
```

注意我们如何发出一个显示内核逻辑地址的`printk`函数。回想一下上一章，这是页面分配器内存，位于内核段/VAS 的直接映射内存或低内存区域。

Now, for security, we should consistently, and only, use the `%pK` format specifier when printing kernel addresses so that a hashed value and not the real virtual address shows up in the kernel logs. However, here, in order to show you the actual kernel virtual address, we also use the `%px` format specifier (which, like the `%pK`, is portable as well; for security, please don't use the `%px` format specifier in production!).

接下来，注意第一个`__get_free_page()` API(在前面的片段中)发出后的详细注释。它提到了这样一个事实，即您不必打印内存不足的错误或警告消息。(好奇？要了解原因，请访问[https://lkml.org/lkml/2014/6/10/382](https://lkml.org/lkml/2014/6/10/382)。)在这个示例模块中(和前面的几个模块一样，接下来还会有更多模块)，我们通过使用适当的 printk 格式说明符(如`%zd`、`%zu`、`%pK`、`%px`和`%pa`)为可移植性对我们的 printk(或`pr_foo()`宏)实例进行编码。

3.  让我们继续使用页面分配器进行第二次内存分配；请参见下面的代码片段:

```sh
/*2\. Allocate 2^bsa_alloc_order pages with the __get_free_pages() API */
  numpg2alloc = powerof(2, bsa_alloc_order); // returns 2^bsa_alloc_order
  gptr2 = (void *) __get_free_pages(GFP_KERNEL|__GFP_ZERO, bsa_alloc_order);
  if (!gptr2) {
      /* no error/warning printk now; see above comment */
      goto out2;
  }
  pr_info("%s: 2\. __get_free_pages() alloc'ed 2^%d = %lld page(s) = %lld bytes\n"
      " from the BSA @ %pK (%px)\n",
      OURMODNAME, bsa_alloc_order, powerof(2, bsa_alloc_order),
      numpg2alloc * PAGE_SIZE, gptr2, gptr2);
  pr_info(" (PAGE_SIZE = %ld bytes)\n", PAGE_SIZE);
```

在前面的代码片段中(参见代码注释)，我们已经通过页面分配器的`__get_free_pages()` API 分配了 2 <sup>3</sup> ，也就是 8 页内存(作为我们模块参数`bsa_alloc_order`的默认值，是`3`)。

An aside: notice that we use the `GFP_KERNEL|__GFP_ZERO` GFP flags to ensure that the allocated memory is zeroed out, a best practice. Then again, zeroing out large memory chunks can result in a slight performance hit.

现在，我们问自己这样一个问题:有没有一种方法可以验证内存是否真的是物理连续的(就像承诺的那样)？事实证明，是的，我们实际上可以检索并打印出每个分配的页面帧开始的物理地址，并检索其**页面帧号** **(PFN** **)** 。

The **PFN** is a simple concept: it's just the index or page number – for example, the PFN of physical address 8192 is 2 (*8192/4096*). As we've shown how to (and importantly, when you can) translate kernel virtual addresses to their physical counterparts earlier (and vice versa; this coverage is in [Chapter 7](07.html), *Memory Management Internals – Essentials*, in the *Direct-mapped RAM and address translation* section), we won't repeat it here.

为了完成将虚拟地址转换为物理地址并检查连续性的工作，我们编写了一个小的“库”函数，它保存在本书 GitHub 源代码树根的一个单独的 C 文件中，`klib_llkd.c`。我们的意图是修改我们的内核模块的 Makefile 来链接这个库文件的代码！(在*通过多个源文件执行库仿真*一节中的[第 5 章](05.html)、*编写您的第一个内核模块–LKMs 第 2 部分*中已经介绍了正确执行此操作。)下面是我们对库例程的调用(就像在步骤 0 中所做的那样):

```sh
show_phy_pages(gptr2, numpg2alloc * PAGE_SIZE, 1);
```

以下是我们库例程的代码(在`<booksrc>/klib_llkd.c`源文件中；同样，为了清楚起见，我们不会在这里显示整个代码):

```sh
// klib_llkd.c
[...]
/* show_phy_pages - show the virtual, physical addresses and PFNs of the memory range provided on a per-page basis.
 * @kaddr: the starting kernel virtual address
 * @len: length of the memory piece (bytes)
 * @contiguity_check: if True, check for physical contiguity of pages
 * 'Walk' the virtually contiguous 'array' of pages one by one (that is, page by page),  
 * printing the virt and physical address (and PFN- page frame number). This way, we can see 
 * if the memory really is *physically* contiguous or not
 */
void show_phy_pages(const void *kaddr, size_t len, bool contiguity_check)
{
    [...]
    if (len % PAGE_SIZE)
        loops++;
    for (i = 0; i < len/PAGE_SIZE; i++) {
        pa = virt_to_phys(vaddr+(i*PAGE_SIZE));
 pfn = PHYS_PFN(pa);

        if (!!contiguity_check) {
        /* what's with the 'if !!(<cond>) ...' ??
         * a 'C' trick: ensures that the if condition always evaluates
         * to a boolean - either 0 or 1 */
            if (i && pfn != prev_pfn + 1)
                pr_notice(" *** physical NON-contiguity detected ***\n");
        }
        pr_info("%05d 0x%px %pa %ld\n", i, vaddr+(i*PAGE_SIZE), &pa, pfn);
        if (!!contiguity_check)
            prev_pfn = pfn;
    }
}
```

研究前面的函数。我们遍历给定的内存范围，(虚拟)一页接一页，获得物理地址和 PFN，然后通过 printk 发出(注意我们如何使用`%pa`格式说明符端口打印一个*物理地址* -它需要通过引用传递)。不仅如此，如果第三个参数`contiguity_check`*是`1`，我们会检查 pfn 之间是否只有一个数字的间隔，从而检查页面在物理上是否确实是连续的。(顺便说一下，我们使用的简单`powerof()`函数也在我们的库代码中。)*

*Hang on, though, a key point: having kernel modules working with physical addresses is *highly discouraged*. Only the kernel's internal memory management code works directly with physical addresses. There are very few real-world cases of even hardware device drivers using physical memory directly (DMA is one, and using the `*ioremap*` APIs another).

We only do so here to prove a point – that the memory allocated by the page allocator (with a single API call) is physically contiguous. Also, do realize that the `virt_to_phys()`(and friends) APIs that we employ are guaranteed to work *only* on direct-mapped memory (the kernel lowmem region) and nothing else (not the `vmalloc` range, the IO memory ranges, bus memory, DMA buffers, and so on).

4.  现在，让我们继续内核模块代码:

```sh
    /* 3\. Allocate and init one page with the get_zeroed_page() API */
    gptr3 = (void *) get_zeroed_page(GFP_KERNEL);
    if (!gptr3)
        goto out3;
    pr_info("%s: 3\. get_zeroed_page() alloc'ed 1 page from the BSA @ %pK (%px)\n", 
        OURMODNAME, gptr3, gptr3);
```

正如在前面的片段中看到的，我们分配了一页内存，但是通过使用 PA `get_zeroed_page()` API 确保它被清零。`pr_info()`显示散列的和实际的 kva(使用`%pK`或`%px`也以可端口的方式打印地址，无论您运行的是 32 位还是 64 位系统。)

5.  接下来，我们用`alloc_page()` API 分配一个页面。小心点！它不返回指向已分配页面的指针，而是返回指向表示已分配页面的元数据结构`page`的指针；下面是函数签名:`struct page * alloc_page(gfp_mask)`。因此，我们使用`page_address()`助手将其转换为内核逻辑(或虚拟)地址:

```sh
/* 4\. Allocate one page with the alloc_page() API.
 pg_ptr1 = alloc_page(GFP_KERNEL);
 if (!pg_ptr1)
     goto out4;

 gptr4 = page_address(pg_ptr1);
 pr_info("%s: 4\. alloc_page() alloc'ed 1 page from the BSA @ %pK (%px)\n"
         " (struct page addr=%pK (%px)\n)",
        OURMODNAME, (void *)gptr4, (void *)gptr4, pg_ptr1, pg_ptr1);
```

在前面的代码片段中，我们通过`alloc_page()` PA API 分配了一页内存。如上所述，我们需要通过`page_address()` API 将它返回的页面元数据结构转换成 KVA(或内核逻辑地址)。

6.  接下来，使用`alloc_pages()` API 分配和`init`T2】2^3 = 8 页。与前面代码片段相同的警告也适用于此:

```sh
 /* 5\. Allocate and init 2^3 = 8 pages with the alloc_pages() API.
 gptr5 = page_address(alloc_pages(GFP_KERNEL, 3));
 if (!gptr5)
     goto out5;
 pr_info("%s: 5\. alloc_pages() alloc'ed %lld pages from the BSA @ %pK (%px)\n", 
     OURMODNAME, powerof(2, 3), (void *)gptr5, (void *)gptr5);
```

在前面的代码片段中，我们组合了包装在`page_address()` API 中的`alloc_pages()`来分配 *2^3 = 8* 页的内存！

有趣的是，我们在代码中使用了几个本地`goto`语句(请查看回购中的代码)。仔细观察它，你会注意到它实际上保持了错误处理代码路径的干净和逻辑。这确实是 Linux 内核编码风格指南的一部分。

Usage of the (sometimes controversial) `goto` is clearly documented right here: [https://www.kernel.org/doc/html/v5.4/process/coding-style.html#centralized-exiting-of-functions](https://www.kernel.org/doc/html/v5.4/process/coding-style.html#centralized-exiting-of-functions). I urge you to check it out! Once you understand the usage pattern, you'll find that it helps reduce the all-too-typical memory leakage (and similar) cleanup errors!

7.  最后，在清理方法中，在从内核内存中移除之前，我们会释放刚刚在内核模块的清理代码中分配的所有内存块。
8.  为了将我们的库`klib_llkd`代码与我们的`lowlevel_mem` 内核模块链接起来，Makefile 更改为具有以下内容(回想一下我们在[第 5 章](05.html)、*编写您的第一个内核模块–LKMs 第 2 部分*中的*通过多个源文件执行库仿真*一节中了解到的将多个源文件编译到单个内核模块中的内容):

```sh
 PWD                   := $(shell pwd)
 obj-m                 += lowlevel_mem_lkm.o
 lowlevel_mem_lkm-objs := lowlevel_mem.o ../../klib_lkdc.o
 EXTRA_CFLAGS          += -DDEBUG
```

同样，在这个 LKM 示例中，我们经常使用`%px` printk 格式说明符，这样我们就可以看到实际的虚拟地址，而不是散列值(内核安全特性)。这里没问题，但不要在生产中这样做。

唷！这是相当多的报道。一定要确保你理解代码，然后继续阅读，看看它在行动。

### 部署我们的底层内存内核模块

好了，是时候看看我们的内核模块了！让我们在树莓 Pi 4(运行默认树莓 Pi 操作系统)和 x86_64 虚拟机(运行 Fedora 31)上构建和部署它。

在树莓 Pi 4 模型 B 上(这里运行树莓 Pi 内核版本 5.4.79-v7l+)，我们构建然后`insmod(8)`我们的`lowlevel_mem_lkm` 内核模块。以下屏幕截图显示了输出:

![](Images/16618eff-3a73-4cdc-91a0-a198c5fe4700.png)

Figure 8.5 – The lowlevel_mem_lkm kernel module's output on a Raspberry Pi 4 Model B

快看。在图 8.6 输出的第 0 步中，我们的`show_phy_pages()`库例程清楚地显示了 KVA `0xc000 0000`有 PA `0x0`，KVA `0xc000 1000`有 pa `0x1000`等等，共五页(连同右边的 PFN)；你可以看到物理 RAM 页面帧到内核虚拟页面的 1:1 身份映射(在内核段的 lowmem 区域)！

接下来，使用`__get_free_page()`应用编程接口的初始内存分配按预期进行。更有趣的是我们的案例 2。在这里，我们可以清楚地看到，每个分配页面的物理地址和 PFN(从 0 到 7，总共 8 个页面)是连续的，这表明分配的内存页面确实是物理连续的！

我们在运行 Ubuntu 20.04 的 x86_64 虚拟机上构建并运行相同的模块(运行我们定制的 5.4“调试”内核)。以下屏幕截图显示了输出:

![](Images/196e090d-1ed4-4c4e-9bc0-cdbefd40c57c.png)

Figure 8.6 – The lowlevel_mem_lkm kernel module's output on a x86_64 VM running Ubuntu 20.04

这一次(参考图 8.7)，由于`PAGE_OFFSET`值是 64 位的量(这里的值是`0xffff 8880 0000 0000`)，你可以再次清楚地看到物理 RAM 帧到内核虚拟地址的身份映射(5 页)。让我们花点时间仔细看看页面分配器 API 返回的内核逻辑地址。在图 8.7 中，可以看到它们都在`0xffff 8880 .... ....`范围内。以下片段来自`Documentation/x86/x86_64/mm.txt`的内核源代码树，记录了 x86_64 上的虚拟内存布局(一部分):

If this all seems new and strange to you, please refer to [Chapter 7](07.html), *Memory Management Internals – Essentials*, particularly the *Examining the kernel segment* and *Direct-mapped RAM and address translation* sections.

```sh
0000000000000000 - 00007fffffffffff (=47 bits) user space, different per mm hole caused by [47:63] sign extension
ffff800000000000 - ffff87ffffffffff (=43 bits) guard hole, reserved for hypervisor
ffff880000000000 - ffffc7ffffffffff (=64 TB) direct mapping of all phys. memory
ffffc80000000000 - ffffc8ffffffffff (=40 bits) hole
ffffc90000000000 - ffffe8ffffffffff (=45 bits) vmalloc/ioremap space
```

很清楚，不是吗？页面分配器内存(伙伴系统空闲列表)直接映射到内核 VAS 的直接映射或低内存区域内的空闲物理内存上。因此，它显然会从这个区域返回内存。您可以在前面的文档输出中看到这个区域(以粗体突出显示)——内核直接映射或 lowmem 区域。我再次强调一个事实，即所使用的特定地址范围是非常特定的。在前面的代码中，这是 x86_64 上的(最大可能)范围。

尽管声称页面分配器和它的 API 已经完成很有诱惑力，但事实是(像往常一样)情况并非如此。一定要读下去，看看为什么——理解这些方面真的很重要。

### 页面分配器和内部碎片

虽然表面上看起来一切都很好，很无辜，但我敦促你再深入一点。只是在表面下，一个巨大的(不愉快！)惊喜可能会等着你:幸福地不知道内核/驱动程序开发人员。我们之前介绍的关于页面分配器的 API(见*表 8.1* )有一个可疑的区别，那就是能够在内部分割——用更简单的话来说，**浪费**——内核内存中非常重要的部分！

要理解为什么会出现这种情况，您必须至少了解页面分配器算法及其 freelist 数据结构的基础知识。页面分配器的基本工作原理章节*介绍了这一点(以防你还没有阅读，请阅读)。*

在*的几个场景*部分中，您会看到，当我们对方便的、完美舍入的两页幂进行分配请求时，它进行得非常顺利。然而，当情况并非如此时——假设驱动程序请求 132 KB 的内存——那么我们最终会遇到一个主要问题:内部碎片或浪费非常高。这是一个严重的不利因素，必须加以解决。我们将从两个方面来看。一定要继续读下去！

#### 确切的页面分配器 API

意识到缺省页面分配器(或 BSA)内部巨大的浪费潜力，一位来自飞思卡尔半导体的开发人员(见信息框)为内核页面分配器提供了一个补丁，扩展了应用编程接口，增加了几个新的。

In the 2.6.27-rc1 series, on 24 July 2008, Timur Tabi submitted a patch to mitigate the page allocator wastage issue. Here's the relevant commit: [https://github.com/torvalds/linux/commit/2be0ffe2b29bd31d3debd0877797892ff2d91f4c](https://github.com/torvalds/linux/commit/2be0ffe2b29bd31d3debd0877797892ff2d91f4c).

使用这些应用编程接口可以更有效地分配大块(多页)内存**，同时减少浪费**。新的(嗯，它*至少是 2008 年的*新版本)分配和释放内存的 API 对如下:

```sh
#include <linux/gfp.h>
void *alloc_pages_exact(size_t size, gfp_t gfp_mask);
void free_pages_exact(void *virt, size_t size);
```

`alloc_pages_exact()` API 的第一个参数`size`以字节为单位，第二个参数是前面讨论的“通常”GFP 标志值(在*处理 GFP 标志*部分中)；`GFP_KERNEL`用于可能睡眠过程上下文情况，而`GFP_ATOMIC`用于从不睡眠中断或原子上下文情况)。

请注意，这个应用编程接口分配的内存仍然保证物理上是连续的。另外，一次可分配的金额(一次函数调用)受`MAX_ORDER`限制；事实上，到目前为止，我们看到的所有其他常规页面分配 API 都是如此。我们将在接下来的章节*中详细讨论 kmalloc API 的大小限制。*在这里，你会意识到讨论实际上不仅限于 slab 缓存，还包括页面分配器！

`free_pages_exact()`应用编程接口只能用于释放其对应的`alloc_pages_exact()`分配的内存。另外，请注意，“free”例程的第一个参数当然是匹配的“alloc”例程返回的值(指向新分配的内存块的指针)。

`alloc_pages_exact()`的实现简单而巧妙:它首先通过`__get_free_pages()` API“照常”分配请求的整个内存块。然后，它循环——从要使用的内存末尾到实际分配的内存量(通常要大得多)——释放那些不必要的内存页面！因此，在我们的例子中，如果您通过`alloc_pages_exact()`应用编程接口分配 132 千字节，它实际上会首先通过`__get_free_pages()`在内部分配 256 千字节，但随后会将内存从 132 千字节释放到 256 千字节！

开源之美的另一个例子！使用这些 API 的演示可以在这里找到:`ch8/page_exact_loop`；我们将把它留给你去试用。

在开始本节之前，我们提到有两种方法可以解决页面分配器的浪费问题。一种是通过使用更高效的`alloc_pages_exact()`和`free_pages_exact()`API，正如我们刚刚学到的；另一种是通过使用不同的层来分配内存——T2 板分配器。我们将很快覆盖它；在那之前，坚持住。接下来，让我们覆盖更多，对理解至关重要的*，关于(典型的)GFP 标志的细节，以及你，内核模块或驱动作者，应该如何使用它们。*

## 绿色和平组织的旗帜——深入挖掘

关于我们对低级页面分配器 API 的讨论，每个函数的第一个参数是所谓的 GFP 掩码。在讨论 API 及其用法时，我们提到了一个*关键规则*。

如果在*进程上下文中并且可以安全睡眠，*使用`GFP_KERNEL`标志。如果让*睡眠是*不安全的(通常，当处于任何类型的中断上下文中或持有某些类型的锁时)，您*必须使用*标志。**

 *我们将在接下来的章节中详细阐述这一点。

### 永远不要在中断或原子环境中睡觉

*安全入睡*这句话到底是什么意思？要回答这个问题，请考虑阻塞调用(APIs): 一个*阻塞调用*是一个调用进程(或线程)因为正在等待某个东西而进入睡眠状态的调用，一个*事件*，它正在等待的事件还没有发生。因此，它等待着——它“睡觉”。当它正在等待的事件在未来某个时间点发生或到达时，它会被内核唤醒并继续前进。

用户空间阻塞应用编程接口的一个例子包括`sleep(3)`。这里，它正在等待的事件是经过了一定的时间。另一个例子是`read(2)`及其变体，其中等待的事件是存储或网络数据变得可用。使用`wait4(2)`，等待的事件是子进程的死亡或停止/继续，等等。

因此，任何可能阻塞的函数最终都会花一些时间休眠(在休眠时，它肯定不在 CPU 运行队列中，而是在等待队列中)。在内核模式下调用这个*可能会阻塞*功能(当然，这是我们处理内核模块时的模式)只有在进程上下文中才允许*。* **在睡眠不安全的上下文中调用任何类型的阻塞调用都是一个错误，例如中断或原子上下文** *。*把这当成金科玉律。这也被称为在原子环境中睡觉——这是错误的，有问题的，而且它必须*永远不会*发生。

You might wonder, *how can I know in advance if my code will ever enter an atomic or interrupt context*? In one way, the kernel helps us out: when configuring the kernel (recall `make menuconfig` from [Chapter 2](02.html), *Building the 5.x Linux Kernel from Source - Part 1*), under the `Kernel Hacking / Lock Debugging` menu, there is a Boolean tunable called `"Sleep inside atomic section checking"`. Turn it on! (The config option is named `CONFIG_DEBUG_ATOMIC_SLEEP`; you can always grep your kernel config file for it. Again, in [Chapter 5](05.html), *Writing Your First Kernel Module - LKMs Part 2*, under the Configuring a "debug" kernel section, this is something you should definitely turn on.)

另一种看待这种情况的方式是你到底是怎么把一个流程或者线程给睡了？简单来说，就是让它调用调度代码——函数`schedule()`。因此，根据我们刚刚学到的东西(作为推论)，`schedule()`只能在睡眠安全的环境中调用；进程上下文通常是安全的，中断上下文从来不是。

这一点真的很重要要牢记！(我们在[第 4 章](04.html)、*编写您的第一个内核模块–LKMs 第 1 部分*、*进程和中断上下文*部分*、*中简要介绍了什么是进程和中断上下文，以及开发人员如何使用`in_task()`宏来确定代码当前是在进程还是中断上下文中运行。)同样，可以使用`in_atomic()`宏；如果代码是一个*原子上下文*——它通常必须不间断地运行到完成——它返回`True`；否则，`False`。您可以处于进程上下文中，但同时又是原子的——例如，当持有某些类型的锁(自旋锁；我们当然会在后面关于*同步*的章节中对此进行介绍；相反的情况不会发生。

除了我们关注的 GFP 标志之外，内核还有其他几个内部使用的`[__]GFP_*`标志；几个是为了明确的回收内存*。*包括(但不限于)`__GFP_IO`、`__GFP_FS`、`__GFP_DIRECT_RECLAIM`、`__GFP_KSWAPD_RECLAIM`、`__GFP_RECLAIM`、`__GFP_NORETRY`等。在这本书里，我们不打算深究这些细节。请参考`include/linux/gfp.h`中描述它们的详细注释(另请参见*进一步阅读*部分)。

**Linux Driver Verification** (**LDV**) project: back in [Chapter 1](01.html), *Kernel Workspace Setup*, we mentioned that this project has useful "rules" with respect to various programming aspects of Linux modules (drivers, mostly) as well as the core kernel.

With regard to our current topic, here's one of the rules, a negative one, implying that you *cannot* do this: *Not disabling IO during memory allocation while holding a USB device lock* ([http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0077](http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0077)). Some quick background: when you specify the `GFP_KERNEL` flag, it implicitly means (among other things) that the kernel can start an IO (Input/Output; reads/writes) operation to reclaim memory. The trouble is, at times this can be problematic and should not be done; to get over this, you're expected use the `GFP_NOIO` flag as part of the GFP bitmask when allocating kernel memory.

That's precisely the case that this LDV 'rule' is referring to: here, between the `usb_lock_device()` and `usb_unlock_device()` APIs, the `GFP_KERNEL` flag shouldn't be used and the `GFP_NOIO` flag should be used instead. (You can see several instances of this flag being used in this code: `drivers/usb/core/message.c`). The LDV page mentions the fact that a couple of USB-related code driver code source files were fixed to adhere to this rule.

好了，现在您已经掌握了页面分配器的大量细节(毕竟，它是内存(de)分配的内部“引擎”！)，它的 API，以及如何使用它们，让我们继续讨论一个非常重要的话题 slab 分配器背后的动机，它的 API，以及如何使用它们。

# 理解和使用内核板分配器

如本章第一节*介绍内核内存分配器时所见，**片层分配器*或*片层缓存*位于页面分配器(或 BSA 返回参考*图 8.1* 。平板分配器用两个主要的想法或目的来证明它的存在:

*   **对象缓存**:这里作为常用“对象”的缓存，以及 Linux 内核内频繁分配的数据结构的分配(以及后续的释放)，以获得高性能。

*   通过提供小的、方便大小的高速缓存，通常是页面的**片段**，减少页面分配器的高浪费(内部碎片)。

现在让我们以更详细的方式来检查这些想法。

## 对象缓存的想法

好的，我们从第一个设计思想开始——公共对象缓存的概念。很久以前，SunOS 开发人员杰夫·邦威克注意到，某些内核对象——通常是数据结构——在操作系统中经常被分配和释放。因此，他有了在缓存中预先分配它们的想法。这就演变成了我们所说的*平板缓存*。

因此，在 Linux 操作系统上，内核(作为启动时初始化的一部分)将相当大量的对象预分配到几个平板缓存中。原因:性能！当核心内核代码(或设备驱动程序)需要这些对象之一的内存时，它会直接请求 slab 分配器。如果缓存，分配几乎是立即的(反之亦然)。你可能会想，*这一切真的有必要吗*？的确如此！

需要高性能的一个很好的例子是网络和块 IO 子系统的关键代码路径。正是因为这个原因，几个网络和块 IO 数据结构(网络堆栈的套接字缓冲区、`sk_buff`、块层的`biovec`，当然还有核心`task_struct`数据结构或对象，就是几个很好的例子)是由内核在片缓存内自动缓存的*(*预分配的*)。类似地，文件系统元数据结构(如`inode`和`dentry`结构等)、内存描述符(`struct mm_struct`)以及更多的内存描述符都是*预先分配给片缓存的*。我们能看到这些缓存的对象吗？是的，再往下一点，我们将精确地做到这一点(通过`/proc/slabinfo`)。*

 *slab(或者现在更正确的说法是 SLUB)分配器性能优越的另一个原因是，传统的基于堆的分配器往往会分配和释放内存，从而产生“漏洞”(碎片)。因为 slab 对象被分配一次(在启动时)到缓存中，并在那里释放(因此没有真正“释放”出来)，所以性能仍然很高。当然，现代内核具有智能，可以在内存压力过大时，以优雅的方式开始释放平板缓存。

平板缓存的当前状态——对象缓存、缓存中的对象数量、使用中的数量、每个对象的大小等等——可以通过几种方式查看:通过`proc`和`sysfs`文件系统的原始视图，或者通过各种前端实用程序(如`slabtop(1)`、`vmstat(8)`和`slabinfo`)的更易于阅读的视图。在下面的代码片段中，在运行 Ubuntu 18.04 LTS 的本机 x86_64(内存为 16 GB)上，我们查看了`/proc/slabinfo`的前 10 行输出:

```sh
$ sudo head /proc/slabinfo 
slabinfo - version: 2.1
# name <active_objs> <num_objs> <objsize> <objperslab> <pagesperslab> : tunables <limit> <batchcount> <sharedfactor> : slabdata <active_slabs> <num_slabs> <sharedavail>
lttng_event     0     0     280   29   2 : tunables 0 0 0 : slabdata 0 0 0
kvm_async_pf    0     0     136   30   1 : tunables 0 0 0 : slabdata 0 0 0
kvm_vcpu        0     0   24576    1   8 : tunables 0 0 0 : slabdata 0 0 0
kvm_mmu_page_header 0 0     168   24   1 : tunables 0 0 0 : slabdata 0 0 0
pte_list_desc   0     0      32  128   1 : tunables 0 0 0 : slabdata 0 0 0
i915_request  112   112     576   28   4 : tunables 0 0 0 : slabdata 4 4 0
ext4_groupinfo_4k 6482 6496 144   28   1 : tunables 0 0 0 : slabdata 232 232 0
scsi_sense_cache 325 416 128 32 1 : tunables 0 0 0 : slabdata 13 13 0
```

需要注意的几点:

*   即使读取`/proc/slabinfo`也需要根访问(因此，我们使用`sudo(8)`)。
*   在前面的输出中，最左边的列是板缓存的名称。它经常(但不总是)匹配它缓存的内核中实际数据结构的名称。
*   接下来，对于每个缓存，信息采用以下格式:`<statistics> : <tunables> : <slabdata>`。标题行中显示的每个字段的含义在`slabinfo(5)`的手册页中有所解释(使用`man 5 slabinfo`查找)。

顺便说一下，`slabinfo`实用程序是用户空间代码*的一个例子，它位于`tools/`目录下的*内核源代码树中(其他几个也是)。它显示一组板层统计数据(使用`-X`开关试试)。要构建它，请执行以下操作:

```sh
cd <ksrc-tree>/tools/vm
make slabinfo
```

此时你可能会有一个问题，*平板缓存目前总共使用了多少内存*？这很容易通过在`Slab:`条目中输入`/proc/meminfo`来回答，如下所示:

```sh
$ grep "^Slab:" /proc/meminfo
Slab:            1580772 kB
```

显而易见，平板缓存可以使用大量内存！事实上，这是 Linux 上的一个常见特性，让那些对它不熟悉的人感到困惑:内核可以并将使用内存来实现缓存目的，从而大大提高性能。当然，它旨在随着内存压力的增加，智能地减少用于缓存的内存量。在常规的 Linux 系统上，很大一部分内存可以用于缓存(尤其是*页面缓存；*它用于在对文件执行输入输出时缓存文件内容。这样也好，*只要* *记忆压力低*即可。`free(1)`实用程序清楚地显示了这一点(同样，在我的 x86_64 Ubuntu 盒子上，在这个例子中有 16 GB 的内存):

```sh
$ free -h
              total     used     free     shared     buff/cache  available
Mem:           15Gi    5.5Gi    1.4Gi      704Mi          8.6Gi      9.0Gi
Swap:         7.6Gi       0B    7.6Gi
$ 
```

`buff/cache`列表示 Linux 内核使用的两个缓存——缓冲区和页面缓存。实际上，在内核使用的各种缓存中，*页面缓存*是一个关键的缓存，通常占内存使用的大部分。

Look up `/proc/meminfo` for fine-granularity detail on system memory usage; the fields displayed are numerous. The man page on `proc(5)` describes them under the `/proc/meminfo` section.

现在您已经理解了 slab 分配器背后的动机(关于这一点还有更多)，让我们深入学习如何使用它为核心内核和模块作者公开的 API。

## 学习如何使用平板分配器 API

您可能已经注意到，到目前为止，我们还没有解释 slab 分配器(缓存)背后的第二个“设计思想”，即*通过提供小的、大小方便的缓存，通常是页面的片段*，来减轻页面分配器的高浪费(内部碎片)。我们将通过一种实用的方式来看看这到底意味着什么，以及内核板分配器 API。

### 分配平板内存

尽管在 slab 层中存在几个执行内存分配和释放的 API，但是只有几个真正关键的 API，其余的都属于“便利或助手”功能类别(我们当然会在后面提到)。内核模块或设备驱动程序作者的关键层分配 API 如下:

```sh
#include <linux/slab.h>
void *kmalloc(size_t size, gfp_t flags);
void *kzalloc(size_t size, gfp_t flags);
```

使用任何平板分配器 API 时，请确保包含`<linux/slab.h>`头文件。

`kmalloc()`和`kzalloc()`例程往往是内核内存分配中最常用的**应用编程接口。一个快速的检查——我们的目标不是非常精确——在 5.4.0 Linux 内核源代码树上非常有用的`cscope(1)`代码浏览工具揭示了(近似的)使用频率:`kmalloc()`被调用了大约 4600 次，`kzalloc()`被调用了超过 11000 次！**

这两个函数都有两个参数:第一个要传递的参数是所需内存分配的大小(以字节为单位)，而第二个参数是要分配的内存类型，通过现在熟悉的 GFP 标志来指定(我们在前面的章节中已经讨论过这个主题，即*处理* *GFP 标志*和*GFP 标志-深入挖掘。*如果你对它们不熟悉，我建议你先看看那些章节)。

成功分配后，返回值是一个指针，*内核逻辑地址*(记住，它仍然是一个虚拟地址，*而不是刚刚分配的内存块(或板)开始的*物理地址)。事实上，您应该注意到，除了第二个参数之外，`kmalloc()`和`kzalloc()`API 非常类似于它们的用户空间对应物，非常熟悉的 glibc `malloc(3)`(和朋友)API。不过，不要误会:它们完全不同。`malloc()`返回用户空间虚拟地址，如前所述，用户模式`malloc(3)`和内核模式`k[m|z]alloc()`之间没有直接关联(因此，否，对`malloc()`的调用不会导致对的立即调用；稍后详细介绍！).

接下来，重要的是要理解，这些 slab 分配器 API**返回的内存保证是物理上连续的** *。*此外，还有另一个关键好处，返回地址保证在 CPU 缓存线边界上；也就是说，它将与**纪念印对齐**。这两个都是重要的性能提升优势。

Every CPU reads and writes data (from and to CPU caches <-> RAM) in an atomic unit called the **CPU cacheline***.* The size of the cacheline varies with the CPU. You can look this up with the `getconf(1)` utility – for example, try doing `getconf -a|grep LINESIZE`. On modern CPUs, the cachelines for instructions and data are often separated out (as are the CPU caches themselves). A typical CPU cacheline size is 64 bytes.

由`kmalloc()`分配后的内存块的内容是随机的(同样，像`malloc(3)`)。事实上，`kzalloc()`之所以是首选和推荐使用的应用编程接口，是因为它将分配的内存设置为零。一些开发人员认为内存板的初始化需要一些时间，从而降低了性能。我们的反论点是，除非内存分配代码处于一个极其时间关键的代码路径中(你可以合理地认为，这首先不是一个好的设计，但有时是没办法的)，否则作为最佳实践，你应该在分配时*初始化你的内存*。由此可以避免大量的内存错误和安全副作用。

Many parts of the Linux kernel core code certainly use the slab layer for memory. Within these, there *are* timecritical code paths – good examples can be found within the network and block IO subsystems. For maximizing performance, the slab (actually SLUB) layer code has been written to be *lo*ckless (via a lock-free technology called per-CPU variables). See more on the performance challenges and implementation details in the *Further reading* section.

### 释放平板内存

当然，您必须释放您在未来某个时间点分配的已分配平板内存(因此不会泄漏内存)；`kfree()`例程服务于此目的。类似于用户空间`free(3)`应用编程接口，`kfree()`使用一个参数——指向要释放的内存块的指针。它必须是一个有效的内核逻辑(或虚拟)地址，并且必须已经由其中一个 slab 层 API(`k[m|z]alloc()`或其助手之一)的返回值初始化。它的 API 签名很简单:

```sh
void kfree(const void *);
```

就像`free(3)`一样，没有返回值。如前所述，注意确保`kfree()`的参数是`k[m|z]alloc()`返回的精确值。传递不正确的值将导致内存损坏，最终导致系统不稳定。

还有几点需要注意。

假设我们已经用`kzalloc()`分配了一些平板内存:

```sh
static char *kptr = kzalloc(1024, GFP_KERNEL);
```

稍后，在使用之后，我们希望释放它，因此我们执行以下操作:

```sh
if (kptr)
    kfree(kptr);
```

该代码–在释放前检查`kptr`的值不是`NULL`–*是不必要的*；只要表演`kfree(kptr);`就完成了。

*不正确的*码(伪码)的另一个例子如下所示:

```sh
static char *kptr = NULL;
 while (<some-condition-is-true>) {
       if (!kptr)
                kptr = kmalloc(num, GFP_KERNEL);
        [... work on the slab memory ...]
       kfree(kptr);
 }
```

有趣:这里，从第二次循环迭代开始，程序员已经*假设*释放后`kptr`指针变量将被设置为`NULL`！事实绝对不是这样(尽管这是一个很好的语义；同样，同样的论点也适用于“通常的”用户空间库 API)。因此，我们遇到了一个危险的错误:在循环的第二次迭代中，`if`条件很可能被证明是错误的，从而跳过分配。然后，我们点击`kfree()`，这当然会破坏内存(由于双自由错误)！(我们在 LKM 提供了这个案例的演示:`ch8/slab2_buggy`)。

关于*在分配之后(或期间)初始化*内存缓冲区，正如我们提到的分配一样，释放内存也是如此。您应该意识到`kfree()` API 只是将刚刚释放的 slab 返回到其对应的缓存中，让内部内存内容保持原样！因此，就在释放你的内存块之前，一个(稍微有点迂腐的)最佳实践是*清除(覆盖)*内存内容。出于安全原因，尤其如此(例如在“信息泄露”的情况下，恶意攻击者可能会扫描释放的内存以寻找“秘密”)。Linux 内核为此提供了`kzfree()`应用编程接口(签名与`kfree()`相同)。

*Careful!* In order to overwrite "secrets," a simple `memset()` of the target buffer might just not work. Why not? The compiler might well optimize away the code (as the buffer is no longer to be used). David Wheeler, in his excellent work *Secure Programming HOWTO* ([https://dwheeler.com/secure-programs/](https://dwheeler.com/secure-programs/)), mentions this very fact and provides a solution: "One approach that seems to work on all platforms is to write your own implementation of memset with internal "volatilization" of the first argument." (This code is based on a workaround proposed by Michael Howard):

`void *guaranteed_memset(void *v,int c,size_t n)`
`{ volatile char *p=v; while (n--) *p++=c; return v; }`

"Then place this definition into an external file to force the function to be external (define the function in a corresponding `.h` file, and `#include` the file in the callers, as is usual). This approach appears to be safe at any optimization level (even if the function gets inlined)."

The kernel's `kzfree()` API should work just fine. Take care when doing similar stuff in user space.

### 数据结构–一些设计技巧

强烈建议在内核空间中使用 slab APIs 进行内存分配。首先，它保证了物理上的连续以及缓存行对齐的内存。这对性能非常好；此外，让我们来看看一些可以带来高额回报的快速技巧。

*CPU 缓存*可以提供巨大的性能提升。因此，特别是对于时间关键的代码，要注意设计数据结构以获得最佳性能:

*   将最重要的(经常访问的，“热门”)成员放在一起，并放在结构的顶部。要了解原因，假设在您的数据结构中有五个重要成员(总大小为 56 字节)；将它们放在一起，放在结构的顶部。假设 CPU 缓存行大小为 64 字节。现在，当您的代码访问这五个重要成员中的任何一个时，所有五个成员都将被提取到中央处理器高速缓存中，因为中央处理器的内存读/写工作在中央处理器高速缓存行大小的原子单元中；这优化了性能(因为使用高速缓存通常比使用内存快几倍)。
*   尝试对齐结构成员，以使单个成员不会“从缓存线中脱落”。通常，编译器在这方面有所帮助，但是您甚至可以使用编译器属性来明确指定这一点。
*   由于有效的 CPU 缓存，按顺序访问内存可以获得高性能。但是，我们不能把所有的数据结构都做成数组！有经验的设计师和开发人员都知道，使用链表是极其常见的。但这难道不会影响表演吗？嗯，是的，在某种程度上。因此，建议:使用链表。将列表的“节点”保持为一个大的数据结构(在顶部有“热”成员并在一起)。这样，我们尝试最大化这两种情况的最佳效果，因为大结构本质上是一个数组。(想想看，我们在[第 6 章](06.html)、*内核内部要素–进程和线程*、–T4】任务列表–中看到的任务结构列表是一个以大数据结构作为节点的链表的完美现实例子)。

下一节将讨论一个关键方面:我们通过流行的`k[m|z]alloc()`API 了解内核在分配(slab)内存时使用的确切 slab 缓存。

### kmalloc 使用的实际板缓存

在尝试使用基本的 slab APIs 开发内核模块之前，我们将进行一个快速的偏离——尽管这非常重要。了解`k[m|z]alloc()`API 分配的内存具体来自哪里非常重要。嗯，是从石板仓库来的，是的，但是具体是哪几个？对`sudo vmstat -m`输出的快速`grep`为我们揭示了这一点(下面的截图在我们的 x86_64 Ubuntu 客户机上):

![](Images/1eccca8f-655a-47c6-9f68-a2e8b882db2f.png)

Figure 8.7 – Screenshot of sudo vmstat -m showing the kmalloc-n slab caches

那很有趣！内核有一系列专用的平板缓存，用于不同大小的通用`kmalloc`内存，*从 8，192 字节到仅仅 8 字节不等！*这告诉我们一些事情——使用页面分配器，如果我们请求 12 字节的内存，它最终会给我们一整页(4kb)——浪费太多了。这里，使用 slab 分配器，一个 12 字节的分配请求最终实际上只分配了 16 字节(从图 8.8 中看到的倒数第二个缓存)！太棒了。

另外，请注意以下几点:

*   在`kfree()`时，内存被释放回适当的平板缓存。
*   `kmalloc`平板缓存的精确大小因架构而异。在我们的树莓皮系统(当然是 ARM 中央处理器)上，通用内存`kmalloc-N`缓存从 64 字节到 8192 字节不等。
*   前面的截图也揭示了一个线索。通常，需求是对小到微小的内存碎片的需求。例如，在前面的截图中，标记为`Num`的列表示当前活动对象的*数量*，最大数量来自 8 字节和 16 字节的`kmalloc`平板缓存(当然，这可能不总是这样。快速提示:使用`slabtop(1)`实用程序(您需要以 root 用户身份运行):顶部的行显示了当前常用的平板缓存。)

当然，Linux 一直在发展。从 5.0 主线内核开始，新引入了`kmalloc`缓存类型，称为可回收缓存(命名格式为`kmalloc-rcl-N`)。因此，在 5.x 内核上执行 grep 也会显示这些缓存:

```sh
$ sudo vmstat -m | grep --color=auto "^kmalloc"
kmalloc-rcl-8k                0      0    8192      4
kmalloc-rcl-4k                0      0    4096      8
kmalloc-rcl-2k                0      0    2048     16
[...]
kmalloc-8k                   52     52    8192      4
kmalloc-4k                   99    120    4096      8
kmalloc-2k                  521    560    2048     16
[...]
```

新的`kmalloc-rcl-N`缓存有助于提高内部效率(在压力下回收页面，并作为一种反碎片措施)。然而，像您这样的模块作者不需要关心这些细节。(本作品的提交可在此查看:[https://github . com/Torvalds/Linux/commit/1291523 f2c1 d 631 FEA 34102 FD 241 FB 54 a4e 8 f7a 0](https://github.com/torvalds/linux/commit/1291523f2c1d631fea34102fd241fb54a4e8f7a0)。)

`vmstat -m` is essentially a wrapper over the kernel's `/sys/kernel/slab` content (more on this follows). Deep internal details of the slab caches can be seen using utilities such as `slabtop(1)`, as well as the powerful `crash(1)` utility (on a "live" system, the relevant crash command is `kmem -s` (or `kmem -S`)).

没错。又到了用一些代码来演示 slab 分配器 API 的用法的时候了！

### 编写内核模块来使用基本的平板应用编程接口

在下面的代码片段中，看一下演示内核模块代码(位于`ch8/slab1/`)。在`init`代码中，我们只执行几个平板层分配(通过`kmalloc()`和`kzalloc()` APIs)，打印一些信息，并释放清理代码路径中的缓冲区(当然，完整的源代码可以在本书的 GitHub 存储库中访问)。让我们一步一步来看代码的相关部分。

在这个内核模块的`init`代码的开始，我们通过分配 1，024 字节给全局指针(`gkptr`)来初始化它(*记住:指针没有内存！*)通过`kmalloc()`板坯分配应用编程接口。请注意，由于我们肯定在流程上下文中运行，因此“睡眠安全”，我们使用`GFP_KERNEL`标志作为第二个参数(以防您想回头参考前面的部分，*GFP 标志–深入研究*，它是否涵盖了):

```sh
// ch8/slab1/slab1.c
[...]
#include <linux/slab.h>
[...]
static char *gkptr;
struct myctx {
    u32 iarr[100];
    u64 uarr[100];
    char uname[128], passwd[16], config[16];
};
static struct myctx *ctx;

static int __init slab1_init(void)
{
    /* 1\. Allocate slab memory for 1 KB using the kmalloc() */
    gkptr = kmalloc(1024, GFP_KERNEL);
    if (!gkptr) {
        WARN_ONCE(1, "%s: kmalloc() failed!\n", OURMODNAME);
        /* As mentioned earlier, there is really no need to print an
         * error msg when a memory alloc fails; the situation "shouldn't"  
         * typically occur, and if it does, the kernel will emit a chain 
         * of messages in any case. Here, we use the WARN_ONCE()
         * macro pedantically, and as this is a 'learning' program.. */
        goto out_fail1;
    }
    pr_info("kmalloc() succeeds, (actual KVA) ret value = %px\n", gkptr);
    /* We use the %px format specifier here to show the actual KVA; in production, Don't! */
    print_hex_dump_bytes("gkptr before memset: ", DUMP_PREFIX_OFFSET, gkptr, 32);
    memset(gkptr, 'm', 1024);
    print_hex_dump_bytes(" gkptr after memset: ", DUMP_PREFIX_OFFSET, gkptr, 32);
```

在前面的代码中，还注意到我们使用`print_hex_dump_bytes()`内核便利例程作为以人类可读格式转储缓冲存储器的便利方式。它的签名是:

```sh
void print_hex_dump_bytes(const char *prefix_str, int prefix_type,
     const void *buf, size_t len);
```

其中`prefix_str`是您希望在十六进制转储的每一行前加前缀的任何字符串；`prefix_type`为`DUMP_PREFIX_OFFSET`、`DUMP_PREFIX_ADDRESS`或`DUMP_PREFIX_NONE`之一，`buf`为十六进制转储的源缓冲区；而`len`是要转储的字节数。

接下来是许多设备驱动程序遵循的典型策略(*最佳实践*:它们将所有必需的或上下文信息保存在单个数据结构中，通常称为*驱动程序上下文*结构。我们通过声明一个名为`myctx`的(愚蠢的/示例)数据结构以及一个名为`ctx`的指向它的全局指针(结构和指针定义在前面的代码块中)来模拟这一点:

```sh
    /* 2\. Allocate memory for and initialize our 'context' structure */
    ctx = kzalloc(sizeof(struct myctx), GFP_KERNEL);
    if (!ctx)
        goto out_fail2;
    pr_info("%s: context struct alloc'ed and initialized (actual KVA ret = %px)\n",
        OURMODNAME, ctx);
    print_hex_dump_bytes("ctx: ", DUMP_PREFIX_OFFSET, ctx, 32);

    return 0;        /* success */
out_fail2:
    kfree(gkptr);
out_fail1:
    return -ENOMEM;
}
```

在数据结构之后，我们通过有用的`kzalloc()`包装应用编程接口将`ctx`分配并初始化为`myctx`数据结构的大小。随后的 *hexdump* 将显示它确实被初始化为全零(为了可读性，我们将只“转储”前 32 个字节)。

请注意我们如何使用`goto`处理错误路径；这在本书前面已经提到过几次了，所以我们在这里就不重复了。最后，在内核模块的清理代码中，我们`kfree()`两个缓冲区，防止任何内存泄漏:

```sh
static void __exit slab1_exit(void)
{
    kfree(ctx);
 kfree(gkptr);
    pr_info("%s: freed slab memory, removed\n", OURMODNAME);
}
```

下面是在我的树莓 Pi 4 上运行的一个示例的截图。我使用我们的`../../lkm`便利脚本来构建、加载和执行`dmesg`:

![](Images/434f0e51-a09f-49dd-8d32-823e1ca41dc0.png)

Figure 8.8 – Partial screenshot of our slab1.ko kernel module in action on a Raspberry Pi 4

好了，现在您已经掌握了使用公共 slab 分配器 API、`kmalloc(), kzalloc()`和`kfree()`的基础知识，让我们更进一步。在下一节中，我们将深入探讨一个真正关键的问题——内存大小受限的现实，您可以通过平板(和页面)分配器获得内存。继续读！

# kmalloc 应用编程接口的大小限制

页分配器和片分配器的一个主要优点是，它们在分配时提供的内存块不仅是虚拟连续的(显然)，而且保证是*物理连续的内存*。现在这是一件大事，肯定会有助于表现。

但是(总有*但是*，不是吗！)，正是由于这种保证，在执行分配时，不可能提供任何给定的大尺寸。换句话说，通过对我们亲爱的`k[m|z]alloc()`API 的一次调用，您可以从 slab 分配器获得的内存量是有明确限制的。上限是多少？(这确实是一个非常常见的问题。)

首先，你应该明白，从技术上来说，极限是由两个因素决定的:

*   一、系统页面大小(由`PAGE_SIZE`宏决定)
*   二、“订单”数量(由`MAX_ORDER`宏决定)；也就是页面分配器(或 BSA)自由列表数据结构中的列表数量(见图 8.2)

在标准 4 KB 页面大小和 MAX_ORDER 值为 11 的情况下，单次`kmalloc()`或`kzalloc()` API 调用可以分配的最大内存量为 4 MB。x86_64 和 ARM 架构都是这种情况。

你可能会想，*这个 4 MB 的限制到底是怎么达到*的？想想看:一旦一个 slab 分配请求超过了内核提供的最大 slab 缓存大小(通常为 8 KB)，内核只需将请求向下传递给页面分配器。页面分配器的最大可分配大小由`MAX_ORDER`决定。设置为`11`时，最大可分配缓冲区大小为*2<sup>(MAX _ ORDER-1)</sup>=***2<sup>10</sup>页数= 1024 页= 1024 * 4K = 4 MB* ！*

 *## 测试极限–通过一次调用分配内存

对于开发人员(以及其他所有人)来说，一个真正关键的事情是在你的工作中**成为经验性的**！英语单词*experimental*的意思是基于所经历或看到的，而不是基于理论。这是一条必须始终遵循的关键规则——不要简单地假设事情，也不要只看表面。你自己试试看吧。

让我们做一些非常有趣的事情:编写一个内核模块，从(通用的)平板缓存中分配内存(当然是通过`kmalloc()` API)。我们将在循环中这样做，在每次循环迭代中分配并释放(计算的)数量。这里的关键点是，我们将按照给定的“步长”不断增加分配的数量。当`kmalloc()`失败时，循环终止；通过这种方式，我们可以测试通过对`kmalloc()`的一次调用，我们实际上可以分配多少内存(当然，你会意识到`kzalloc()`，作为`kmalloc()`的简单包装器，面临着完全相同的限制)。

在下面的代码片段中，我们展示了相关的代码。从内核模块的`init`代码中调用`test_maxallocsz()`函数:

```sh
// ch8/slab3_maxsize/slab3_maxsize.c
[...]
static int stepsz = 200000;
module_param(stepsz, int, 0644);
MODULE_PARM_DESC(stepsz,
"Amount to increase allocation by on each loop iteration (default=200000");

static int test_maxallocsz(void)
{
  size_t size2alloc = 0;
  void *p;

  while (1) {
      p = kmalloc(size2alloc, GFP_KERNEL);
      if (!p) {
          pr_alert("kmalloc fail, size2alloc=%zu\n", size2alloc);
          return -ENOMEM;
      }
      pr_info("kmalloc(%7zu) = 0x%pK\n", size2alloc, p);
      kfree(p);
 size2alloc += stepsz;
  }
  return 0;
}
```

By the way, notice how our `printk()` function uses the `%zu` format specifier for the `size_t` (essentially an unsigned integer) variable? `%zu` is a portability aid; it makes the variable format correct for both 32- and 64-bit systems!

让我们构建(在主机上交叉编译)并在运行我们定制的 5.4.51-v7+内核的树莓 Pi 设备上插入这个内核模块；几乎立刻，在`insmod(8)`上，你会看到一条错误信息，`Cannot allocate memory`，由`insmod`进程打印；以下截屏显示了这一点:

![](Images/0bffc2c9-9b67-4c11-85ec-dbf90edf6014.png)

Figure 8.9 – The first insmod(8) of our slab3_maxsize.ko kernel module on a Raspberry Pi 3 running a custom 5.4.51 kernel

这是意料之中的！想想看，我们的内核模块代码的`init`功能终究还是用`ENOMEM`失败了。不要被这个所迷惑；查找内核日志揭示了实际发生的事情。事实是，在这个内核模块的第一次测试运行中，你会发现在`kmalloc()`失败的地方，内核转储了一些诊断信息，包括一个相当长的内核堆栈跟踪。这是因为它调用了`WARN()`宏。

因此，我们的平板内存分配在某种程度上起了作用。要清楚地看到故障点，只需在内核日志(`dmesg`)显示中向下滚动。下面的截图显示了这一点:

![](Images/c71451dc-2f70-4cd0-9ee3-9eecf381b8a5.png)

Figure 8.10 – Partial screenshot showing the lower part of the dmesg output (of our slab3_maxsize.ko kernel module) on a Raspberry Pi 3

啊哈，看看输出的最后一行(图 8.11):`kmalloc()`在 4 MB 以上(420 万字节)的分配上失败，完全符合预期；在那之前，它是成功的。

有趣的是，请注意，我们(相当有意识地)执行了循环中第一个大小为`0`的分配；它不会失败:

*   `kmalloc(0, GFP_xxx);`返回零指针；在 x86[_64]上，是数值`16`或`0x10`(详见`include/linux/slab.h`)。实际上，它是一个无效的虚拟地址，位于页面`0` `NULL`指针陷阱中。当然，访问它会导致页面错误(源自 MMU)。
*   同样，尝试零指针的`kfree(NULL);`或`kfree()`会导致`kfree()`成为无操作

不过，请稍等——需要注意的一个极其重要的点是:在*kmalloc*部分中，我们看到了用于向调用者分配内存的 slab 缓存是`kmalloc-n` slab 缓存，其中`n`的范围从`64`到`8192`字节(在树莓 Pi 上，因此在本讨论中是 ARM)。另外，仅供参考，您可以快速执行`sudo vmstat -m | grep -v "\-rcl\-" | grep --color=auto "^kmalloc"`来验证这一点。

但是很明显，在前面的内核模块代码示例中，我们通过`kmalloc()`分配了大量内存(从 0 字节到 4 MB)。它真正的工作方式是`kmalloc()`应用编程接口仅使用`kmalloc-'n'`平板缓存进行小于或等于 8，192 字节(如果可用)的内存分配；对更大内存块的任何分配请求都被传递给底层页面(或伙伴系统)分配器！现在，回想一下我们在上一章中所学的内容:页面分配器使用好友系统自由列表(基于每个*节点:区域*)*和*自由列表上排队的内存块的最大大小是*2<sup>(MAX _ ORDER-1)</sup>= 2<sup>10</sup>**页面*，当然是 4 MB(给定 4 KB 的页面大小和`11`的`MAX_ORDER`)。这与我们的理论讨论完全一致。

所以，我们有了:在理论和实践中，你现在可以看到(同样，给定 4 KB 的页面大小和`11`的`MAX_ORDER`，通过对`kmalloc()`(或`kzalloc()`)的一次调用可以分配的最大内存大小是 4 MB。

### 通过/proc/buddyinfo 伪文件进行检查

意识到这一点真的很重要，尽管我们发现 4 MB 的内存是我们一次能得到的最大值，但这绝对不意味着你会一直得到那么多。不，当然不是。它完全取决于内存请求时特定空闲列表中的空闲内存量。想想看:如果你运行在一个运行了几天(或几周)的 Linux 系统上，会怎么样。找到物理上连续的 4 MB 空闲内存块的可能性非常低(同样，这取决于系统上的内存量及其工作负载)。

根据经验，如果前面的实验没有产生我们认为的最大大小(即 4 MB)的最大分配，为什么不在新启动的来宾系统上尝试呢？现在，拥有物理上连续的 4 MB 空闲内存块的机会要大得多。不确定吗？让我们再次获得经验，并在使用中和新启动的系统上查找`/proc/buddyinfo`的内容，以确定内存块是否可用。在下面的代码片段中，在我们正在使用的 x86_64 Ubuntu 客户机系统上，只有 1 GB 的内存，我们查找它:

```sh
$ cat /proc/buddyinfo 
Node 0, zone      DMA    225  154   46   30   14   9   1   1   0   0   0 
Node 0, zone    DMA32    314  861  326  291  138  50  27   2   5   0   0 
  order --->               0    1    2    3    4   5   6   7   8   9  10
```

正如我们之前了解到的(在*自由列表组织*部分)，在前面的代码块中看到的数字按照顺序`0`到`MAX_ORDER-1`(通常， *0* 到*11–1 = 10*)排列，并且它们以该顺序表示 *2 <sup>顺序</sup>* 连续自由页面帧的数量。

在前面的输出中，我们可以看到我们做的*不是*在订单`10`列表上有空闲块(也就是 4 MB 的块；它是零)。在新启动的 Linux 系统上，我们很有可能会这样做。在以下输出中，在刚刚重新启动的同一系统上，我们看到在节点`0`的区域 DMA32 中有七个物理上连续的 4 MB 可用内存块:

```sh
$ cat /proc/buddyinfo 
Node 0, zone      DMA      10   2    2    3   3   3   3   2   2   0   0 
Node 0, zone    DMA32     276 143  349  189  99   3   6   3   6   4   7 
 order --->                0   1    2    3   4   5   6   7   8   9  10
```

重申这一点，在树莓皮已经上升了大约半个小时，我们有以下内容:

```sh
rpi ~/ $ cat /proc/buddyinfo 
Node 0, zone   Normal    82   32   11   6   5   3   3   3   4   4   160
```

这里有 160 个 4 兆物理连续内存块可用(空闲)。

当然，还有更多要探索的。在下一节中，我们将介绍更多关于使用 slab 分配器的内容——资源管理的 API 替代方案、其他可用的 slab 助手 API，以及关于现代 Linux 内核中的 cgroups 和内存的说明。

# 平板分配器——一些附加细节

还有几个关键点有待探索。首先，一些关于使用内核的内存分配器 API 的资源管理版本的信息，接下来是内核中一些额外可用的 slab 助手例程，然后是对 cgroups 和内存的简单介绍。我们绝对建议您也浏览这些部分。请继续读下去！

## 使用内核的资源管理内存分配 API

对于设备驱动程序特别有用，内核为内存分配提供了一些托管 API。这些被正式称为设备资源管理或 devres APIs(这方面的内核文档链接是[https://www . kernel . org/doc/Documentation/driver-model/devres . txt](https://www.kernel.org/doc/Documentation/driver-model/devres.txt))。都以`devm_`为前缀；虽然其中有几个，但我们在这里只关注一个常见的用例——用这些 API 代替通常的`k[m|z]alloc()`API。它们如下:

*   `void * devm_kmalloc(struct device *dev, size_t size, gfp_t gfp);`
*   `void * devm_kzalloc(struct device *dev, size_t size, gfp_t gfp);`

这些资源管理的 API 之所以有用，是因为开发者不需要显式释放它们分配的内存。内核资源管理框架保证，当驱动程序分离时，或者如果内核模块被移除(或者设备被分离，以先发生的为准)，它将自动释放内存缓冲区。这个特性立即增强了代码的健壮性。为什么呢？很简单，我们都是人，都会犯错。泄漏内存(尤其是在错误代码路径上)确实是一个非常常见的错误！

与这些 API 的使用相关的几点:

*   一个关键点——请不要试图盲目用对应的`devm_k[m|z]alloc()`替换`k[m|z]alloc()`！这些资源管理的分配实际上被设计为仅在设备驱动程序的`init`和/或`probe()`方法中使用(所有使用内核统一设备模型的驱动程序通常会提供`probe()`和`remove()`(或`disconnect()`)方法)。我们这里就不深究这些方面了)。
*   `devm_kzalloc()`通常是优选的，因为它也初始化缓冲区。在内部(就像`kzalloc()`一样)，它只是`devm_kmalloc()`应用编程接口的一个薄薄的包装。
*   第二个和第三个参数是常见的，就像`k[m|z]alloc()`API 一样——要分配的字节数和要使用的 GFP 标志。第一个参数是`struct device`的指针。很明显，它代表您的驾驶员正在驾驶的*设备*。
*   由于这些 API 分配的内存是自动释放的(在驱动程序分离或模块移除时)，您不必做任何事情。不过，它可以通过`devm_kfree()`应用编程接口释放。但是，您这样做通常表明托管 API 是错误的...
*   许可:被管理的应用编程接口只被导出(因此是可用的)到 GPL 许可的模块(除了其他可能的许可)。

## 其他平板辅助应用接口

有几个助手平板分配器 API，`k[m|z]alloc()` API 家族的朋友。其中包括为数组分配内存的`kcalloc()`和`kmalloc_array()`应用编程接口，以及`krealloc()`，其行为类似于熟悉的用户空间应用编程接口`realloc(3)`。

结合为元素数组分配内存，`array_size()`和`struct_size()`内核助手例程会非常有帮助。特别是，`struct_size()`在分配结构数组时被大量用于防止(实际上是修复)许多整数溢出(和相关)错误，这确实是一个常见的任务。作为一个快速的例子，这里有一个来自`net/bluetooth/mgmt.c`的小代码片段:

```sh
rp = kmalloc(struct_size(rp, addr, i), GFP_KERNEL);
 if (!rp) {
     err = -ENOMEM; [...]
```

值得浏览一下`include/linux/overflow.h`内核头文件。

`kzfree()`类似于`kfree()`，但将正在释放的(可能更大的)内存区域清零。(为什么更大？这将在下一节中解释。)请注意，这被认为是一种安全措施，但可能会影响性能。

这些 API 的资源管理版本也是可用的:`devm_kcalloc()`和`devm_kmalloc_array()`。

## 对照组和记忆

Linux 内核支持一个非常复杂的资源管理系统，称为**cggroups**(**控制组**)，简单来说，用于分层组织进程和执行资源管理(有关 cggroups 的更多信息，以及 cgroups v2 CPU 控制器使用的示例，可在[第 11 章](11.html)、*CPU 调度程序-第 2 部分*，关于 CPU 调度)中找到)。

在几个资源控制器中，有一个用于内存带宽。通过仔细配置，sysadmin 可以有效地调节系统上的内存分配。内存保护是可能的，通过某些`memcg`(内存组)伪文件(特别是`memory.min`和`memory.low`文件)进行硬保护和尽力保护。以类似的方式，在 cggroup 中，`memory.high`和`memory.max`伪文件是控制 cggroup 内存使用的主要机制。当然，由于它的内容比这里提到的要多得多，我在这里建议您参考关于新 cgroups (v2)的内核文档:[https://www . kernel . org/doc/html/latest/admin-guide/cgroup-v2 . html](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html)。

好了，现在你已经学会了如何更好地使用 slab 分配器 API，让我们再深入一点。现实情况是，关于由 slab 分配器 API 分配的内存块的大小，仍然有一些重要的警告。一定要读下去，找出它们是什么！

# 使用平板分配器时的注意事项

我们将把这次讨论分成三个部分。我们将首先重新检查一些必要的背景(我们之前已经介绍过)，然后用两个用例来充实问题——第一个非常简单，第二个是手头问题的更真实的案例。

## 背景细节和结论

到目前为止，您已经了解了一些关键点:

*   *页面*(或*好友系统* ) *分配器*将 2 页的力量分配给呼叫者。将 2 升至的功率称为*指令*；它的范围通常从`0`到`10`(在 x86[_64]和 ARM 上)。
*   这很好，除非不是。当请求的内存量很小时，*浪费*(或内部碎片)会很大。
*   对页面片段(小于 4，096 字节)的请求非常常见。因此，分层在页面分配器上的*平板分配器(见图 8.1)设计有对象缓存和小型通用内存缓存，以有效地满足对少量内存的请求。*
*   页面分配器保证物理上连续的页面和缓存行对齐的内存。
*   slab 分配器保证物理上连续和缓存行对齐的内存。

太棒了——这让我们得出结论，当需要的内存量很大，并且是 2 的完美(或接近)次方时，使用页面分配器。当它非常小(不到一页)时，使用 slab 分配器。事实上，`kmalloc()`的内核源代码有一个注释，简洁地总结了`kmalloc()`应用编程接口应该如何使用(以粗体显示如下):

```sh
// include/linux/slab.h
[...]
 * kmalloc - allocate memory
 * @size: how many bytes of memory are required.
 * @flags: the type of memory to allocate.
 * kmalloc is the normal method of allocating memory
 * for objects smaller than page size in the kernel.
```

听起来很棒，但还是有问题！要看到它，让我们学习如何使用另一个有用的平板 API，`ksize()`。其签名如下:

```sh
size_t ksize(const void *);
```

`ksize()`的参数是指向现有板缓存的指针(它必须是有效的)。换句话说，它是来自一个 slab 分配器 API(通常是`k[m|z]alloc()`)的返回地址。返回值是实际分配的字节数。

好了，现在你知道`ksize()`是干什么用的了，让我们用更实用的方式来使用它，先用一个简单的用例，再用一个更好的用例！

## 使用 ksize()测试板分配–案例 1

为了理解我们的意思，考虑一个小例子(为了可读性，我们将不显示必要的有效性检查。此外，由于这是一个很小的代码片段，我们没有在本书的代码库中将其作为内核模块提供):

```sh
struct mysmallctx {
    int tx, rx;
    char passwd[8], config[4];
} *ctx;

pr_info("sizeof struct mysmallctx = %zd bytes\n", sizeof(struct mysmallctx));
ctx = kzalloc(sizeof(struct mysmallctx), GFP_KERNEL);
pr_info("(context structure allocated and initialized to zero)\n"
        "*actual* size allocated = %zu bytes\n", ksize(ctx));
```

我的 x86_64 Ubuntu 客户机系统上的结果输出如下:

```sh
$ dmesg
[...]
sizeof struct mysmallctx = 20 bytes
(context structure allocated and initialized to zero)
*actual* size allocated = 32 bytes
```

因此，我们试图用`kzalloc()`分配 20 个字节，但实际上获得了 32 个字节(因此浪费了 12 个字节，即 60%！).这是意料之中的。回想一下`kmalloc-n`平板缓存——在 x86 上，有一个用于 16 字节，另一个用于 32 字节(以及其他许多字节)。所以，当我们要求介于两者之间的量时，我们显然从两者中的较高者获得记忆。(顺便说一下，仅供参考，在我们基于 ARM 的树莓 Pi 系统上，`kmalloc`的最小平板缓存是 64 字节，所以，当然，当我们要求 20 字节时，我们会得到 64 字节。)

Note that the `ksize()` API works only on allocated slab memory; you cannot use it on the return value from any of the page allocator APIs (which we saw in the *Understanding and u**sing the kernel page allocator (or BSA)* section).

现在是第二个，也是更有趣的，用例。

## 使用 ksize()测试板分配–案例 2

好了，现在我们把之前的内核模块(`ch8/slab3_maxsize`)扩展到`ch8/slab4_actualsize`。在这里，我们将执行相同的循环，使用`kmalloc()`分配内存，并像以前一样释放内存，但这一次，我们还将通过调用`ksize()`应用编程接口，记录平板层在每次循环迭代中分配给我们的实际内存量:

```sh
// ch8/slab4_actualsize/slab4_actualsize.c
static int test_maxallocsz(void)
{
    size_t size2alloc = 100, actual_alloced;
    void *p;

    pr_info("kmalloc(      n) :  Actual : Wastage : Waste %%\n");
    while (1) {
        p = kmalloc(size2alloc, GFP_KERNEL);
        if (!p) {
            pr_alert("kmalloc fail, size2alloc=%zu\n", size2alloc);
            return -ENOMEM;
        }
        actual_alloced = ksize(p);
        /* Print the size2alloc, the amount actually allocated,
         * the delta between the two, and the percentage of waste
         * (integer arithmetic, of course :-)  */
        pr_info("kmalloc(%7zu) : %7zu : %7zu : %3zu%%\n",
              size2alloc, actual_alloced, (actual_alloced-size2alloc),
              (((actual_alloced-size2alloc)*100)/size2alloc));        kfree(p);
        size2alloc += stepsz;
    }
    return 0;
}
```

这个内核模块的输出扫描起来确实很有意思！在下图中，我们显示了我在运行我们定制的 5.4.0 内核的 x86_64 Ubuntu 18.04 LTS 客户机上获得的部分输出截图:

![](Images/7e3a9dfe-f703-40df-ad41-cb0d667a54b9.png)

Figure 8.11 – Partial screenshot of our slab4_actualsize.ko kernel module in action

在前面的截图中可以清楚地看到模块的 printk 输出。屏幕的其余部分是来自内核的诊断信息——这是在内核空间内存分配请求失败时发出的。所有这些内核诊断信息都是第一次调用内核调用`WARN_ONCE()`宏的结果，作为底层页面分配器代码，`mm/page_alloc.c:__alloc_pages_nodemask()`——众所周知的伙伴系统分配器的“心脏”——失败了！这通常不应该发生，因此诊断(关于内核诊断的细节超出了本书的范围，所以我们将把它放在一边。话虽如此，在接下来的章节中，我们将在一定程度上研究内核堆栈回溯)。

### 解释案例 2 的输出

仔细看前面的截图(图 8.12；在这里，我们将简单地忽略`WARN()`宏发出的内核诊断，它被调用是因为内核级内存分配失败！).图 8.12 的输出有五列，如下所示:

*   从`dmesg(1)`开始的时间戳；我们忽略它。
*   `kmalloc(n)`:由`kmalloc()`请求的字节数(其中`n`为所需数量)。
*   平板分配器分配的实际字节数(通过`ksize()`显示)。
*   浪费(字节):实际字节和所需字节之间的差异。
*   以百分比表示的浪费。

例如，在第二次分配中，我们请求了 200，100 字节，但实际获得了 262，144 字节(256 KB)。这是有道理的，因为这是好友系统自由列表中一个页面分配器列表的精确大小(它是*顺序 6* ，作为 *2 <sup>6</sup> = 64 页= 64×4 = 256 KB*；见*图 8.2* 。因此，增量，或真正的浪费，是 *262，144 - 200，100 = 62，044 字节*，当以百分比表示时，是 31%。

它是这样的:请求的(或要求的)大小越接近内核的可用(或实际)大小，浪费就越少；反之亦然。让我们看看前面输出中的另一个例子(为了清楚起见，剪切后的输出如下所示):

```sh
[...]
[92.273695] kmalloc(1600100) : 2097152 :  497052 : 31%
[92.274337] kmalloc(1800100) : 2097152 :  297052 : 16%
[92.275292] kmalloc(2000100) : 2097152 :   97052 :  4%
[92.276297] kmalloc(2200100) : 4194304 : 1994204 : 90%
[92.277015] kmalloc(2400100) : 4194304 : 1794204 : 74%
[92.277698] kmalloc(2600100) : 4194304 : 1594204 : 61%
[...]
```

从前面的输出可以看到`kmalloc()`请求 1，600，100 字节(约 1.5 MB)时，实际得到 2，097，152 字节(正好 2 MB)，浪费 31%。当我们越来越接近分配“边界”或阈值(内核的片缓存或页面分配器内存块的实际大小)时，浪费就会逐渐减少:减少到 16%，然后减少到 4%。但是看:下一次分配，当我们跨过那个门槛，要求*刚刚超过*2mb(2200100 字节)，我们实际上得到 4 MB，*浪费了 90%* ！然后，随着我们越来越接近 4 MB 的内存大小，浪费再次下降...

这很重要！您可能认为仅仅使用 slab 分配器 API 就非常高效，但实际上，当请求的内存量超过 slab 层可以提供的最大容量(通常为 8 KB，这在我们之前的实验中经常出现)时，slab 层会调用页面分配器。因此，页面分配器，遭受其通常的浪费问题，最终分配的内存远远超过你实际需要的，或者实际上从未使用过的。真是浪费！

寓意:*用平板 API*检查并重新检查分配内存的代码。使用`ksize()`对其进行测试，以计算实际分配了多少内存，而不是您认为分配了多少。

没有捷径。嗯，有一个:如果你需要少于一页的内存(一个非常典型的用例)，就使用 slab APIs。如果你需要更多，前面的讨论就开始了。另一件事:使用`alloc_pages_exact() / free_pages_exact()`API(包含在*One Solution-确切的页面分配器 API*部分)也有助于减少浪费。

### 绘制它

有趣的是，我们使用众所周知的`gnuplot(1)`工具根据之前收集的数据绘制一个图表。实际上，我们必须最小化地修改内核模块，只输出我们想要的图形:需要(或请求)分配的内存量( *x* 轴)和运行时实际发生的浪费百分比( *y* 轴)。你可以在本书的 GitHub 资源库中找到我们稍微修改过的内核模块的代码:这里:`ch8/slab4_actualsz_wstg_plot`([https://GitHub . com/packt publishing/Linux-Kernel-Programming/tree/master/ch8/SLA B4 _ actualsize](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/ch8/slab4_actualsize))。

因此，我们构建并插入这个内核模块，“按摩”内核日志，按照`gnuplot`的要求以适当的列格式保存数据(在名为`2plotdata.txt`的文件中)。虽然我们不打算在这里深究使用`gnuplot(1)`的复杂性(参考*进一步阅读*部分以获得教程链接)，但是在下面的代码片段中，我们展示了生成我们的图的基本命令:

```sh
gnuplot> set title "Slab/Page Allocator: Requested vs Actually allocated size Wastage in Percent"
gnuplot> set xlabel "Required size"
gnuplot> set ylabel "%age Waste"
gnuplot> plot "2plotdata.txt" using 1:100 title "Required Size" with points, "2plotdata.txt" title "Wastage %age" with linespoints 
gnuplot> 
```

瞧吧，情节是这样的:

![](Images/73266f0c-19af-4a1f-8ed0-99981904a38d.png)

Figure 8.12 – A graph showing the size requested by kmalloc() (x axis) versus the wastage incurred (as a percentage; y axis)

这个“锯齿”形状的图表有助于将你刚刚学到的东西形象化。一个`kmalloc()`(或`kzalloc()`，或实际上*任何*页面分配器应用编程接口)分配请求的大小越接近内核预定义的自由列表大小，浪费就越少。但是一旦越过了这个阈值，损耗就会放大(峰值)到接近 100%(正如上图中的垂直线所示)。

至此，我们已经涵盖了大量内容。不过，和往常一样，我们还没有完成:下一节将非常简要地强调内核中实际的 slab 层实现(是的，有几个)。让我们来看看！

## 内核中的平板层实现

最后，我们提到这样一个事实:至少有三种不同的互斥的 slab 分配器内核级实现；运行时只能使用其中一个。运行时使用的是在*配置*内核时选择的(您在[第 2 章](02.html)、*从源代码构建 5.x Linux 内核–第 1 部分*中详细学习了此过程)。相关的内核配置选项如下:

*   `CONFIG_SLAB`
*   `CONFIG_SLUB`
*   `CONFIG_SLOB`

第一个(`SLAB`)是早期的，支持度很高(但优化度相当低)的一个；第二个(`SLUB` *，未引用的分配器*)是对第一个的重大改进，在内存效率、性能和更好的诊断方面，是默认选择的那个。`SLOB`分配器是一个彻底的简化，根据内核配置帮助，“在大型系统上表现不佳。”

# 摘要

在本章中，您详细了解了页面(或好友系统)以及平板分配器的工作原理。回想一下，在内核中分配(并释放)内存的实际“引擎”最终是*页面(或伙伴系统)分配器*、，平板分配器分层在其之上，为典型的小于一页大小的分配请求提供优化，并高效地分配几个众所周知的内核数据结构(“对象”)。

您学习了如何有效地使用页面分配器和平板分配器公开的 API，并通过几个演示内核模块来帮助以实践的方式展示这一点。很大一部分注意力(非常正确地)放在了开发人员为某个 *N* 字节数发出内存请求的实际问题上，但是您了解到它可能是非常次优的，内核实际上分配了更多(浪费可能攀升至非常接近 100%)！您现在知道如何检查和减轻这些情况。干得好！

下一章将详细介绍最优分配策略，以及一些更高级的内核内存分配主题，包括使用`vmalloc`接口创建定制的平板缓存、 *OOM 杀手*的全部内容等等。因此，首先确保您已经理解了本章的内容，并且已经完成了内核模块和任务(如下所示)。那么，让我们带你去下一个！

# 问题

作为我们的总结，这里有一个问题列表，供您测试您对本章材料的知识:[https://github . com/packt publishing/Linux-Kernel-Programming/tree/master/questions](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions)。你会在这本书的 GitHub repo 中找到一些问题的答案:[https://GitHub . com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions _ to _ assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn)。

# 进一步阅读

为了帮助您用有用的材料更深入地研究这个主题，我们在本书的 GitHub 存储库中的进一步阅读文档中提供了一个相当详细的在线参考资料和链接列表(有时甚至是书籍)。*进一步阅读*文档可在此处获得:[https://github . com/packt publishing/Linux-Kernel-Programming/blob/master/进一步阅读. md](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md) 。*******