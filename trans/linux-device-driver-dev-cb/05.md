# 管理中断和并发

实现设备驱动程序时，开发人员必须解决两个主要问题:

*   如何与外设交换数据
*   如何管理外设对中央处理器产生的中断

前几章已经讨论了第一点(至少对于 char 驱动程序)，而第二点(及其相关内容)将是本章的主题。

在内核中，我们可以考虑运行在两个主要执行上下文中的中央处理器(或执行某些代码的内部内核)——**中断上下文**和**进程上下文**。中断上下文非常容易理解；事实上，CPU 每次执行中断处理程序(即每次中断发生时内核执行的特殊代码)时都处于这种上下文中。除此之外，中断可以由硬件甚至软件产生；这就是我们讨论硬件中断和软件中断的原因(我们将在接下来的章节中仔细研究软件中断)，它们依次定义了**硬件中断上下文**和**软件中断上下文**。

另一方面，**进程上下文**是指 CPU(或其内部核心之一)在内核空间中执行某个进程的某些代码(进程也在用户空间中执行，但我们在此不做介绍)，即 CPU 执行某个进程已经调用的系统调用的代码(参见[第 3 章](03.html)、*使用 Char 驱动程序*)。在这种情况下，很常见的是让出 CPU，然后暂停当前进程，因为外围设备的一些数据还没有准备好被读取；例如；这可以通过要求调度程序获取 CPU，然后将其分配给另一个进程来实现。当这种情况发生时，我们通常说当前的**进程已经进入睡眠状态，**并且当数据新可用时，我们说一个**进程已经被唤醒**，并且，它从先前中断的地方重新开始它的执行。

在本章中，我们将看到如何执行所有这些操作，设备驱动程序开发人员如何请求内核暂停当前的读取进程，因为外围设备没有准备好响应请求，以及如何唤醒正在睡眠的进程。我们还将看到如何管理对我们的驱动程序方法的并发访问，以避免由于竞争条件导致的数据损坏，以及如何管理时间流，以便在明确定义的时间量之后执行特定的操作，同时考虑外围设备可能需要的时间限制。

我们还将研究如何在 char 驱动程序和用户空间之间交换数据，以及如何处理驱动程序应该能够管理的内核事件。第一个(可能也是最重要的)例子是如何管理中断，接下来是如何“及时”推迟一个作业，以及如何等待一个事件。我们可以使用以下方法完成所有这些工作:

*   实现中断处理程序
*   推迟工作
*   用内核定时器管理时间
*   等待事件
*   进行原子操作

# 技术要求

关于本章的更多信息，可以访问*附录*。

本章使用的代码和其他文件可以在[https://GitHub . com/gio metti/Linux _ device _ driver _ development _ cook book/tree/master/chapter _ 05](https://github.com/giometti/linux_device_driver_development_cookbook/tree/master/chapter_05)下载。

# 实现中断处理程序

在内核内部，**中断处理程序**是与 CPU 中断线路(或引脚)相关联的功能，只要与该线路连接的外围设备改变引脚状态，Linux 就会执行该功能；当这种情况发生时，会为 CPU 生成一个中断请求，并由内核捕获，内核再执行适当的处理程序。

在这个方法中，我们将看到如何安装一个中断处理程序，每当一个中断发生在一个定义明确的行上时，内核就执行这个中断处理程序。

# 准备好

实现中断处理程序最简单的代码是`linux/drivers/misc/dummy-irq.c`中的代码。以下是处理程序:

```
static int irq = -1;

static irqreturn_t dummy_interrupt(int irq, void *dev_id)
{
    static int count = 0;

    if (count == 0) {
        printk(KERN_INFO "dummy-irq: interrupt occurred on IRQ %d\n",
                irq);
        count++;
    }

    return IRQ_NONE;
}
```

下面是安装或删除它的代码:

```
static int __init dummy_irq_init(void)
{
    if (irq < 0) {
        printk(KERN_ERR "dummy-irq: no IRQ given. Use irq=N\n");
        return -EIO;
    }
    if (request_irq(irq, &dummy_interrupt, IRQF_SHARED, "dummy_irq", &irq)) {
        printk(KERN_ERR "dummy-irq: cannot register IRQ %d\n", irq);
        return -EIO;
    }
    printk(KERN_INFO "dummy-irq: registered for IRQ %d\n", irq);
    return 0;
}

static void __exit dummy_irq_exit(void)
{
    printk(KERN_INFO "dummy-irq unloaded\n");
    free_irq(irq, &irq);
}
```

这段代码真的很简单，我们可以看到，它调用了`dummy_irq_init()`模块初始化函数中的`request_irq()`函数，`dummy_irq_exit()`模块退出函数中的`free_irq()`函数。然后，这两个函数分别要求内核将`dummy_interrupt()`中断处理程序连接到`irq`中断线上，并在相反的操作中，将处理程序从中断线上分离。

这段代码简要展示了如何安装中断处理程序；但是，它没有显示设备驱动程序的开发人员如何安装自己的处理程序；这就是为什么在下一节中，我们将使用用通用输入输出线(GPIO)模拟的真实中断线路来做一个实际的例子。

为了对我们的第一个**中断请求** ( **IRQ** )处理程序进行管理，我们可以使用一个普通的 GPIO 作为中断线路；但是，在这样做之前，我们必须验证我们的 GPIO 线路是否正确检测到高输入电平和低输入电平。

为了管理 GPIOs，我们将使用它的 sysfs 接口，因此，首先，我们必须通过检查`/sys/class/gpio`目录是否存在来验证它当前是否为我们的内核启用。如果没有，我们将不得不使用内核配置菜单(`make menuconfig`)来启用`CONFIG_GPIO_SYSFS`内核配置条目；可以通过转到设备驱动程序，然后转到 GPIO 支持，并启用/sys/class/gpio/...(sysfs 接口)菜单条目。

一种快速检查条目是否已启用的方法是使用以下命令行:

```
$ rgrep CONFIG_GPIO_SYSFS .config
CONFIG_GPIO_SYSFS=y
```

否则，如果未启用，我们将获得以下输出，然后我们必须启用它:

```
$ rgrep CONFIG_GPIO_SYSFS .config
# CONFIG_GPIO_SYSFS is not set
```

如果一切就绪，我们应该得到类似于以下内容的东西:

```
# ls /sys/class/gpio/
export  gpiochip446  gpiochip476  unexport
```

`gpiochip446`和`gpiochip476`目录代表两个 ESPRESSObin 的 GPIOs 控制器，正如我们在前面描述设备树的章节中看到的。(参见[第 4 章](09.html)、*附录中*无敌 3720* 部分使用设备树、*、*为特定外设配置中央处理器引脚*部分)。`export`和`unexport`文件用于访问 GPIO 线路。

为了完成我们的工作，我们需要访问 MPP2_20 CPU 线，它被映射到 ESPRESSObin 扩展#2 的第 12 针；即 ESPRESSObin 示意图上的连接器 P8(或 J18)。(详见[第一章](01.html)中*技术要求*部分，一*安装开发系统*)。在 CPU 数据表中，我们发现 MPP2_20 线连接到第二个 pinctrl 控制器(名为南桥，在设备树中映射为`pinctrl_sb: pinctrl@18800`)。为了知道哪个是正确的 gpiochip 设备，我们仍然可以使用 sysfs，如下所示:

```
# ls -l /sys/class/gpio/gpiochip4*
lrwxrwxrwx 1 root root 0 Mar 7 20:20 /sys/class/gpio/gpiochip446 ->
  ../../devices/platform/soc/soc:internal-regs@d0000000/d0018800.pinctrl/gpio/gpiochip446
lrwxrwxrwx 1 root root 0 Mar 7 20:20 /sys/class/gpio/gpiochip476 ->
  ../../devices/platform/soc/soc:internal-regs@d0000000/d0013800.pinctrl/gpio/gpiochip476
```

现在很明显，我们必须使用`gpiochip446`。在该目录中，我们将找到`base`文件，该文件告诉我们第一个 GPIO 行的相应编号，并且，由于我们使用的是第 20 行，我们应该如下导出`base+20` GPIO 行:

```
# cat /sys/class/gpio/gpiochip446/base 
446
# echo 466 > /sys/class/gpio/export 
```

如果一切正常，新的`gpio466`条目现在出现在`/sys/class/gpio`目录中，对应于我们刚刚导出的 GPIO 行:

```
# ls /sys/class/gpio/ 
export  gpio466  gpiochip446  gpiochip476  unexport
```

太好了。`gpio466`目录现在可以使用了，通过查看它，我们得到了以下文件:

```
# ls /sys/class/gpio/gpio466/
active_low device direction edge power subsystem uevent value
```

要查看我们是否能够修改我们的 GPIO 行，我们可以简单地使用以下命令:

```
cat /sys/class/gpio/gpio466/value 
1
```

Note that the line is set to 1, even if unconnected, because this pin is normally configured with an internal pull-up that forces the pin state to the high level.

该输出告诉我们，GPIO 线 20 当前为高电平，但是，如果我们将 P8 连接器的引脚 12 连接到同一连接器(P8/J8)的地(引脚 1 或 2)，GPIO 线应该进入下行状态，前面的命令现在应该返回 0，如下所示:

```
# cat /sys/class/gpio/gpio466/value 
0
```

If the line doesn't change, you should verify that you're working on the correct pins/connector. Also, you should take a look at the `/sys/class/gpio/gpio466/direction` file, which should hold the `in` string, shown as follows:
**`# cat /sys/class/gpio/gpio466/direction`**
`in`

好的。现在我们准备好生成中断了！

# 怎么做...

让我们看看如何通过以下步骤来实现:

1.  现在，让我们假设我们有一个名为`irqtest`的专用平台驱动程序，在 ESPRESSObin 设备树中定义如下:

```
    irqtest {
        compatible = "ldddc,irqtest";

        gpios = <&gpiosb 20 GPIO_ACTIVE_LOW>;
    };
```

Remember that the ESPRESSObin device tree file is `linux/arch/arm64/boot/dts/marvell/armada-3720-espressobin.dts`.

2.  然后，我们必须向内核添加一个平台驱动程序，就像我们在上一章中用以下代码所做的那样:

```
static const struct of_device_id irqtest_dt_ids[] = {
    { .compatible = "ldddc,irqtest", },
    { /* sentinel */ }
};
MODULE_DEVICE_TABLE(of, irqtest_dt_ids);

static struct platform_driver irqtest_driver = {
    .probe = irqtest_probe,
    .remove = irqtest_remove,
    .driver = {
        .name = "irqtest",
        .of_match_table = irqtest_dt_ids,
    },
};

module_platform_driver(irqtest_driver);
```

Note that all code presented here can be obtained from the GitHub repository by applying the `add_irqtest_module.patch` patch within the root directory of kernel sources by executing the `patch` command, as follows:
`**$ patch -p1 < ../linux_device_driver_development_cookbook/chapter_5/add_irqtest_module.patch**`

3.  现在，我们知道了，一旦内核在设备树中检测到一个驱动程序与`ldddc,irqtest`兼容，就应该执行下面的`irqtest_probe()`探测功能。这个功能与前面`linux/drivers/misc/dummy-irq.c`文件中的功能非常相似，尽管有点复杂。事实上，首先我们必须通过使用`of_get_gpio()`功能从设备树中读取中断将来自的 GPIO 线:

```
static int irqtest_probe(struct platform_device *pdev)
{
    struct device *dev = &pdev->dev;
    struct device_node *np = dev->of_node;
    int ret;

    /* Read gpios property (just the first entry) */
    ret = of_get_gpio(np, 0); 
    if (ret < 0) {
        dev_err(dev, "failed to get GPIO from device tree\n");
        return ret;
    }
    irqinfo.pin = ret;
    dev_info(dev, "got GPIO %u from DTS\n", irqinfo.pin);
```

4.  然后，我们必须通过使用`devm_gpio_request()`函数向内核请求 GPIO 行:

```
    /* Now request the GPIO and set the line as an input */
    ret = devm_gpio_request(dev, irqinfo.pin, "irqtest");
    if (ret) {
        dev_err(dev, "failed to request GPIO %u\n", irqinfo.pin);
        return ret;
    }
    ret = gpio_direction_input(irqinfo.pin);
    if (ret) {
        dev_err(dev, "failed to set pin input direction\n");
        return -EINVAL;
    }

    /* Now ask to the kernel to convert GPIO line into an IRQ line */
    ret = gpio_to_irq(irqinfo.pin);
    if (ret < 0) {
        dev_err(dev, "failed to map GPIO to IRQ!\n");
        return -EINVAL;
    }
    irqinfo.irq = ret;
    dev_info(dev, "GPIO %u correspond to IRQ %d\n",
                irqinfo.pin, irqinfo.irq);
```

5.  在我们确定 GPIO 仅用于我们之后，我们必须使用`gpio_direction_input()`功能将其设置为输入(中断是输入信号)，然后我们必须使用`gpio_to_irq()`功能获得相应的中断线路号(通常是不同的号码):

```
    ret = gpio_direction_input(irqinfo.pin);
    if (ret) {
        dev_err(dev, "failed to set pin input direction\n");
        return -EINVAL;
    }

    /* Now ask to the kernel to convert GPIO line into an IRQ line */
    ret = gpio_to_irq(irqinfo.pin);
    if (ret < 0) {
        dev_err(dev, "failed to map GPIO to IRQ!\n");
        return -EINVAL;
    }
    irqinfo.irq = ret;
    dev_info(dev, "GPIO %u correspond to IRQ %d\n",
                irqinfo.pin, irqinfo.irq);
```

6.  之后，我们有了使用`linux/include/linux/interrupt.h`头文件中定义的`request_irq()`函数安装中断处理程序的所有必要信息，如下所示:

```
extern int __must_check
request_threaded_irq(unsigned int irq, irq_handler_t handler,
            irq_handler_t thread_fn,
            unsigned long flags, const char *name, void *dev);

static inline int __must_check
request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags,
            const char *name, void *dev)
{
    return request_threaded_irq(irq, handler, NULL, flags, name, dev);
}

extern int __must_check
request_any_context_irq(unsigned int irq, irq_handler_t handler,
            unsigned long flags, const char *name, void *dev_id);
```

7.  最后，`handler`参数指定了作为中断处理程序执行的函数，`dev`是一个指针，内核在执行时将原样传递给处理程序。在我们的示例中，中断处理程序定义如下:

```
static irqreturn_t irqtest_interrupt(int irq, void *dev_id)
{
    struct irqtest_data *info = dev_id;
    struct device *dev = info->dev;

    dev_info(dev, "interrupt occurred on IRQ %d\n", irq);

    return IRQ_HANDLED;
}
```

# 它是如何工作的...

在*步骤 1* 中，该节点声明了一个与名为`ldddc,irqtest`的驱动程序兼容的设备，该设备要求使用`gpiosb`节点的 GPIO 线 20，在 Armada 3270 设备树`arch/arm64/boot/dts/marvell/armada-37xx.dtsi`文件中定义如下:

```
    pinctrl_sb: pinctrl@18800 {
        compatible = "marvell,armada3710-sb-pinctrl",
                 "syscon", "simple-mfd";
        reg = <0x18800 0x100>, <0x18C00 0x20>;
        /* MPP2[23:0] */
        gpiosb: gpio {
            #gpio-cells = <2>;
            gpio-ranges = <&pinctrl_sb 0 0 30>;
            gpio-controller;
            interrupt-controller;
            #interrupt-cells = <2>;
            interrupts =
            <GIC_SPI 160 IRQ_TYPE_LEVEL_HIGH>,
            <GIC_SPI 159 IRQ_TYPE_LEVEL_HIGH>,
            <GIC_SPI 158 IRQ_TYPE_LEVEL_HIGH>,
            <GIC_SPI 157 IRQ_TYPE_LEVEL_HIGH>,
            <GIC_SPI 156 IRQ_TYPE_LEVEL_HIGH>;
        };
   ...
```

Here, we have the confirmation that the `gpiosb` node is related to MPP2 lines.

在*步骤 2* 中，我们只在内核中声明驱动程序，而在*步骤* *3* 中，函数从`gpio`属性中获取 GPIO 信息，通过使用设置为`0`的第二个参数，我们只需请求第一个条目。返回值被保存到模块的数据结构中，现在定义如下:

```
static struct irqtest_data {
    int irq;
    unsigned int pin;
    struct device *dev;
} irqinfo;
```

在第 4 步中，实际上`devm_gpio_request()`调用并不是严格需要的，因为我们在内核中，没有人能阻止我们使用资源；然而，如果所有驱动程序都这样做，我们可以确保如果有人持有资源，我们会得到通知！

We should now notice that the `devm_gpio_request()` function does not have a counterpart in the module's `exit()` function `irqtest_remove()` . This is because functions with the `devm` prefix are related to managed devices that are able to automatically deallocate resources when the owner device is removed from the system.
In the `linux/drivers/gpio/devres.c` file, where this function is defined, we see the following comment, which explains how this function works:
`/**`
`* devm_gpio_request - request a GPIO for a managed device`
`* @dev: device to request the GPIO for`
`* @gpio: GPIO to allocate`
`* @label: the name of the requested GPIO`
`*`
`* Except for the extra @dev argument, this function takes the`
`* same arguments and performs the same function as`
`* gpio_request(). GPIOs requested with this function will be`
`* automatically freed on driver detach.`
`*`
`* If an GPIO allocated with this function needs to be freed`
`* separately, devm_gpio_free() must be used.`
`*/`
This is advanced resource management and beyond the scope of this book. However, if you are interested, there is a lot of information on the internet, and the following is a good article to start with: [https://lwn.net/Articles/222860/](https://lwn.net/Articles/222860/).
Anyway the normal counterparts of the `devm_gpio_request()` function are the `gpio_request()` and `gpio_free()` functions.

在步骤 5 中，注意一个 GPIO 行号几乎从不对应一个中断行号；这就是为什么我们需要调用`gpio_to_irq()`函数，以便获得与我们的 GPIO 线相关的正确的 IRQ 线。

在第 6 步中，我们可以看到`request_irq()`函数是`request_threaded_irq()`函数的特例，它通知我们中断处理程序可以在中断上下文中运行，或者在进程上下文中的内核线程中运行。

At the moment, we still don't know what kernel threads are (they will be explained in [Chapter 6](06.html), *Miscellaneous Kernel Internals*), but it should be easy to understand that they are something like a thread (or process) executed in the kernel space.

此外，`request_any_context_irq()`函数可用于根据 IRQ 线路特性，委托内核自动请求正常中断处理程序或线程中断处理程序。

This a really advanced use of interrupt handlers, which is fundamental when we have to manage peripherals (such as I2C or SPI devices) where we need to suspend the interrupt handler to be able to read from, or write data to, the peripheral's registers.

除了这些方面，所有的`request_irq*()`函数都有几个参数。首先是`irq`行，然后是一个符号`name`描述我们可以在`/proc/interrupts`文件中找到的中断行，然后我们可以使用`flags`参数指定一些特殊设置，如下所示(完整列表见`linux/include/linux/interrupt.h`文件):

```
/*
 * These correspond to the IORESOURCE_IRQ_* defines in
 * linux/ioport.h to select the interrupt line behaviour. When
 * requesting an interrupt without specifying a IRQF_TRIGGER, the
 * setting should be assumed to be "as already configured", which
 * may be as per machine or firmware initialisation.
 */
#define IRQF_TRIGGER_NONE 0x00000000
#define IRQF_TRIGGER_RISING 0x00000001
#define IRQF_TRIGGER_FALLING 0x00000002
#define IRQF_TRIGGER_HIGH 0x00000004
#define IRQF_TRIGGER_LOW 0x00000008
...
/*
 * IRQF_SHARED - allow sharing the irq among several devices
 * IRQF_ONESHOT - Interrupt is not reenabled after the hardirq handler finished.
 * Used by threaded interrupts which need to keep the
 * irq line disabled until the threaded handler has been run.
 * IRQF_NO_SUSPEND - Do not disable this IRQ during suspend. Does not guarantee
 * that this interrupt will wake the system from a suspended
 * state. See Documentation/power/suspend-and-interrupts.txt
 */
```

当 IRQ 线路与多个外设共享时，应使用`IRQF_SHARED`标志。(现在它相当无用，但在过去，它非常有用，尤其是在 x86 机器上。)系统使用`IRQF_ONESHOT`标志来确保即使是线程中断处理程序也可以在自己的 IRQ 线被禁用的情况下运行。`IRQF_NO_SUSPEND`标志可用于通过发送适当的中断请求，允许我们的外设将系统从挂起状态唤醒。(详见`linux/Documentation/power/suspend-and-interrupts.txt`文件。)

然后`IRQF_TRIGGER_*`标志可用于指定我们外设的 IRQ 触发模式，即中断是否必须在高电平或低电平或上升或下降转换期间产生。

These last flag groups should be carefully checked against the device tree pinctrl settings; otherwise, we might see some unexpected behavior.

在步骤 7 中，由于在`request_irq()`函数中我们将`dev`参数设置为`struct irqtest_data`模块的指针，当`irqtest_interrupt()`中断处理程序执行时，它将在`dev_id`参数中找到与我们提供给`request_irq()`的指针相同的指针。通过使用这个技巧，我们可以得到从探测函数得到的`dev`值，并且我们可以安全地将其作为`dev_info()`函数的参数重用，就像前面一样。

在我们的例子中，中断处理程序除了显示一条消息之外几乎什么也不做。然而，通常在中断处理程序中，我们必须确认外设，向其读写数据，然后唤醒所有等待外设活动的休眠进程。无论如何，最后，处理程序应该从`linux/include/linux/irqreturn.h`文件中列出的值中返回一个值:

```
/**
 * enum irqreturn
 * @IRQ_NONE interrupt was not from this device or was not handled
 * @IRQ_HANDLED interrupt was handled by this device
 * @IRQ_WAKE_THREAD handler requests to wake the handler thread
 */
```

`IRQ_NONE`值在我们处理共享中断的情况下很有用，它通知系统当前的 IRQ 不适合我们，并且它必须传播到下一个处理程序，而`IRQ_WAKE_THREAD`应该在线程化 IRQ 处理程序的情况下使用。当然，`IRQ_HANDLED`必须用于向系统报告 IRQ 已送达。

# 还有更多...

如果您希望检查这是如何工作的，我们可以通过测试我们的示例来完成。我们必须编译它，然后用我们编译为内置的代码重新安装内核，所以让我们使用通常的`make menuconfig`命令并启用我们的测试代码，或者只使用`make oldconfig`，当系统要求选择时回答`y`，如下所示:

```
Simple IRQ test (IRQTEST_CODE) [N/m/y/?] (NEW)
```

之后，我们只需重新编译并重新安装内核，然后重新启动 ESPRESSObin。如果在引导过程中一切正常，我们应该会看到如下内核消息:

```
irqtest irqtest: got GPIO 466 from DTS
irqtest irqtest: GPIO 466 correspond to IRQ 40
irqtest irqtest: interrupt handler for IRQ 40 is now ready!
```

现在，MPP2_20 线已经被内核取用，转换成 40 号中断线路。为了验证它，我们可以看一下`/proc/interrupts`文件，它保存了内核中所有注册的中断线路。之前，我们在中断处理程序注册过程中使用了`request_irq()`函数中的`irqtest`标签，因此我们必须在文件中使用`grep`进行搜索，如下所示:

```
# grep irqtest /proc/interrupts 
 40:     0     0     GPIO2   20   Edge   irqtest
```

好的。中断线路 40 已经分配给我们的模块，我们注意到这个 IRQ 线路对应于 GPIO2 组的 GPIO 线路 20(即 MPP2_20 线路)。如果我们看一下`/proc/interrupts`文件的开头，应该会得到如下输出:

```
# head -4 /proc/interrupts 
           CPU0   CPU1 
  1:          0      0   GICv3   25   Level   vgic
  3:       5944  20941   GICv3   30   Level   arch_timer
  4:          0      0   GICv3   27   Level   kvm guest timer
...
```

第一个数字是中断线路；第二个和第三个分别显示了 CPU0 和 CPU1 服务了多少个中断，因此我们可以使用这些信息来验证哪个 CPU 服务了我们的中断。

好的。现在我们准备好出发了。只需将引脚 12 连接到 P8 扩展连接器的引脚 1；至少应该生成一个中断，并且应该在内核消息中出现如下消息:

```
irqtest irqtest: interrupt occurred on IRQ 40
```

Note that you may get several messages due to the fact that, during the short circuit operation, the electrical signal may generate several oscillations, which in turn will generate several interrupts.

最后，让我们看看如果我们尝试使用 sysfs 接口导出 466 号 GPIO 行会发生什么，就像我们之前所做的那样:

```
# echo 466 > /sys/class/gpio/export 
-bash: echo: write error: Device or resource busy
```

现在，我们正确地得到一个繁忙的错误，因为当我们使用`devm_gpio_request()`函数时，内核已经请求了这样一个 GPIO。

# 请参见

*   关于中断处理程序的更多信息，一个很好的起点(即使它有点过时)是位于[https://www.tldp.org/LDP/lkmpg/2.4/html/x1210.html](https://www.tldp.org/LDP/lkmpg/2.4/html/x1210.html)T2【的 Linux 内核模块编程指南】。

# 推迟工作

中断是由外围设备生成的事件，但是，如前所述，它们不是内核可以处理的唯一事件。事实上，软件中断是存在的，它类似于硬件中断，但由软件产生。在这本书里，我们会看到两个这样的软件中断的例子；这两种方法都可以用来安全地将工作推迟到将来。我们还将了解一种有用的机制，设备驱动程序开发人员可以使用这种机制来捕获特殊的内核事件并执行相应的操作(例如，当网络设备启用时，或者系统正在重新启动时，等等)。

在本食谱中，我们将看到当内核中发生特定事件时，如何推迟作业。

# 准备好了

由于小任务和工作队列是为了推迟作业而实现的，它们的主要用途是在中断处理程序中，我们只需确认中断请求(通常称为 IRQ)，然后调用小任务/工作队列来完成作业。

然而，不要忘记这只是小任务和工作队列的几种可能用法之一，当然，即使没有中断也可以使用。

# 怎么做...

在这一节中，我们将针对前面的`irqtest.c`示例，通过使用补丁来展示关于小任务和工作队列的简单示例。

在接下来的章节中，无论何时需要，我们都将展示这些机制的更复杂的用法，但是，目前，我们只对理解它们的基本用法感兴趣。

# 小任务

让我们看看如何通过以下步骤来实现:

1.  需要进行以下修改，以便向我们的`irqtest_interrupt()`中断处理程序添加自定义小任务调用:

```
--- a/drivers/misc/irqtest.c
+++ b/drivers/misc/irqtest.c
@@ -26,9 +26,19 @@ static struct irqtest_data {
 } irqinfo;

 /*
- * The interrupt handler
+ * The interrupt handlers
  */

+static void irqtest_tasklet_handler(unsigned long flag)
+{
+     struct irqtest_data *info = (struct irqtest_data *) flag;
+     struct device *dev = info->dev;
+
+     dev_info(dev, "tasklet executed after IRQ %d", info->irq);
+}
+DECLARE_TASKLET(irqtest_tasklet, irqtest_tasklet_handler,
+                   (unsigned long) &irqinfo);
+
 static irqreturn_t irqtest_interrupt(int irq, void *dev_id)
 {
      struct irqtest_data *info = dev_id;
@@ -36,6 +46,8 @@ static irqreturn_t irqtest_interrupt(int irq, void *dev_id)

      dev_info(dev, "interrupt occurred on IRQ %d\n", irq);

+     tasklet_schedule(&irqtest_tasklet);
+
      return IRQ_HANDLED;
 }

@@ -98,6 +110,7 @@ static int irqtest_remove(struct platform_device *pdev)
 {
      struct device *dev = &pdev->dev;

+     tasklet_kill(&irqtest_tasklet);
      free_irq(irqinfo.irq, &irqinfo);
      dev_info(dev, "IRQ %d is now unmanaged!\n", irqinfo.irq);
```

The previous patch can be found in the GitHub resources in the `add_tasklet_to_irqtest_module.patch` file, and it can be applied as usual with the
**`patch -p1 < add_tasklet_to_irqtest_module.patch`** command.

2.  一旦定义了小任务，就可以使用`tasklet_schedule()`函数调用它，如前所示。要停止它，我们可以使用`tasklet_kill()`函数，在我们的例子中是`irqtest_remove()`函数，在从内核卸载模块之前停止小任务。事实上，在卸载我们的模块或发生内存损坏之前，我们必须确保之前由我们的驱动程序分配和/或启用的每个资源都已被禁用和/或释放。
    注意`DECLARE_TASKLET()`的编译时用法不是声明小任务的唯一方法。事实上，以下是一种替代方式:

```
--- a/drivers/misc/irqtest.c
+++ b/drivers/misc/irqtest.c
@@ -23,12 +23,21 @@ static struct irqtest_data {
      int irq;
      unsigned int pin;
      struct device *dev;
+     struct tasklet_struct task;
 } irqinfo;

 /*
- * The interrupt handler
+ * The interrupt handlers
  */

+static void irqtest_tasklet_handler(unsigned long flag)
+{
+     struct irqtest_data *info = (struct irqtest_data *) flag;
+     struct device *dev = info->dev;
+
+     dev_info(dev, "tasklet executed after IRQ %d", info->irq);
+}
+
 static irqreturn_t irqtest_interrupt(int irq, void *dev_id)
 {
      struct irqtest_data *info = dev_id;
@@ -36,6 +45,8 @@ static irqreturn_t irqtest_interrupt(int irq, void *dev_id)

      dev_info(dev, "interrupt occurred on IRQ %d\n", irq);

+     tasklet_schedule(&info->task);
+
      return IRQ_HANDLED;
 }

@@ -80,6 +91,10 @@ static int irqtest_probe(struct platform_device *pdev)
      dev_info(dev, "GPIO %u correspond to IRQ %d\n",
                                irqinfo.pin, irqinfo.irq);
```

然后，我们创建我们的小任务如下:

```
+     /* Create our tasklet */
+     tasklet_init(&irqinfo.task, irqtest_tasklet_handler,
+                               (unsigned long) &irqinfo);
+
      /* Request IRQ line and setup corresponding handler */
      irqinfo.dev = dev;
      ret = request_irq(irqinfo.irq, irqtest_interrupt, 0,
@@ -98,6 +113,7 @@ static int irqtest_remove(struct platform_device *pdev)
 {
      struct device *dev = &pdev->dev;

+     tasklet_kill(&irqinfo.task);
      free_irq(irqinfo.irq, &irqinfo);
      dev_info(dev, "IRQ %d is now unmanaged!\n", irqinfo.irq);
```

The preceding patch can be found in the GitHub resources in the `add_tasklet_2_to_irqtest_module.patch` file, and it can be applied as usual with the
**`patch -p1 < add_tasklet_2_to_irqtest_module.patch`** command.

当我们必须在设备结构中嵌入小任务，然后动态生成它时，第二种形式非常有用。

# 工作队列

现在让我们来看看工作队列。在下面的例子中，我们添加了一个由`irqtest_wq`指针引用并命名为`irqtest`的自定义工作队列，它依次执行由`work`和`dwork`结构描述的两个不同的工作:前者是正常工作，而后者代表延迟工作，即在众所周知的延迟之后执行的工作。

1.  首先，我们必须添加我们的数据结构:

```
a/drivers/misc/irqtest.c
+++ b/drivers/misc/irqtest.c
@@ -14,6 +14,7 @@
 #include <linux/gpio.h>
 #include <linux/irq.h>
 #include <linux/interrupt.h>
+#include <linux/workqueue.h>

 /*
  * Module data
@@ -23,12 +24,37 @@ static struct irqtest_data {
        int irq;
      unsigned int pin;
      struct device *dev;
+     struct work_struct work;
+     struct delayed_work dwork;
 } irqinfo;

+static struct workqueue_struct *irqtest_wq;
...
```

All these modifications can be found in the GitHub resources in the `add_workqueue_to_irqtest_module.patch` file and it can be applied as usual with the
**`patch -p1 < add_workqueue_to_irqtest_module.patch`** command.

2.  然后，我们必须创建工作队列，它就可以工作了。对于工作队列的创建，我们可以使用`create_singlethread_workqueue()`功能，而这两个工作可以使用`INIT_WORK()`和`INIT_DELAYED_WORK(),`进行初始化，如下所示:

```
@@ -80,24 +108,40 @@ static int irqtest_probe(struct platform_device *pdev)
      dev_info(dev, "GPIO %u correspond to IRQ %d\n",
                                irqinfo.pin, irqinfo.irq);

+     /* Create our work queue and init works */
+     irqtest_wq = create_singlethread_workqueue("irqtest");
+     if (!irqtest_wq) {
+         dev_err(dev, "failed to create work queue!\n");
+         return -EINVAL;
+     }
+     INIT_WORK(&irqinfo.work, irqtest_work_handler);
+     INIT_DELAYED_WORK(&irqinfo.dwork, irqtest_dwork_handler);
+
      /* Request IRQ line and setup corresponding handler */
      irqinfo.dev = dev;
      ret = request_irq(irqinfo.irq, irqtest_interrupt, 0,
                                "irqtest", &irqinfo);
      if (ret) {
          dev_err(dev, "cannot register IRQ %d\n", irqinfo.irq);
-         return -EIO;
+         goto flush_wq;
      }
      dev_info(dev, "interrupt handler for IRQ %d is now ready!\n",
                                irqinfo.irq);

      return 0;
+
+flush_wq:
+     flush_workqueue(irqtest_wq);
+     return -EIO;
 }
```

To create a workqueue, we can also use the `create_workqueue()` function; however, this creates a workqueue that has a dedicated thread for each processor on the system. In many cases, all those threads are simply overkilled and the single worker thread obtained with `create_singlethread_workqueue()` will suffice. Note that the Concurrency Managed Workqueue API, available in the kernel's documentation file (`linux/Documentation/core-api/workqueue.rst`), states that the `create_*workqueue()` functions are deprecated and scheduled for removal. However, they seem to be still widely used with kernel sources.

3.  接下来是处理程序主体，表示正常工作队列和延迟工作队列的有效工作负载，如下所示:

```
+static void irqtest_dwork_handler(struct work_struct *ptr)
+{
+     struct irqtest_data *info = container_of(ptr, struct irqtest_data,
+                                                   dwork.work);
+     struct device *dev = info->dev;
+
+     dev_info(dev, "delayed work executed after work");
+}
+
+static void irqtest_work_handler(struct work_struct *ptr)
+{
+     struct irqtest_data *info = container_of(ptr, struct irqtest_data,
+                                                   work);
+     struct device *dev = info->dev;
+
+     dev_info(dev, "work executed after IRQ %d", info->irq);
+
+     /* Schedule the delayed work after 2 seconds */
+     queue_delayed_work(irqtest_wq, &info->dwork, 2*HZ);
+}
```

Note that to specify a delay of two seconds we used the `2*HZ `code, where `HZ` is a define (see the next section for further information about `HZ`) representing how many jiffies are needed to compose one second. So, to have a delay of two seconds, we have to multiply `HZ` by two.

4.  中断处理程序现在只使用下面的`queue_work()`函数在返回之前执行第一个工作队列:

```
@@ -36,6 +62,8 @@ static irqreturn_t irqtest_interrupt(int irq, void *dev_id)

      dev_info(dev, "interrupt occurred on IRQ %d\n", irq);

+     queue_work(irqtest_wq, &info->work);
+
      return IRQ_HANDLED;
 }
```

因此，当`irqtest_interrupt()`结束时，系统调用`irqtest_work_handler()`，然后通过使用`queue_delayed_work()`以两秒钟的延迟调用`irqtest_dwork_handler()`。

5.  最后，对于小任务，在退出模块之前，我们必须取消所有工作和工作队列(如果创建的话)，方法是使用`cancel_work_sync()`进行正常工作，`cancel_delayed_work_sync()`进行延迟工作，以及(在我们的例子中)`flush_workqueue()`停止`irqtest`工作队列:

```
 static int irqtest_remove(struct platform_device *pdev)
 {
      struct device *dev = &pdev->dev;

+     cancel_work_sync(&irqinfo.work);
+     cancel_delayed_work_sync(&irqinfo.dwork);
+     flush_workqueue(irqtest_wq);
      free_irq(irqinfo.irq, &irqinfo);
      dev_info(dev, "IRQ %d is now unmanaged!\n", irqinfo.irq);
```

# 还有更多...

我们可以通过测试我们的例子来检查它是如何工作的。因此，我们必须应用所需的补丁，然后我们必须重新编译内核，重新安装并重新启动 ESPRESSObin。

# 小任务

为了测试小任务，我们可以像以前一样，将扩展连接器 P8 的引脚 12 连接到引脚 1。以下是我们应该获得的内核消息:

```
irqtest irqtest: interrupt occurred on IRQ 40
irqtest irqtest: tasklet executed after IRQ 40
```

如预期的那样，产生一个 IRQ，然后由硬件`irqtest_interrupt()`中断处理器管理，该处理器依次执行`irqtest_tasklet_handler()`。小任务处理器。

# 工作队列

为了测试工作队列，我们必须短路我们众所周知的引脚，我们应该有如下输出:

```
[ 33.113008] irqtest irqtest: interrupt occurred on IRQ 40
[ 33.115731] irqtest irqtest: work executed after IRQ 40
...
[ 33.514268] irqtest irqtest: interrupt occurred on IRQ 40
[ 33.516990] irqtest irqtest: work executed after IRQ 40
[ 33.533121] irqtest irqtest: interrupt occurred on IRQ 40
[ 33.535846] irqtest irqtest: work executed after IRQ 40
[ 35.138114] irqtest irqtest: delayed work executed after work
```

Note that, this time, I didn't remove the first part of kernel messages, in order to see timings, and to better evaluate delay between the normal work and delayed one.

正如我们所看到的，只要我们连接 ESPRESSObin 引脚，我们就有几个中断跟随着工作，但是延迟的工作只执行一次。发生这种情况是因为，即使调度了几次，也只是第一次调用才生效，所以在这里我们可以看到，延迟的工作在其第一次`schedule_work()`调用后 2.025106 秒终于被执行了。这也意味着它已经比要求和预期的两秒钟晚了 25.106 毫秒被有效执行。这样一个明显的异常是由于这样一个事实，当您要求内核安排一些工作在延迟的工作队列中在稍后的时间点发生时，内核肯定会在未来的期望点安排您的工作，但是它不能保证您将在那个时间点执行它。它只会向你保证，这样的工作不会早于要求的截止日期。这种额外随机延迟的长度取决于当时的系统工作负载水平。

# 请参见

*   关于小任务，不妨看看[https://www . kernel . org/doc/html docs/kernel-hacking/basic-softirqs . html .](https://www.kernel.org/doc/htmldocs/kernel-hacking/basics-softirqs.html)
*   关于工作队列，更多信息请访问[https://www . kernel . org/doc/html/v 4.15/core-API/workqueue . html](https://www.kernel.org/doc/html/v4.15/core-api/workqueue.html)。

# 用内核定时器管理时间

在设备驱动程序开发过程中，可能需要在特定的时刻执行几个重复的操作，或者我们可能不得不在明确定义的延迟后推迟一些代码的执行。在这些情况下，内核定时器来帮助设备驱动程序开发人员。

在本食谱中，我们将看到如何使用内核定时器在明确定义的时间段内重复执行任务，或者将任务推迟到明确定义的时间间隔之后。

# 准备好了

对于内核定时器的一个简单例子，我们仍然可以使用一个内核模块，在这个模块的初始化函数中定义一个内核定时器。

在 GitHub 资源的`chapter_05/timer`目录中，有两个关于**内核定时器** ( **ktimer** )和**高分辨率定时器** ( **hrtimer** )的简单例子，在接下来的章节中，我们将详细解释它们，从新的高分辨率实现开始，这应该是新驱动中的首选。还提供了一个旧的应用编程接口来完成图片。

# 怎么做...

`hires_timer.c`文件的以下主要部分包含一个关于高分辨率内核定时器的简单示例。

1.  让我们从文件的结尾开始，用模块`init()`功能:

```
static int __init hires_timer_init(void)
{
    /* Set up hires timer delay */

    pr_info("delay is set to %dns\n", delay_ns);

    /* Setup and start the hires timer */
    hrtimer_init(&hires_tinfo.timer, CLOCK_MONOTONIC,
                HRTIMER_MODE_REL | HRTIMER_MODE_SOFT);
    hires_tinfo.timer.function = hires_timer_handler;
    hrtimer_start(&hires_tinfo.timer, ns_to_ktime(delay_ns),
                HRTIMER_MODE_REL | HRTIMER_MODE_SOFT);

    pr_info("hires timer module loaded\n");
    return 0;
}
```

我们来看看`exit()`功能模块的位置:

```
static void __exit hires_timer_exit(void)
{
    hrtimer_cancel(&hires_tinfo.timer);

    pr_info("hires timer module unloaded\n");
}

module_init(hires_timer_init);
module_exit(hires_timer_exit);
```

正如我们在模块`hires_timer_init()`初始化函数中看到的，我们读取`delay_ns`参数，并且，使用`hrtimer_init()`函数，我们首先通过指定一些特征来初始化定时器:

```
/* Initialize timers: */
extern void hrtimer_init(struct hrtimer *timer, clockid_t which_clock,
                         enum hrtimer_mode mode);
```

使用`which_clock`参数，我们要求内核使用特定的时钟。在我们的示例中，我们使用了`CLOCK_MONOTONIC`，这对于可靠的时间戳和精确测量短时间间隔非常有用(它在系统启动时开始，但在挂起期间停止)，但是我们可以使用其他值(完整列表请参见`linux/include/uapi/linux/time.h`头文件)，例如:

2.  定时器初始化后，我们必须使用`function`指针设置回调或处理函数，如下所示，这里我们已经将`timer.function`设置为`hires_timer_handler`:

```
hires_tinfo.timer.function = hires_timer_handler;
```

这次`hires_tinfo`模块数据结构定义如下:

```
static struct hires_timer_data {
    struct hrtimer timer;
    unsigned int data;
} hires_tinfo;
```

3.  计时器初始化后，我们可以通过调用`hrtimer_start()`来启动它，在这里我们只需使用类似`ns_to_ktime()`的函数来设置到期时间，以防我们有时间间隔，或者使用`ktime_set()`，以防我们有秒/纳秒值。

See the `linux/include/linux/ktime.h` header for more of the `ktime*()` functions.

如果我们看一下`linux/include/linux/hrtimer.h`文件，我们发现启动高分辨率计时器的主要功能是`hrtimer_start_range_ns()`，`hrtimer_start()`是该功能的一个特例，如下图所示:

```
/* Basic timer operations: */
extern void hrtimer_start_range_ns(struct hrtimer *timer, ktime_t tim,
                           u64 range_ns, const enum hrtimer_mode mode);

/**
 * hrtimer_start - (re)start an hrtimer
 * @timer: the timer to be added
 * @tim: expiry time
 * @mode: timer mode: absolute (HRTIMER_MODE_ABS) or
 * relative (HRTIMER_MODE_REL), and pinned (HRTIMER_MODE_PINNED);
 * softirq based mode is considered for debug purpose only!
 */
static inline void hrtimer_start(struct hrtimer *timer, ktime_t tim,
                                 const enum hrtimer_mode mode)
{
    hrtimer_start_range_ns(timer, tim, 0, mode);
}
```

We also discover that the `HRTIMER_MODE_SOFT` mode should not be used apart from for debugging purposes.

通过使用`hrtimer_start_range_ns()`函数，我们允许`range_ns`增量时间，这使内核可以自由地将实际唤醒时间安排在对功耗和性能都友好的时间。内核为到期时间加上增量给出正常的尽力而为行为，但是可以决定更早地启动定时器，但是不能早于`tim`到期时间。

4.  来自`hires_timer.c`文件的`hires_timer_handler()`函数是回调函数的一个例子:

```
static enum hrtimer_restart hires_timer_handler(struct hrtimer *ptr)
{
    struct hires_timer_data *info = container_of(ptr,
                    struct hires_timer_data, timer);

    pr_info("kernel timer expired at %ld (data=%d)\n",
                jiffies, info->data++);

    /* Now forward the expiration time and ask to be rescheduled */
    hrtimer_forward_now(&info->timer, ns_to_ktime(delay_ns));
    return HRTIMER_RESTART;
}
```

通过使用`container_of()`操作符，我们可以获取一个指向我们的数据结构的指针(在示例中定义为`struct hires_timer_data`)，然后，在完成我们的工作之后，我们调用`hrtimer_forward_now()`来设置一个新的到期时间，并且，通过返回`HRTIMER_RESTART`值，我们要求内核重启定时器。对于一次性计时器，我们可以返回`HRTIMER_NORESTART`。

5.  在模块退出时，在`hires_timer_exit()`功能内，我们必须使用`hrtimer_cancel()`功能等待定时器停止。等待计时器停止真的很重要，因为计时器是异步事件，在计时器回调执行时，我们可能会删除`struct hires_timer_data`模块释放结构，这可能会导致严重的内存损坏！

请注意，同步是作为睡眠(或暂停)`process,`实现的，这意味着当我们处于中断上下文(硬或软)时，无法调用`hrtimer_cancel()`功能。但是，在这些情况下，我们可以使用`hrtimer_try_to_cancel()`，如果计时器已经正确停止(或者根本不活动)，它会简单地返回一个非负值。

# 它是如何工作的...

为了了解它是如何工作的，我们通过像往常一样简单地编译代码来测试我们的代码，然后将代码移动到我们的 ESPRESSObin 中。一切就绪后，我们只需将模块加载到内核中，如下所示:

```
# insmod hires_timer.ko
```

然后，在内核消息中，我们应该得到如下内容:

```
[ 528.902156] hires_timer:hires_timer_init: delay is set to 1000000000ns
[ 528.911593] hires_timer:hires_timer_init: hires timer module loaded
```

在*第 1 步*、*第 2 步*、*第 3 步*中，我们设置了定时器，这里我们知道它已经延迟一秒钟启动。

由于步骤 4，当定时器到期时，我们执行内核定时器的处理程序:

```

[ 529.911604] hires_timer:hires_timer_handler: kernel timer expired at 4295024749 (data=0)
[ 530.911602] hires_timer:hires_timer_handler: kernel timer expired at 4295024999 (data=1)
[ 531.911602] hires_timer:hires_timer_handler: kernel timer expired at 4295025249 (data=2)
[ 532.911602] hires_timer:hires_timer_handler: kernel timer expired at 4295025499 (data=3)
...
```

I've left the timings so you have an idea about kernel timer's precision.

我们可以看到，到期时间确实很准确(几微秒)。

现在，由于*步骤 5* ，如果我们移除模块，定时器停止，如下图所示:

```
hires_timer:hires_timer_exit: hires timer module unloaded
```

# 还有更多...

为了完成您的理解，看一下遗留的内核定时器应用编程接口可能会很有趣。

# 传统内核定时器

`ktimer.c`文件包含一个遗留内核定时器的简单例子。像往常一样，让我们从模块`init()`和`exit()`功能所在的文件末尾开始:

```
static int __init ktimer_init(void)
{
    /* Save kernel timer delay */
    ktinfo.delay_jiffies = msecs_to_jiffies(delay_ms);
    pr_info("delay is set to %dms (%ld jiffies)\n",
                delay_ms, ktinfo.delay_jiffies);

    /* Setup and start the kernel timer */
    timer_setup(&ktinfo.timer, ktimer_handler, 0); 
    mod_timer(&ktinfo.timer, jiffies + ktinfo.delay_jiffies);

    pr_info("kernel timer module loaded\n");
    return 0;
}

static void __exit ktimer_exit(void)
{
    del_timer_sync(&ktinfo.timer);

    pr_info("kernel timer module unloaded\n");
}
```

具有处理函数的模块数据结构如下:

```
static struct ktimer_data {
    struct timer_list timer;
    long delay_jiffies;
    unsigned int data;
} ktinfo;

...

static void ktimer_handler(struct timer_list *t)
{
    struct ktimer_data *info = from_timer(info, t, timer);

    pr_info("kernel timer expired at %ld (data=%d)\n",
                jiffies, info->data++);

    /* Reschedule kernel timer */
    mod_timer(&info->timer, jiffies + info->delay_jiffies);
}
```

我们可以看到，这种实现与高分辨率计时器非常相似。事实上，在`ktimer_init()`初始化函数中，我们读取模块`delay_ms`参数，并通过使用`msecs_to_jiffies()`，将其值转换为 jiffies，jiffies 是内核定时器的度量单位。(请记住，传统内核定时器的时间限制较低，为一秒钟。)

然后，我们使用`timer_setup()`和`mod_timer()`功能分别设置和启动内核定时器。`timer_setup()`函数接受三个参数:

```
/**
 * timer_setup - prepare a timer for first use
 * @timer: the timer in question
 * @callback: the function to call when timer expires
 * @flags: any TIMER_* flags
 *
 * Regular timer initialization should use either DEFINE_TIMER() above,
 * or timer_setup(). For timers on the stack, timer_setup_on_stack() must
 * be used and must be balanced with a call to destroy_timer_on_stack().
 */
#define timer_setup(timer, callback, flags) \
    __init_timer((timer), (callback), (flags))
```

一个`struct timer_list`类型的变量`timer`，一个函数`callback`(或处理程序)，以及一些标志(在`flags`变量中)，这些标志可以用来指定我们的内核定时器的一些特定特性。为了让您了解可用标志及其含义，以下是来自`linux/include/linux/timer.h`文件的一些标志定义:

```
/*
 * A deferrable timer will work normally when the system is busy, but
 * will not cause a CPU to come out of idle just to service it; instead,
 * the timer will be serviced when the CPU eventually wakes up with a
 * subsequent non-deferrable timer.
 *
 * An irqsafe timer is executed with IRQ disabled and it's safe to wait for
 * the completion of the running instance from IRQ handlers, for example,
 * by calling del_timer_sync().
 *
 * Note: The irq disabled callback execution is a special case for
 * workqueue locking issues. It's not meant for executing random crap
 * with interrupts disabled. Abuse is monitored!
 */
#define TIMER_CPUMASK     0x0003FFFF
#define TIMER_MIGRATING   0x00040000
#define TIMER_BASEMASK    (TIMER_CPUMASK | TIMER_MIGRATING)
#define TIMER_DEFERRABLE  0x00080000
#define TIMER_PINNED      0x00100000
#define TIMER_IRQSAFE     0x00200000
```

关于回调函数，我们从例子来看`ktimer_handler()`:

```
static void ktimer_handler(struct timer_list *t)
{
    struct ktimer_data *info = from_timer(info, t, timer);

    pr_info("kernel timer expired at %ld (data=%d)\n",
                jiffies, info->data++);

    /* Reschedule kernel timer */
    mod_timer(&info->timer, jiffies + info->delay_jiffies);
}
```

通过使用`from_timer()`，我们可以获取一个指向我们的数据结构的指针(在示例中定义为`struct ktimer_data`，然后，在完成我们的工作之后，我们可以再次调用`mod_timer()`来重新安排新的计时器执行；否则，一切都将停止。

Note that the `from_timer()` function still uses `container_of()` to do its job, as the following definition from the `linux/include/linux/timer.h` file shows:
`#define from_timer(var, callback_timer, timer_fieldname) \`
`container_of(callback_timer, typeof(*var), timer_fieldname)`.

在模块退出时，在`ktimer_exit()`功能内，我们必须使用`del_timer_sync()`功能等待定时器停止。无论我们之前声明的等待退出仍然有效，因此，要从中断上下文中停止内核定时器，我们可以使用`try_to_del_timer_sync()`，如果定时器已经正确停止，它只返回一个非负值。

为了测试我们的代码，我们只需要编译它，然后将其移动到我们的 ESPRESSObin，然后我们可以将该模块加载到内核中，如下所示:

```
# insmod ktimer.ko
```

然后，在内核消息中，我们应该得到如下内容:

```
[ 122.174020] ktimer:ktimer_init: delay is set to 1000ms (250 jiffies)
[ 122.180519] ktimer:ktimer_init: kernel timer module loaded
[ 123.206222] ktimer:ktimer_handler: kernel timer expired at 4294923072 (data=0)
[ 124.230222] ktimer:ktimer_handler: kernel timer expired at 4294923328 (data=1)
[ 125.254218] ktimer:ktimer_handler: kernel timer expired at 4294923584 (data=2)
```

Again, I've left the timings to give you an idea about kernel timer's precision.

在这里，我们发现 1,000 ms 等于 250 jiffies 也就是说，1 jiffy 是 4 ms，我们还可以看到计时器的处理程序每秒或多或少都会被执行。(抖动非常接近 4 毫秒，即 1 吉非。)

当我们移除模块时，定时器停止，如下所示:

```
ktimer:ktimer_exit: kernel timer module unloaded
```

# 请参见

*   关于高分辨率内核定时器的有趣文档在`linux/Documentation/timers/hrtimers.txt`的内核源代码中。

# 等待事件

在前面几节中，我们看到了如何直接在其处理程序中管理中断，或者通过使用小任务、工作队列等来推迟中断活动。此外，我们还看到了如何进行周期性操作，或者如何及时推迟行动；但是，设备驱动程序可能需要等待特定的事件，例如等待一些数据，等待缓冲区变满，或者等待变量达到所需的值。

Please don't confuse events managed by the notifiers, we saw before, which are kernel related, with generic events for a specific driver.

当没有要从外设读取的数据时，读取过程必须进入睡眠状态，然后在“数据就绪”事件到来时被唤醒。另一个例子是，当我们开始一项复杂的工作时，我们希望在完成时得到信号；在这种情况下，我们开始作业，然后进入睡眠状态，直到“作业完成”事件到来。所有这些任务都可以通过使用**等待队列**(等待队列)或**完成**(仍然由等待队列实现)来完成。

等待队列(或完成队列)只是一个队列，其中一个或多个进程等待与该队列相关的事件；当事件到达时，一个、多个、甚至所有休眠进程都会被唤醒，以便有人管理它。在这个食谱中，我们将学习如何使用 waitqueue。

# 准备好

为了准备一个关于等待队列的简单例子，我们可以再次使用一个内核模块，在这个模块中，我们在模块初始化函数中定义了一个内核定时器，它的任务是生成我们的事件，然后我们使用一个等待队列或完成来等待它。

在 GitHub 资源的`chapter_05/wait_event`目录中，有两个关于 waitqueues 和 completions 的简单例子，然后在*中，它是如何工作的...*一节，我们将详细解释它们。

# 怎么做...

首先，让我们看一个关于 waitqueue 的简单例子，wait queue 用于等待“数据大于 5”事件。

# 等待队列

以下是`waitqueue.c`文件的主要部分，其中保存了一个关于 waitqueues 的简单示例。

1.  还是让我们从头开始，来看看`init()`模块的功能:

```
static int __init waitqueue_init(void)
{
    int ret;

    /* Save kernel timer delay */
    wqinfo.delay_jiffies = msecs_to_jiffies(delay_ms);
    pr_info("delay is set to %dms (%ld jiffies)\n",
                delay_ms, wqinfo.delay_jiffies);

    /* Init the wait queue */
    init_waitqueue_head(&wqinfo.waitq);

    /* Setup and start the kernel timer */
    timer_setup(&wqinfo.timer, ktimer_handler, 0);
    mod_timer(&wqinfo.timer, jiffies + wqinfo.delay_jiffies);
```

内核定时器启动后，我们可以使用`wait_event_interruptible()`功能在`wqinfo.waitq`等待队列中等待`wqinfo.data > 5`事件，如下所示:

```
    /* Wait for the wake up event... */
    ret = wait_event_interruptible(wqinfo.waitq, wqinfo.data > 5);
    if (ret < 0)
        goto exit;

    pr_info("got event data > 5\n");

    return 0;

exit:
    if (ret == -ERESTARTSYS)
        pr_info("interrupted by signal!\n");
    else
        pr_err("unable to wait for event\n");

    del_timer_sync(&wqinfo.timer);

    return ret;
}
```

2.  数据结构现在定义如下:

```
static struct ktimer_data {
    struct wait_queue_head waitq;
    struct timer_list timer;
    long delay_jiffies;
    unsigned int data;
} wqinfo;
```

3.  然而，在 waitqueue 上发生任何动作之前，它必须被初始化，因此，在启动内核定时器之前，我们使用`init_waitqueue_head()`功能来正确设置存储在`struct ktimer_data`中的`struct wait_queue_head waitq`。

如果我们看一下`linux/include/linux/wait.h`标题，我们可以看到`wait_event_interruptible()`是如何工作的:

```
/**
 * wait_event_interruptible - sleep until a condition gets true
 * @wq_head: the waitqueue to wait on
 * @condition: a C expression for the event to wait for
 *
 * The process is put to sleep (TASK_INTERRUPTIBLE) until the
 * @condition evaluates to true or a signal is received.
 * The @condition is checked each time the waitqueue @wq_head is woken up.
 *
 * wake_up() has to be called after changing any variable that could
 * change the result of the wait condition.
 *
 * The function will return -ERESTARTSYS if it was interrupted by a
 * signal and 0 if @condition evaluated to true.
 */
#define wait_event_interruptible(wq_head, condition) \
```

4.  要了解如何唤醒休眠进程，我们应该考虑名为`ktimer_handler()`的`waitqueue.c`文件中的内核定时器处理程序:

```
static void ktimer_handler(struct timer_list *t)
{
    struct ktimer_data *info = from_timer(info, t, timer);

    pr_info("kernel timer expired at %ld (data=%d)\n",
                jiffies, info->data++);

    /* Wake up all sleeping processes */
    wake_up_interruptible(&info->waitq);

    /* Reschedule kernel timer */
    mod_timer(&info->timer, jiffies + info->delay_jiffies);
}
```

# 完成

如果我们希望等待一个作业完成，我们仍然可以使用 waitqueue，但是最好使用一个专门设计用于执行此类活动的完成队列(顾名思义)。这里有一个简单的例子，可以从 GitHub 关于比赛的资源的`completion.c`文件中检索到。

1.  首先来看看模块`init()`和`exit()`功能:

```
static int __init completion_init(void)
{
    /* Save kernel timer delay */
    cinfo.delay_jiffies = msecs_to_jiffies(delay_ms);
    pr_info("delay is set to %dms (%ld jiffies)\n",
                delay_ms, cinfo.delay_jiffies);

    /* Init the wait queue */
    init_completion(&cinfo.done);

    /* Setup and start the kernel timer */
    timer_setup(&cinfo.timer, ktimer_handler, 0); 
    mod_timer(&cinfo.timer, jiffies + cinfo.delay_jiffies);

    /* Wait for completition... */
    wait_for_completion(&cinfo.done);

    pr_info("job done\n");

    return 0;
}

static void __exit completion_exit(void)
{
    del_timer_sync(&cinfo.timer);

    pr_info("module unloaded\n");
}
```

2.  模块数据结构现在如下所示:

```
static struct ktimer_data {
    struct completion done;
    struct timer_list timer;
    long delay_jiffies;
    unsigned int data;
} cinfo;
```

3.  工作完成后，我们可以使用`complete()`功能向`ktimer_handler ()`内核定时器处理程序发出信号，表示工作已经完成:

```
static void ktimer_handler(struct timer_list *t)
{
    struct ktimer_data *info = from_timer(info, t, timer);

    pr_info("kernel timer expired at %ld (data=%d)\n",
                jiffies, info->data++);

    /* Signal that job is done */
    complete(&info->done);
}
```

当调用`complete()`时，等待完成的单个线程被发出信号:

```
/**
 * complete: - signals a single thread waiting on this completion
 * @x: holds the state of this particular completion
 *
 * This will wake up a single thread waiting on this completion. Threads will be
 * awakened in the same order in which they were queued.
 *
 * See also complete_all(), wait_for_completion() and related routines.
 *
 * It may be assumed that this function implies a write memory barrier before
 * changing the task state if and only if any tasks are woken up.
 */
void complete(struct completion *x)
```

而如果我们调用`complete_all()`，所有等待完成的线程都会被告知:

```
/**
 * complete_all: - signals all threads waiting on this completion
 * @x: holds the state of this particular completion
 *
 * This will wake up all threads waiting on this particular completion
 * event.
 * It may be assumed that this function implies a write memory barrier
 * before changing the task state if and only if any tasks are
 * woken up.
 * Since complete_all() sets the completion of @x permanently to done
 * to allow multiple waiters to finish, a call to reinit_completion()
 * must be used on @x if @x is to be used again. The code must make
 * sure that all waiters have woken and finished before reinitializing
 * @x. Also note that the function completion_done() can not be used
 * to know if there are still waiters after complete_all() has been
 * called.
 */
void complete_all(struct completion *x)
```

# 它是如何工作的...

让我们在以下几节中看看这是如何工作的:

# 等待队列

在步骤 3 中，如果条件为真，则调用过程简单地继续执行；否则，它会进入睡眠状态，直到条件变为真或收到信号。(在这种情况下，函数返回`-ERESTARTSYS`值。)

为了完整的理解，我们应该注意到`linux/include/linux/wait.h`头中定义了等待事件函数的另外两个变体。第一个变体只是`wait_event()`功能，它的工作原理与`wait_event_interruptible()`完全一样，但是它不能被任何信号打断:

```
/**
 * wait_event - sleep until a condition gets true
 * @wq_head: the waitqueue to wait on
 * @condition: a C expression for the event to wait for
 *
 * The process is put to sleep (TASK_UNINTERRUPTIBLE) until the
 * @condition evaluates to true. The @condition is checked each time
 * the waitqueue @wq_head is woken up.
 *
 * wake_up() has to be called after changing any variable that could
 * change the result of the wait condition.
 */
#define wait_event(wq_head, condition) \
```

而第二个是`wait_event_timeout()`或`wait_event_interruptible_timeout()`，以同样的方式工作，直到超时:

```
/** * wait_event_interruptible_timeout - sleep until a condition
 *    gets true or a timeout elapses
 * @wq_head: the waitqueue to wait on
 * @condition: a C expression for the event to wait for
 * @timeout: timeout, in jiffies
 *
 * The process is put to sleep (TASK_INTERRUPTIBLE) until the
 * @condition evaluates to true or a signal is received.
 * The @condition is checked each time the waitqueue @wq_head
 * is woken up.
 * wake_up() has to be called after changing any variable that could
 * change the result of the wait condition.
 * Returns:
 * 0 if the @condition evaluated to %false after the @timeout elapsed,
 * 1 if the @condition evaluated to %true after the @timeout elapsed,
 * the remaining jiffies (at least 1) if the @condition evaluated
 * to %true before the @timeout elapsed, or -%ERESTARTSYS if it was
 * interrupted by a signal.
 */
#define wait_event_interruptible_timeout(wq_head, condition, timeout) \
```

在*步骤 4* 中，在该功能中，我们将存储的值更改为数据，然后在 waitqueue 上使用`wake_up_interruptible()`，以向休眠进程发出数据已更改的信号，它应该会醒来以测试条件是否成立。

在`linux/include/linux/wait.h`头中，定义了几个函数，用于通过使用一个通用的`__wake_up()`函数来唤醒一个、多个或所有等待的进程(可中断或不可中断):

```
#define wake_up(x)         __wake_up(x, TASK_NORMAL, 1, NULL)
#define wake_up_nr(x, nr)  __wake_up(x, TASK_NORMAL, nr, NULL)
#define wake_up_all(x)     __wake_up(x, TASK_NORMAL, 0, NULL)
...
#define wake_up_interruptible(x) __wake_up(x, TASK_INTERRUPTIBLE, 1, NULL)
#define wake_up_interruptible_nr(x, nr) __wake_up(x, TASK_INTERRUPTIBLE, nr, NULL)
#define wake_up_interruptible_all(x) __wake_up(x, TASK_INTERRUPTIBLE, 0, NULL)
...
```

在我们的例子中，我们要求的数据大于 5，所以`wake_up_interruptible()`的前 5 个调用不应该唤醒我们的进程；让我们在下一节中验证它！

Note that the process that will go to sleep is just the `insmod` command, which is the one that calls the module initialization function.

# 完成

在*第 1 步*中，我们可以看到代码与前面的 waitqueue 示例非常相似；我们只需像往常一样使用`init_completion()`函数初始化完成，然后在`struct ktimer_data`结构内调用`struct completion done`上的`wait_for_completion()`等待作业结束。

至于等待队列，在`linux/include/linux/completion.h`头中，我们可以找到`wait_for_completion()`函数的几个变体:

```
extern void wait_for_completion(struct completion *);
extern int wait_for_completion_interruptible(struct completion *x);
extern unsigned long wait_for_completion_timeout(struct completion *x,
                                                   unsigned long timeout);
extern long wait_for_completion_interruptible_timeout(
        struct completion *x, unsigned long timeout);
```

# 还有更多...

现在，为了在这两种情况下测试我们的代码，我们必须编译内核模块，然后在 ESPRESSObin 上移动它们；此外，为了更好地理解示例的工作原理，我们应该使用 SSH 连接，然后从另一个终端窗口在串行控制台上查找内核消息。

# 等待队列

当我们用`insmod`插入`waitqueue.ko`模块时，如下，我们应该注意到进程被暂停，直到数据变得大于 5:

```
# insmod waitqueue.ko
```

When the `insmod` process is suspended, you should not get the prompt until the test is finished.

在串行控制台上，我们应该会收到以下消息:

```
waitqueue:waitqueue_init: delay is set to 1000ms (250 jiffies)
waitqueue:ktimer_handler: kernel timer expired at 4295371304 (data=0)
waitqueue:ktimer_handler: kernel timer expired at 4295371560 (data=1)
waitqueue:ktimer_handler: kernel timer expired at 4295371816 (data=2)
waitqueue:ktimer_handler: kernel timer expired at 4295372072 (data=3)
waitqueue:ktimer_handler: kernel timer expired at 4295372328 (data=4)
waitqueue:ktimer_handler: kernel timer expired at 4295372584 (data=5)
waitqueue:waitqueue_init: got event data > 5
waitqueue:ktimer_handler: kernel timer expired at 4295372840 (data=6)
...
```

一旦`got event data > 5`信息出现在屏幕上，则`insmod`过程应该返回，并显示新的提示。

为了验证`wait_event_interruptible()`是否随`-ERESTARTSYS`返回，当信号到达时，我们可以卸载模块并重新加载，然后只需在数据到达 5:

```
# rmmod waitqueue 
# insmod waitqueue.ko
^C
```

这一次在内核消息中，我们应该得到如下内容:

```
waitqueue:waitqueue_init: delay is set to 1000ms (250 jiffies)
waitqueue:ktimer_handler: kernel timer expired at 4295573632 (data=0)
waitqueue:ktimer_handler: kernel timer expired at 4295573888 (data=1)
waitqueue:waitqueue_init: interrupted by signal!
```

# 完成

为了测试完成，我们必须将`completion.ko`模块插入内核。现在你应该注意到，如果我们按下 *CTRL* + *C* 什么都没有发生，因为我们使用了`wait_for_completion()`而不是`wait_for_completion_interruptible()`:

```
# insmod completion.ko
^C^C^C^C
```

五秒钟后提示符返回，内核消息如下:

```
completion:completion_init: delay is set to 5000ms (1250 jiffies)
completion:ktimer_handler: kernel timer expired at 4296124608 (data=0)
completion:completion_init: job done
```

# 请参见

*   虽然有点过时，但在网址[https://lwn.net/Articles/577370/](https://lwn.net/Articles/577370/)上有一些关于排队等候的好信息。

# 执行原子操作

原子操作是设备驱动程序开发的关键步骤。事实上，驱动程序不像一个从头到尾执行的普通程序，因为它提供了几种方法(例如，向外围设备读写数据，或者设置一些通信参数)，这些方法可以相互异步调用。所有这些方法在必须以一致的方式修改的公共数据结构上同时运行。这就是为什么我们需要能够执行原子操作。

Linux 内核使用大量的原子操作。每个都用于不同的操作，这取决于 CPU 是在中断环境中运行还是在进程环境中运行。

当 CPU 在进程上下文中时，我们可以安全地使用**互斥体，**如果互斥体被锁定，可以让当前运行的进程进入睡眠状态；然而，在中断上下文中“进入睡眠”是不允许的，所以我们需要另一种机制，Linux 给了我们**自旋锁**，它允许在任何地方锁定，但时间很短。发生这种情况是因为自旋锁在当前的 CPU 上执行一个繁忙等待的紧循环来完成它们的工作，如果我们停留太久，我们可能会失去性能。

在本食谱中，我们将看到如何以不间断的方式对数据进行操作，以避免数据损坏。

# 准备好

同样，为了构建我们的示例，我们可以使用一个内核模块，该模块在模块`init()`函数期间定义了一个内核计时器，该函数的任务是生成一个异步执行，我们可以在其中使用互斥机制来保护我们的数据。

在 GitHub 资源的`chapter_05/atomic`目录中，有互斥、自旋锁和原子数据的简单例子，在接下来的部分中，我们将详细解释它们。

# 怎么做...

在这一段中，我们将给出两个如何使用互斥锁和自旋锁的例子。我们应该把它们看作是一个关于如何使用 API 的演示，因为在真实的驱动程序中，它们的用法有点不同，将在 [第 7 章](07.html)*高级 Char 驱动程序操作*以及后面的章节中介绍。

# 互斥体

以下是`mutex.c`文件的结尾，其中为模块`init()`功能定义并初始化了互斥体:

```
static int __init mut_init(void)
{
    /* Save kernel timer delay */
    minfo.delay_jiffies = msecs_to_jiffies(delay_ms);
    pr_info("delay is set to %dms (%ld jiffies)\n",
                delay_ms, minfo.delay_jiffies);

    /* Init the mutex */
    mutex_init(&minfo.lock);

    /* Setup and start the kernel timer */
    timer_setup(&minfo.timer, ktimer_handler, 0); 
    mod_timer(&minfo.timer, jiffies);

    mutex_lock(&minfo.lock);
    minfo.data++;
    mutex_unlock(&minfo.lock);

    pr_info("mutex module loaded\n");
    return 0;
}
```

以下是模块`exit()`功能的初始化:

```
static void __exit mut_exit(void)
{
    del_timer_sync(&minfo.timer);

    pr_info("mutex module unloaded\n");
}

module_init(mut_init);
module_exit(mut_exit);
```

1.  在模块初始化`mut_init()`功能中，我们使用`mutex_init()`初始化`lock`互斥体；然后我们就可以安全地启动计时器了。
    模块数据结构定义如下:

```
static struct ktimer_data {
    struct mutex lock;
    struct timer_list timer;
    long delay_jiffies;
    int data;
} minfo;
```

2.  我们使用`mutex_trylock()`尝试安全获取锁:

```
static void ktimer_handler(struct timer_list *t)
{
    struct ktimer_data *info = from_timer(info, t, timer);
    int ret;

    pr_info("kernel timer expired at %ld (data=%d)\n",
                jiffies, info->data);
    ret = mutex_trylock(&info->lock);
    if (ret) {
        info->data++;
        mutex_unlock(&info->lock);
    } else
        pr_err("cannot get the lock!\n");

    /* Reschedule kernel timer */
    mod_timer(&info->timer, jiffies + info->delay_jiffies);
}
```

# 自旋锁

1.  像往常一样，`spinlock.c`文件显示为自旋锁使用的一个例子。这里是`init()`功能模块:

```
static int __init spin_init(void)
{
    unsigned long flags;

    /* Save kernel timer delay */
    sinfo.delay_jiffies = msecs_to_jiffies(delay_ms);
    pr_info("delay is set to %dms (%ld jiffies)\n",
                delay_ms, sinfo.delay_jiffies);

    /* Init the spinlock */
    spin_lock_init(&sinfo.lock);

    /* Setup and start the kernel timer */
    timer_setup(&sinfo.timer, ktimer_handler, 0); 
    mod_timer(&sinfo.timer, jiffies);

    spin_lock_irqsave(&sinfo.lock, flags);
    sinfo.data++;
    spin_unlock_irqrestore(&sinfo.lock, flags);

    pr_info("spinlock module loaded\n");
    return 0;
}
```

这里是模块`exit()`功能:

```
static void __exit spin_exit(void)
{
    del_timer_sync(&sinfo.timer);

    pr_info("spinlock module unloaded\n");
}

module_init(spin_init);
module_exit(spin_exit);
```

模块数据结构如下:

```
static struct ktimer_data {
    struct spinlock lock;
    struct timer_list timer;
    long delay_jiffies;
    int data;
} sinfo;
```

2.  在示例中，我们使用`spin_lock_init()`来初始化自旋锁，然后使用两个不同的函数对来保护我们的数据:`spin_lock()`和`spin_unlock()`；这两者都只是使用自旋锁来避免竞争条件，而`spin_lock_irqsave()`和`spin_unlock_irqrestore()`在当前的 CPU 中断被禁用时使用自旋锁:

```
static void ktimer_handler(struct timer_list *t)
{
    struct ktimer_data *info = from_timer(info, t, timer);

    pr_info("kernel timer expired at %ld (data=%d)\n",
                jiffies, info->data);
    spin_lock(&sinfo.lock);
    info->data++;
    spin_unlock(&info->lock);

    /* Reschedule kernel timer */
    mod_timer(&info->timer, jiffies + info->delay_jiffies);
}
```

By using `spin_lock_irqsave()` and `spin_unlock_irqrestore()`, we can be sure that nobody can interrupt us because the IRQs are disabled, and that no other CPU can execute our code (thanks to the spinlock).

# 它是如何工作的...

让我们在接下来的两节中看看互斥体和自旋锁是如何工作的。

# 互斥体

在*步骤 2* 中，每次我们必须修改我们的数据时，我们可以通过调用`mutex_lock()`和`mutex_unlock()`对来保护它，传递一个指向互斥锁的指针作为参数；当然，我们不能在中断上下文中这样做(就像内核定时器处理程序一样)，这就是为什么我们使用`mutex_trylock()`来尝试安全地获取锁。

# 自旋锁

在第 1 步中，这个例子与前一个非常相似，但它显示了互斥锁和自旋锁之间真正重要的区别:前者保护代码免受进程并发的影响，而后者保护代码免受 CPU 并发的影响！事实上，如果内核没有对称多处理支持(内核`.config`文件中的`CONFIG_SMP=n`，那么自旋锁就消失在空代码中了。

这是一个非常重要的概念，设备驱动开发者应该非常了解；否则，驱动程序可能根本无法工作，或者导致严重的 bug。

# 还有更多...

因为最后一个例子只是为了展示互斥体和自旋锁，所以 API 测试是非常无用的。然而，如果我们无论如何都希望这样做，过程是一样的:编译模块，然后将它们移动到 ESPRESSObin。

# 互斥体

当我们插入`mutex.ko`模块时，输出应该如下所示:

```
# insmod mutex.ko 
mutex:mut_init: delay is set to 1000ms (250 jiffies)
mutex:mut_init: mutex module loaded
```

在步骤 1 中，我们执行模块`init()`功能，在互斥保护区域内增加`minfo.data`。

```
mutex:ktimer_handler: kernel timer expired at 4294997916 (data=1)
mutex:ktimer_handler: kernel timer expired at 4294998168 (data=2)
mutex:ktimer_handler: kernel timer expired at 4294998424 (data=3)
...
```

当我们执行处理程序时，我们可以确定，如果模块`init()`函数当前持有互斥体，它就不能增加`minfo.data`。

# 自旋锁

当我们插入`spinlock.ko`模块时，输出应该如下所示:

```
# insmod spinlock.ko 
spinlock:spin_init: delay is set to 1000ms (250 jiffies)
spinlock:spin_init: spinlock module loaded
```

和以前一样，在*步骤 1* 中，我们执行模块`init()`功能，在该功能中，我们在自旋锁保护区域内增加`minfo.data`。

```
spinlock:ktimer_handler: kernel timer expired at 4295019195 (data=1)
spinlock:ktimer_handler: kernel timer expired at 4295019448 (data=2)
spinlock:ktimer_handler: kernel timer expired at 4295019704 (data=3)
...
```

同样，当我们执行处理程序时，如果模块`init()`函数当前持有自旋锁，我们可以确定它不能增加`minfo.data`。

Note that, in the case of mono core machines, spinlocks vanish, and we assure the `minfo.data` lock by just disabling interrupts.

通过使用互斥体和自旋锁，我们拥有了保护数据不受竞争条件影响所需的一切；然而，Linux 为我们提供了另一个 API，**原子操作**。

# 原子数据类型

在设备驱动程序开发过程中，我们可能需要自动递增或递减一个变量，或者更简单地说，在一个变量中设置一个或多个位。为此，我们可以使用一组由内核保证是原子的变量和操作，而不是使用复杂的互斥机制。

在 GitHub 资源的`atomic.c`文件中，我们可以看到一个关于它们的简单例子，其中原子变量可以定义如下:

```
static atomic_t bitmap = ATOMIC_INIT(0xff);

static struct ktimer_data {
    struct timer_list timer;
    long delay_jiffies;
    atomic_t data;
} ainfo;
```

另外，以下是模块`init()`功能:

```
static int __init atom_init(void)
{
    /* Save kernel timer delay */
    ainfo.delay_jiffies = msecs_to_jiffies(delay_ms);
    pr_info("delay is set to %dms (%ld jiffies)\n",
                delay_ms, ainfo.delay_jiffies);

    /* Init the atomic data */
    atomic_set(&ainfo.data, 10);

    /* Setup and start the kernel timer after required delay */
    timer_setup(&ainfo.timer, ktimer_handler, 0); 
    mod_timer(&ainfo.timer, jiffies + ainfo.delay_jiffies);

    pr_info("data=%0x\n", atomic_read(&ainfo.data));
    pr_info("bitmap=%0x\n", atomic_fetch_and(0x0f, &bitmap));

    pr_info("atomic module loaded\n");
    return 0;
}
```

这里是模块`exit()`功能:

```
static void __exit atom_exit(void)
{
    del_timer_sync(&ainfo.timer);

    pr_info("atomic module unloaded\n");
}
```

在前面的代码中，我们使用`ATOMIC_INIT()`来静态定义和初始化一个原子变量，而`atomic_set()`函数可以用来动态地做同样的事情。随后，可以使用`atomic_*()`前缀的函数来操作原子变量，这些函数位于`linux/include/linux/atomic.h`和`linux/include/asm-generic/atomic.h`文件中。

最后，内核定时器处理程序可以如下实现:

```
static void ktimer_handler(struct timer_list *t)
{
    struct ktimer_data *info = from_timer(info, t, timer);

    pr_info("kernel timer expired at %ld (data=%d)\n",
                jiffies, atomic_dec_if_positive(&info->data));

    /* Compute an atomic bitmap operation */
    atomic_xor(0xff, &bitmap);
    pr_info("bitmap=%0x\n", atomic_read(&bitmap));

    /* Reschedule kernel timer */
    mod_timer(&info->timer, jiffies + info->delay_jiffies);
}
```

原子数据可以通过特定的值进行加减、递增、递减、OR-ed、AND-ed、XOR-ed 等等，所有这些操作都由内核保证是原子的，所以它们的用法真的很简单。

同样，测试代码是非常无用的。但是，如果我们编译然后在 ESPRESSObin 中插入`atomic.ko`模块，输出如下:

```
# insmod atomic.ko 
atomic:atom_init: delay is set to 1000ms (250 jiffies)
atomic:atom_init: data=a
atomic:atom_init: bitmap=ff
atomic:atom_init: atomic module loaded
atomic:ktimer_handler: kernel timer expired at 4295049912 (data=9)
atomic:ktimer_handler: bitmap=f0
atomic:ktimer_handler: kernel timer expired at 4295050168 (data=8)
atomic:ktimer_handler: bitmap=f
...
atomic:ktimer_handler: kernel timer expired at 4295051960 (data=1)
atomic:ktimer_handler: bitmap=f0
atomic:ktimer_handler: kernel timer expired at 4295052216 (data=0)
atomic:ktimer_handler: bitmap=f
atomic:ktimer_handler: kernel timer expired at 4295052472 (data=-1)
```

此时，`data`停留在`-1`处，不再递减。

# 请参见

*   关于内核锁定机制的几个例子，请参考[https://www . kernel . org/doc/html docs/kernel-lock/locks . html](https://www.kernel.org/doc/htmldocs/kernel-locking/locks.html)[。](https://www.kernel.org/doc/htmldocs/kernel-locking/locks.html)
*   关于原子操作的更多信息，请看[https://www . kernel . org/doc/html/v 4.12/core-API/atomic _ ops . html](https://www.kernel.org/doc/html/v4.12/core-api/atomic_ops.html)[。](https://www.kernel.org/doc/htmldocs/kernel-locking/locks.html)