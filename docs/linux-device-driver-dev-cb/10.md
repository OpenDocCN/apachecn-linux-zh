# 十、附加信息：管理中断和并发

回想一下我们在[第 3 章](https://cdp.packtpub.com/linux_device_driver_development_cookbook/wp-admin/post.php?post=28&action=edit#post_26)、*中使用字符驱动所做的工作，*当我们谈到`read()`系统调用以及如何为我们的字符驱动实现它(参见 GitHub 上的`chapter_4/chrdev/chrdev.c`文件)时，我们注意到我们的实现很棘手，因为数据总是可用的:

```sh
static ssize_t chrdev_read(struct file *filp,
               char __user *buf, size_t count, loff_t *ppos)
{
    struct chrdev_device *chrdev = filp->private_data;
    int ret;

    dev_info(chrdev->dev, "should read %ld bytes (*ppos=%lld)\n",
                count, *ppos);

    /* Check for end-of-buffer */
    if (*ppos + count >= BUF_LEN)
        count = BUF_LEN - *ppos;

    /* Return data to the user space */
    ret = copy_to_user(buf, chrdev->buf + *ppos, count);
    if (ret < 0)
        return ret;

    *ppos += count;
    dev_info(chrdev->dev, "return %ld bytes (*ppos=%lld)\n", count, *ppos);

    return count;
}
```

在前面的例子中，`chrdev->buf`内部的数据总是存在的，但是在真实的外设中，这往往不是真的；我们通常必须等待新的数据，然后当前进程应该暂停(即*进入休眠状态*)。这就是为什么我们的`chrdev_read()`应该是这样的:

```sh
static ssize_t chrdev_read(struct file *filp,
               char __user *buf, size_t count, loff_t *ppos)
{
    struct chrdev_device *chrdev = filp->private_data;
    int ret;

    /* Wait for available data */
    wait_for_event(chrdev->available > 0);

    /* Check for end-of-buffer */
    if (count > chrdev->available)
        count = chrdev->available;

    /* Return data to the user space */
    ret = copy_to_user(buf, ..., count);
    if (ret < 0)
        return ret;

    *ppos += count;

    return count;
}
```

Please note that this example is deliberately not complete, due to the fact that a real (and complete) `read()` system call implementation will be presented in [Chapter 7](07.html), *Advanced Char Driver Operations*. In this chapter, we simply introduce mechanisms and not how we can use them in a device driver.

通过使用`wait_for_event()`函数，我们要求内核测试是否有一些可用的数据，如果有，允许进程执行，否则，当前进程将被置于睡眠状态，然后一旦条件`chrdev->available > 0`为真，就被再次唤醒。

外设通常使用中断来通知中央处理器一些新数据可用(或者一些重要的活动必须用它们来完成)，然后很明显，它就在那里，在中断处理程序内部，作为设备驱动开发人员，我们必须通知内核，等待这些数据的睡眠进程应该被唤醒。在接下来的几节中，我们将通过使用非常简单的示例来了解内核中有哪些机制可用，以及如何使用它们来暂停进程，我们还将了解何时可以安全地执行该操作！事实上，如果我们要求调度程序撤销当前进程的中央处理器，将其交给中断处理程序中的另一个进程，我们只是试图执行一个无意义的操作。当我们处于中断上下文中时，我们不是在执行进程代码，那么我们可以撤销哪个进程的 CPU 呢？简单来说，当 CPU 处于进程上下文中时，执行进程可以*进入睡眠*，而当我们处于中断上下文中时，我们不能，因为当前没有进程，官方上，持有 CPU！

最后一个概念非常重要，设备驱动开发人员必须很好地理解它；事实上，如果我们试图在 CPU 处于中断上下文时进入睡眠状态，那么将会产生一个严重的异常，很可能整个系统都会挂起。

另一个需要真正明确的重要概念是**原子操作。**设备驱动不是一个有规律的开始和结束的正常程序；相反，设备驱动是可以同时运行的方法和异步中断处理程序的集合。这就是为什么我们很可能不得不保护我们的数据免受可能破坏它们的比赛条件的影响。

例如，如果我们使用缓冲区仅保存从外设接收的数据，我们必须确保数据正确排队，以便读取过程可以读取有效数据，并且不会丢失任何信息。然后，在这些情况下，我们应该使用 Linux 为我们提供的一些互斥机制来完成我们的工作。然而，我们必须注意我们所做的事情，因为这些机制中的一些可以在两个进程或中断上下文中安全使用，而另一些则不能；其中一些只能在进程上下文中使用，如果我们在中断上下文中使用它们，它们会损坏我们的系统。

此外，我们应该考虑到现代 CPU 有多个内核，因此使用禁用 CPU 中断以获取原子代码的技巧根本不起作用，必须使用特定的互斥机制来代替。在 Linux 中，这种机制被称为**自旋锁**，它可以在中断或进程上下文中使用，但时间很短，因为它们是使用繁忙等待方法实现的。这意味着，为了执行原子操作，当一个内核在属于这种原子操作的代码的关键部分运行时，中央处理器中的所有其他内核都被排除在同一关键部分之外，使它们通过在紧密循环中主动旋转来等待，这反过来意味着您实际上是在丢弃中央处理器的周期，这些周期没有做任何有用的事情。

In the next sections, we're going to see, in detail, all these aspects and we'll try to explain their usage with very simple examples; in [Chapter 7](https://cdp.packtpub.com/linux_device_driver_development_cookbook/wp-admin/post.php?post=28&action=edit#post_30), *Advanced Char Driver Operations*, we'll see how we can use these mechanisms in a device driver. 

# 推迟工作

很久以前就有**下半部分**，也就是一个硬件事件被拆分成两半:上半部分(硬件中断处理程序)和下半部分(软件中断处理程序)。这是因为中断处理程序必须尽快执行，以便为下一个传入的中断做好准备，因此，例如，中央处理器不能长时间停留在中断处理程序的主体中，等待缓慢的外围设备发送或接收其数据。这就是为什么我们使用下半部分；中断被分成两部分:上半部分，真正的硬件中断处理程序，执行速度快，禁用中断，简单地确认外设，然后启动下半部分，启用中断执行，可以安全地完成发送/接收作业，慢慢来。

然而，下半部分非常有限，所以内核开发人员在 Linux 2.4 系列中引入了**小任务**。小任务允许以非常简单的方式动态创建可推迟的函数；它们是在软件中断上下文中执行的，适合快速执行，因为它们无法休眠。然而，如果我们需要睡觉，我们必须使用另一种机制。在 Linux 2.6 系列中，引入了**工作队列**来替代一个类似的被称为 taskqueue 的结构，它已经出现在 Linux 2.4 系列中；它们允许内核函数像小任务一样被激活(或延迟)以供以后执行，但相比之下，小任务(在软件中断内执行)在称为**工作线程**的特殊内核线程中执行。这意味着两者都可以用于推迟作业，但是工作队列处理程序可以休眠。当然，这个处理程序有更高的延迟，但是相比之下，工作队列包含更丰富的工作延迟应用编程接口。

在结束这个食谱之前，还有另外两个重要的概念需要讨论:共享工作队列和`container_of()`宏。

# 共享工作队列

食谱中的前一个例子可以通过使用**共享工作队列**来简化。这是一个由内核本身定义的特殊工作队列，如果设备驱动(和其他内核实体)承诺*不会长时间独占队列(即没有长时间的睡眠，也没有长时间运行的任务)，如果他们接受他们的处理程序可能需要更长的时间才能获得公平的 CPU 份额的事实，他们就可以使用这个队列。如果两个条件都满足，我们可以避免用`create_singlethread_workqueue()`创建自定义工作队列，我们可以简单地使用`schedule_work()`和`schedule_delayed_work()`来安排工作，如下所示。以下是处理程序:*

```sh
--- a/drivers/misc/irqtest.c
+++ b/drivers/misc/irqtest.c
...
+static void irqtest_work_handler(struct work_struct *ptr)
+{
+     struct irqtest_data *info = container_of(ptr, struct irqtest_data,
+                                                      work);
+     struct device *dev = info->dev;
+
+     dev_info(dev, "work executed after IRQ %d", info->irq);
+
+     /* Schedule the delayed work after 2 seconds */
+     schedule_delayed_work(&info->dwork, 2*HZ);
+}
+
 static irqreturn_t irqtest_interrupt(int irq, void *dev_id)
 {
      struct irqtest_data *info = dev_id;
@@ -36,6 +60,8 @@ static irqreturn_t irqtest_interrupt(int irq, void *dev_id)

      dev_info(dev, "interrupt occurred on IRQ %d\n", irq);

+     schedule_work(&info->work);
+
      return IRQ_HANDLED;
 }
```

然后，初始化和删除的修改:

```sh
@@ -80,6 +106,10 @@ static int irqtest_probe(struct platform_device *pdev)
      dev_info(dev, "GPIO %u correspond to IRQ %d\n",
                                irqinfo.pin, irqinfo.irq);

+     /* Init works */
+     INIT_WORK(&irqinfo.work, irqtest_work_handler);
+     INIT_DELAYED_WORK(&irqinfo.dwork, irqtest_dwork_handler);
+
      /* Request IRQ line and setup corresponding handler */
      irqinfo.dev = dev;
      ret = request_irq(irqinfo.irq, irqtest_interrupt, 0,
@@ -98,6 +128,8 @@ static int irqtest_remove(struct platform_device *pdev)
 {
        struct device *dev = &pdev->dev;

+     cancel_work_sync(&irqinfo.work);
+     cancel_delayed_work_sync(&irqinfo.dwork);
      free_irq(irqinfo.irq, &irqinfo);
      dev_info(dev, "IRQ %d is now unmanaged!\n", irqinfo.irq);
```

The preceding patch can be found in the GitHub repository in the `add_workqueue_2_to_irqtest_module.patch` file and it can be applied as usual with the following command:

**`$ patch -p1 < add_workqueue_2_to_irqtest_module.patch`**

# ()宏的容器

最后，我们应该用一些词来解释一下`container_of()`宏。该宏在`linux/include/linux/kernel.h`中定义如下:

```sh
/**
 * container_of - cast a member of a structure out to the containing structure
 * @ptr: the pointer to the member.
 * @type: the type of the container struct this is embedded in.
 * @member: the name of the member within the struct.
 *
 */
#define container_of(ptr, type, member) ({ \
    void *__mptr = (void *)(ptr); \
    BUILD_BUG_ON_MSG(!__same_type(*(ptr), ((type *)0)->member) && \
                     !__same_type(*(ptr), void), \
                     "pointer type mismatch in container_of()"); \
    ((type *)(__mptr - offsetof(type, member))); })
```

`container_of()`函数接受三个参数:一个指针`ptr`，容器的`type`，以及指针在容器内引用的`member`的名称。通过使用这些信息，宏可以扩展到指向包含结构的新地址，该结构容纳相应的成员。

因此，在我们的例子中，在`irqtest_work_handler()`中，我们可以得到一个`struct irqtest_data`指针来告诉`container_of()`它的名为`work`的成员的地址。

For further information regarding `container_of()` function, the internet is your friend; however, a good starting point is in kernel sources within the  `linux/Documentation/driver-model/design-patterns.txt` file, which describes a few common design patterns found in device drivers using this macro.

看看**通知链**，简称为**通知器**，可能会很有意思，这是内核提供的一种通用机制，旨在为内核元素提供一种方式来表达对被告知通用**异步** **事件**发生的兴趣。

# 通知程序

通知机制的基本构件是`linux/include/linux/notifier.h`头文件中定义的`struct notifier_block`，如下所示:

```sh
typedef int (*notifier_fn_t)(struct notifier_block *nb,
                        unsigned long action, void *data);

struct notifier_block {
    notifier_fn_t notifier_call;
    struct notifier_block __rcu *next;
    int priority;
};
```

该结构包含事件发生时要调用的函数的指针`notifier_call`。调用通知函数时传递给它的参数包括一个指向通知块本身的`nb`指针、一个依赖于特定使用链的事件`action`代码和一个指向未指定私有数据类型的`data`指针，它们可以以类似于小任务或等待队列的方式使用。

`next`字段由通知程序内部管理，而`priority`字段定义了`notifier_call`所指向的功能在通知程序链中的优先级。首先，执行具有较高优先级的功能。实际上，几乎所有注册的优先级都被排除在通知程序块定义之外，这意味着它的默认值为 0，执行顺序最终仅取决于注册顺序(即半随机顺序)。

设备驱动开发人员不应该需要创建自己的通知程序，通常他们需要使用现有的通知程序。Linux 定义了几个通知程序，如下所示:

*   网络设备通知程序(参见`linux/include/linux/netdevice.h`)—报告网络设备的事件
*   背光通知器(参见`linux/include/linux/backlight.h`)—报告液晶背光事件
*   暂停通知程序(参见`linux/include/linux/suspend.h`)—报告暂停和恢复相关事件的能力
*   重启通知程序(参见`linux/include/linux/reboot.h`)—报告重启请求
*   电源通知器(见`linux/include/linux/power_supply.h`)—报告电源活动

每个通知程序都有一个注册功能，可以用来要求系统在特定事件发生时得到通知。例如，以下代码是请求网络设备和重新启动事件的有用示例:

```sh
static int __init notifier_init(void)
{
    int ret;

    ninfo.netdevice_nb.notifier_call = netdevice_notifier;
    ninfo.netdevice_nb.priority = 10; 

    ret = register_netdevice_notifier(&ninfo.netdevice_nb);
    if (ret) {
        pr_err("unable to register netdevice notifier\n");
        return ret;
    }

    ninfo.reboot_nb.notifier_call = reboot_notifier;
    ninfo.reboot_nb.priority = 10; 

    ret = register_reboot_notifier(&ninfo.reboot_nb);
    if (ret) {
        pr_err("unable to register reboot notifier\n");
        goto unregister_netdevice;
    }

    pr_info("notifier module loaded\n");

    return 0;

unregister_netdevice:
    unregister_netdevice_notifier(&ninfo.netdevice_nb);
    return ret;
}

static void __exit notifier_exit(void)
{
    unregister_netdevice_notifier(&ninfo.netdevice_nb);
    unregister_reboot_notifier(&ninfo.reboot_nb);

    pr_info("notifier module unloaded\n");
}
```

All code presented here is in the `notifier.c` file from GitHub repository regarding this chapter.

`register_netdevice_notifier()`和`register_reboot_notifier()`函数都在如下定义的两个结构通知程序块上工作:

```sh
static struct notifier_data {
    struct notifier_block netdevice_nb;
    struct notifier_block reboot_nb;
    unsigned int data;
} ninfo;
```

通知函数是这样定义的:

```sh
static int netdevice_notifier(struct notifier_block *nb,
                              unsigned long code, void *unused)
{
    struct notifier_data *ninfo = container_of(nb, struct notifier_data,
                                               netdevice_nb);

    pr_info("netdevice: event #%d with code 0x%lx caught!\n",
                    ninfo->data++, code);

    return NOTIFY_DONE;
}

static int reboot_notifier(struct notifier_block *nb,
                           unsigned long code, void *unused)
{ 
    struct notifier_data *ninfo = container_of(nb, struct notifier_data,
                                               reboot_nb);

    pr_info("reboot: event #%d with code 0x%lx caught!\n",
                    ninfo->data++, code);

    return NOTIFY_DONE;
}
```

通过使用`container_of()`，像往常一样，我们可以得到一个指向我们的数据结构的指针，`struct notifier_data`；然后，一旦我们的工作完成，我们必须返回一个在`linux/include/linux/notifier.h`标题中定义的固定值:

```sh
#define NOTIFY_DONE       0x0000                     /* Don't care */
#define NOTIFY_OK         0x0001                     /* Suits me */
#define NOTIFY_STOP_MASK  0x8000                     /* Don't call further */
#define NOTIFY_BAD        (NOTIFY_STOP_MASK|0x0002)  /* Bad/Veto action */
```

它们的含义如下:

*   `NOTIFY_DONE`:对这个通知不感兴趣。
*   `NOTIFY_OK`:通知处理正确。
*   `NOTIFY_BAD`:这个通知有问题，所以停止调用这个事件的回调函数！

`NOTIFY_STOP_MASK`可用于封装(负)`errno`值，如下所示:

```sh
/* Encapsulate (negative) errno value (in particular, NOTIFY_BAD <=> EPERM). */
static inline int notifier_from_errno(int err)
{
    if (err)
        return NOTIFY_STOP_MASK | (NOTIFY_OK - err);

    return NOTIFY_OK;
}
```

然后可以通过`notifier_to_errno()`检索`errno`值，如下所示:

```sh
/* Restore (negative) errno value from notify return value. */
static inline int notifier_to_errno(int ret)
{
    ret &= ~NOTIFY_STOP_MASK;
    return ret > NOTIFY_OK ? NOTIFY_OK - ret : 0;
}
```

为了测试我们的简单示例，我们必须编译`notifier.c`内核模块，然后将`notifier.ko`模块移动到 ESPRESSObin，在这里它可以插入内核，如下所示:

```sh
# insmod notifier.ko 
notifier:netdevice_notifier: netdevice: event #0 with code 0x5 caught!
notifier:netdevice_notifier: netdevice: event #1 with code 0x1 caught!
notifier:netdevice_notifier: netdevice: event #2 with code 0x5 caught!
notifier:netdevice_notifier: netdevice: event #3 with code 0x5 caught!
notifier:netdevice_notifier: netdevice: event #4 with code 0x5 caught!
notifier:netdevice_notifier: netdevice: event #5 with code 0x5 caught!
notifier:notifier_init: notifier module loaded
```

刚插入后，有些事件已经通知了；但是，要生成新事件，我们可以尝试使用以下`ip`命令禁用或启用网络设备:

```sh
# ip link set lan0 up
notifier:netdevice_notifier: netdevice: event #6 with code 0xd caught!
RTNETLINK answers: Network is down
```

代码`0xd`对应于`linux/include/linux/netdevice.h`中定义的`NETDEV_PRE_UP`事件:

```sh
/* netdevice notifier chain. Please remember to update netdev_cmd_to_name()
 * and the rtnetlink notification exclusion list in rtnetlink_event() when
 * adding new types.
 */
enum netdev_cmd {
    NETDEV_UP = 1, /* For now you can't veto a device up/down */
    NETDEV_DOWN,
    NETDEV_REBOOT, /* Tell a protocol stack a network interface
                      detected a hardware crash and restarted
                      - we can use this eg to kick tcp sessions
                      once done */
    NETDEV_CHANGE, /* Notify device state change */
    NETDEV_REGISTER,
    NETDEV_UNREGISTER,
    NETDEV_CHANGEMTU, /* notify after mtu change happened */
    NETDEV_CHANGEADDR,
    NETDEV_GOING_DOWN,
    NETDEV_CHANGENAME,
    NETDEV_FEAT_CHANGE,
    NETDEV_BONDING_FAILOVER,
    NETDEV_PRE_UP,
...
```

如果我们重新启动系统，我们应该会在内核消息中看到以下消息:

```sh
# reboot
...
[ 2804.502671] notifier:reboot_notifier: reboot: event #7 with code 1 caught!
```

# 内核定时器

一个**内核定时器**是一个简单的方法，要求内核在一段明确定义的时间后执行一个特定的功能。Linux 实现了两种不同类型的内核定时器:在`linux/include/linux/timer.h`头文件中定义的旧的但仍然有效的内核定时器和在`linux/include/linux/hrtimer.h `头文件中定义的新的**高分辨率**内核定时器。即使它们的实现方式不同，两种机制的工作方式也非常相似:我们必须声明一个保存计时器数据的结构，该结构可以通过适当的函数进行初始化，然后可以使用适当的函数启动计时器。一旦超时，计时器将调用一个处理程序来执行所需的操作，最终，我们有可能停止或重新启动计时器。

传统内核定时器仅在分辨率为 1 jiffy 时受支持。jiffy 的长度取决于 Linux 内核中定义的`HZ`的值(参见`linux/include/asm-generic/param.h `文件)；通常，在 PC 和其他一些平台上是 1 毫秒，而在大多数嵌入式平台上设置为 10 毫秒。过去，1 毫秒的分辨率解决了设备驱动开发人员的大多数问题，但如今，大多数外设需要更高的分辨率才能得到正确管理。这就是为什么更高分辨率的计时器开始发挥作用，使系统能够在更精确的时间间隔内快速唤醒和处理数据。目前，内核定时器已经被高分辨率定时器废弃(即使它们仍然围绕内核源使用)，其目标是在 Linux 中实现 POSIX 1003.1b 第 14 节(时钟和定时器)API，即精度优于 1 jiffy 的定时器。

Note that we just saw that, to delay a job, we can also use delayed workqueues.*